Что такое сервлет?	Сервлет является интерфейсом Java, реализация которого расширяет функциональные возможности сервера. Сервлет взаимодействует с клиентами посредством принципа запрос-ответ.Хотя сервлеты могут обслуживать любые запросы, они обычно используются для расширения веб-серверов. Для таких приложений технология Java Servlet определяет HTTP-специфичные сервлет классы. Пакеты javax.servlet и javax.servlet.http обеспечивают интерфейсы и классы для создания сервлетов.
Что такое контейнер сервлетов?	Контейнер сервлетов — программа, представляющая собой сервер, который занимается системной поддержкой сервлетов и обеспечивает их жизненный цикл в соответствии с правилами, определёнными в спецификациях. Известные реализации:Apache Tomcat, Jetty, JBoss, GlassFish, IBM WebSphere, Oracle Weblogic.
Какие задачи, функциональность контейнера сервлетов?	Контейнер сервлетов может работать как полноценный самостоятельный веб-сервер, быть поставщиком страниц для другого веб-сервера, например Apache, или интегрироваться в Java EE сервер приложений. Обеспечивает обмен данными между сервлетом и клиентами, берёт на себя выполнение таких функций, как создание программной среды для функционирующего сервлета, идентификацию и авторизацию клиентов, организацию сессии для каждого из них.
Что вы знаете о сервлет фильтрах?	Сервлетный фильтр, в соответствии со спецификацией, это Java-код, пригодный для повторного использования и позволяющий преобразовать содержание HTTP-запросов, HTTP-ответов и информацию, содержащуюся в заголовках HTTP. Сервлетный фильтр занимается предварительной обработкой запроса, прежде чем тот попадает в сервлет, и/или последующей обработкой ответа, исходящего из сервлета.Сервлетные фильтры могут:  — перехватывать инициализацию сервлета прежде, чем сервлет будет инициирован; — определить содержание запроса прежде, чем сервлет будет инициирован; — модифицировать заголовки и данные запроса, в которые упаковывается поступающий запрос; — модифицировать заголовки и данные ответа, в которые упаковывается получаемый ответ; — перехватывать инициализацию сервлета после обращения к сервлету.  Сервлетный фильтр может быть сконфигурирован так, что он будет работать с одним сервлетом или группой сервлетов. Основой для формирования фильтров служит интерфейс javax.servlet.Filter, который реализует три метода:void init (FilterConfig config) throws ServletException;void destroy();void doFilter (ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException; Метод init() вызывается прежде, чем фильтр начинает работать,и настраивает конфигурационный объект фильтра. Метод doFilter выполняет непосредственно работу фильтра. Таким образом, сервер вызывает init() один раз, чтобы запустить фильтр в работу, а затем вызывает doFilter() столько раз, сколько запросов будет сделано непосредственно к данному фильтру. После того, как фильтр заканчивает свою работу, вызывается метод destroy().
Зачем нужны слушатели в сервлетах?	Слушатели контекста и сессий это классы, которые могут следить за тем, когда контекст или сессия были инициализированы, или отслеживать время, когда они должны быть уничтожены, и когда атрибуты были добавлены или удалены из контекста или сессии. Servlet 2.4 расширяет модель слушателей запроса, позволяя отслеживать, как запрос создается и уничтожается, и, как атрибуты добавляются и удаляются из сервлета. В Servlet 2.4 добавлены следующие классы: ServletRequestListener ServletRequestEvent ServletRequestAttributeListener ServletRequestAttributeEvent
Как обработать исключения, выброшенные другим сервлетом в приложении?	Т.к. браузер понимает только HTTP, то когда приложение выбросит исключение контейнер сервлетов обработает исключение и создаст HTTP response. Это аналогично тому что происходит при кодах ошибок вроде 404, 403 и т.д. Servlet API предоставляет поддержку собственных сервлетов для обработки исключений и ошибок, которые мы можем задать в дескрипторе развертывания. Главная задача таких сервлетов — обработать ошибку или исключение и отправить понятный HTTP ответ пользователю. Например, можно предоставить ссылку на главную страницу, а так же описание некоторых деталей об ошибке.
Что такое дескриптор развертывания?	Дескриптор развертывания это конфигурационный файл артефакта, который будет развернут в контейнере сервлетов. В спецификации Java Platform, Enterprise Edition дескриптор развертывания описывает то, как компонент, модуль или приложение (такое, как веб-приложение или приложение предприятия) должно быть развернуто. Этот конфигурационный файл указывает параметры развертывания для модуля или приложения с определенными настройками, параметры безопасности и описывает конкретные требования к конфигурации. Для синтаксиса файлов дескриптора развертывания используется язык XML.
Как реализовать запуск сервлета с запуском приложения?	Контейнер сервлетов обычно загружает сервлет при первом запросе клиента, но иногда необходимо загрузить сервлет прямо на старте приложения (например если сервлет объемный и будет долго грузиться). Для этого необходимо использовать элемент load-on-startup в дескрипторе (или аннотацию loadOnStartup), который укажет необходимость загрузки сервлета при запуске. <servlet> <servlet-name>foo</servlet-name> <servlet-class>com.foo.servlets.Foo</servlet-class> <load-on-startup>5</load-on-startup> </servlet> Значение должно быть int. Если значение отрицательное, то сервлет будет загружен при запросе клиента, а если 0 и далее, то загрузится на старте приложения. Чем меньше число, тем раньше в очереди на загрузку будет сервлет.
Что представляет собой объект ServletConfig?	Интерфейс javax.servlet.ServletConfig используется для передачи конфигурационной информации сервлету. Каждый сервлет имеет свой собственный объект ServletConfig, за создание экземпляра которого ответственен контейнер сервлетов. Для установки параметров конфигурации используются init параметры в web.xml (или аннотации WebInitParam). Для получения объекта ServletConfig данного сервлета используется метод getServletConfig().
Что представляет собой объект ServletContext?	Интерфейс javax.servlet.ServletContext предоставляет доступ к параметрам веб приложения сервлету. Объект ServletContext является уникальным и доступен всем сервлетам веб приложения. Мы можем использовать объект ServletContext, когда нам необходимо предоставить доступ одному или нескольким сервлетам к инициализированным параметрам веб приложения. Для этого используется элемент <context-param> в web.xml. Объект ServletContext можно получить с помощью метода getServletContext() у интерфейса ServletConfig.Контейнеры сервлетов так же могут предоставлять context объекты, уникальные для группы сервлетов. Каждая из групп будет связана со своим набором URL путей хоста.ServletContext был расширен в спецификации Servlet 3 и предоставляет программное добавление слушателей и фильтров в приложение. Так же у этого интерфейса имеются множество полезных методов вроде getMimeType(), getResourceAsStream() и т.д..
В чем отличия ServletContext и ServletConfig?	ServletConfig является уникальным объектом для каждого сервлета, в то время как ServletContext уникальный для всего приложения.  ServletConfig используется для предоставления параметров инициализации сервлету, а ServletContext для предоставления параметров инициализации приложения для всех сервлетов.  У нас нет возможности устанавливать атрибуты в объекте ServletConfig, в то время как можно установить атрибуты в объекте ServletContext, которые будут доступны другим сервлетам.
Что такое Request Dispatcher?	Интерфейс RequestDispatcher используется для передачи запроса другому ресурсу (это может быть HTML, JSP или другой сервлет в том же приложении). Мы можем использовать это для добавления контента другого ресурса к ответу. Этот интерфейс используется для внутренней коммуникации между сервлетами в одном контексте. В интерфейсе реализовано два метода:void forward(ServletRequest var1, ServletResponse var2) — передает запрос из сервлета к другому ресурсу (сервлету, JSP или HTML файлу) на сервере.void include(ServletRequest var1, ServletResponse var2) — включает контент ресурса (сервлет, JSP или HTML страница) в ответ.Доступ к интерфейсу можно получить с помощью метода ServletContext getRequestDispatcher(String s). Путь должен начинаться с / , который будет интерпретироваться относительным текущего корневого пути контекста.
Как можно создать блокировку (deadlock) в сервлете?	Дедлок можно получить реализовав зацикленный вызов метода, например вызвав метод doPost() в методе doGet() и вызвать doGet() в методе doPost().
Как получить адрес сервлета на сервере?	Для получения актуального пути сервлета на сервере можно использовать эту конструкцию: getServletContext().getRealPath(request.getServletPath())
Как получить информацию о сервере из сервлета?	Информацию о сервере можно получить с использованием объекта ServletContext с помощью метода getServerInfo(). Т.е. getServletContext().getServerInfo().
Как получить ip адрес клиента на сервере?	Использовать request.getRemoteAddr() для получения ip клиента в сервлете.
Что вы знаете о классах обертках (wrapper) для сервлетов?	В Servlet HTTP API предоставляются два класса обертки — HttpServletRequestWrapper и HttpServletResponseWrapper. Они помогают разработчикам реализовывать собственные реализации типов request и response сервлета. Мы можем расширить эти классы и переопределить только необходимые методы для реализации собственных типов объектов ответов и запросов. Эти классы не используются в стандартном программировании сервлетов.
Каков жизненный цикл сервлета и когда какие методы вызываются?	Контейнер сервлетов управляет четырьмя фазами жизненного цикла сервлета:  Загрузка класса сервлета — когда контейнер получает запрос для сервлета, то происходит загрузка класса сервлета в память и вызов конструктора без параметров.  Инициализация класса сервлета — после того как класс загружен контейнер инициализирует объект ServletConfig для этого сервлета и внедряет его через init() метод. Это и есть место где сервлет класс преобразуется из обычного класса в сервлет.  Обработка запросов — после инициализации сервлет готов к обработке запросов. Для каждого запроса клиента сервлет контейнер порождает новую нить (поток) и вызывает метод service() путем передачи ссылки на объект ответа и запроса.  Удаление из Service — когда контейнер останавливается или останавливается приложение, то контейнер сервлетов уничтожает классы сервлетов путем вызова destroy() метода.  Можно описать как последовательность вызова методов: init(), service(), destroy(). public void init(ServletConfig config) - используется контейнером для инициализации сервлета. Вызывается один раз за время жизни сервлета.  public void service(ServletRequest request, ServletResponse response) - вызывается для каждого запроса. Метод не может быть вызван раньше выполнения init() метода.  public void destroy() - вызывается для уничтожения сервлета (один раз за время жизни сервлета).
В каком случае вы будете переопределять метод service()?	Метод service() переопределяется, когда мы хотим, чтобы сервлет обрабатывал как GET так и POST запросы в одном методе. Когда контейнер сервлетов получает запрос клиента, то происходит вызов метода service(), который в свою очередь вызывает doGet(), doPost() методы, основанные на HTTP методе запроса. Есть мнение, что метод service() переопределять особого смысла нет, кроме указанного вначале случая использования одного метода на два типа запросов.
Есть ли смысл определить конструктор для сервлета, как лучше инициализировать данные?	Такая возможность есть, но считается бессмысленной. Инициализировать данные лучше переопределив метод init(), в котором получить доступ к параметрам инициализации сервлета через использование объекта ServletConfig.
В чем отличия GenericServlet и HttpServlet?	Абстрактный класс GenericServlet — независимая от используемого протокола реализация интерфейса Servlet. HttpServlet, как понятно из название, реализация интерфейса сервлета для протокола HTTP. Следует отметить, что HttpServlet extends GenericServlet.
Как вызвать из сервлета другой сервлет этого же и другого приложения?	Если необходимо вызывать сервлет из того же приложения, то необходимо использовать механизм внутренней коммуникации сервлетов (inter-servlet communication mechanisms). Мы можем вызвать другой сервлет с помощью RequestDispatcher forward() и include() методов для доступа к дополнительным атрибутам в запросе для использования в другом сервлете. Метод forward() используется для передачи обработки запроса в другой сервлет. Метод include() используется, если мы хотим вложить результат работы другого сервлета в возвращаемый ответ. Если необходимо вызывать сервлет из другого приложения, то использовать RequestDispatcher уже не получится (определен для приложения). Поэтому можно использовать ServletResponse sendRedirect() метод и предоставить полный URL из другого сервлета. Для передачи данных можно использовать cookies как часть ответа сервлета, а потом использовать их в нашем сервлете.
Стоит ли волноваться о "многопоточной безопасности" работая с сервлетами?	Методы класса HTTPServlet init() и destroy() вызываются один раз за жизненный цикл сервлета — поэтому по поводу них беспокоиться не стоит. Методы doGet(), doPost() вызываются на каждый запрос клиента и т.к. сервлеты используют многопоточность, то здесь нужно задумываться о потокобезопасной работе. В случае наличия локальных переменных в этих методах нет необходимости думать о многопоточной безопасности, т.к. они будут созданы отдельно для каждой нити. Но если используются глобальные ресурсы, то необходимо использовать синхронизацию как и в любом многопоточном приложении Java.
В чем отличие между веб сервером и сервером приложений?	Веб сервер необходим для обработки HTTP request от браузера клиента и ответа клиенту с помощью HTTP response. Веб сервер понимает язык HTTP и запускается по HTTP протоколу. Примером веб сервера может служить реализация от Apache — Tomcat. Сервер приложений предоставляет дополнительные возможности, такие как поддержка JavaBeans, JMS Messaging, Transaction Management и др. Можно сказать, что сервер приложений это веб сервер с дополнительными возможностями, которые помогают разрабатывать корпоративные приложения.
Какой метод HTTP не является неизменяемым?	HTTP метод называется неизменяемым, если он всегда возвращает одинаковый результат. HTTP методы GET, PUT, DELETE, HEAD, OPTIONS являются неизменяемыми. Необходимо реализовывать приложение так, чтобы эти методы возвращали одинаковый результат. К изменяемым методам относится HTTP метод POST. Post метод используется для реализации чего-либо, что изменяется при каждом запросе. К примеру, для доступа к HTML странице или изображению необходимо использовать метод GET, т.к. он возвращает одинаковый результат. Но если нам необходимо сохранить информацию о заказе в базе данных, то нужно использовать POST метод. Неизменяемые методы так же известны как безопасные методы и нет необходимости заботиться о повторяющихся запросах от клиента для этих методов.
В чем разница между методами GET и POST?	GET метод является неизменяемым, тогда как POST — изменяемый. С помощью метода GET можно посылать ограниченное кол-во данных, которые будут пересланы в заголовке URL. В случае POST метода мы можем пересылать большие объемы данных, т.к. они будут находится в теле метода. Данные GET метода передаются в открытом виде, что может использоваться в зловредных целях. POST данные передаются в теле запроса и скрыты от пользователя. GET метод является HTTP методом по умолчанию, а POST метод необходимо указывать явно, чтобы отправить запрос. GET метод используется гиперссылками на странице.
Что такое MIME-тип?	MIME (произн. «майм», англ. Multipurpose Internet Mail Extensions — многоцелевые расширения интернет-почты) — стандарт, описывающий передачу различных типов данных по электронной почте, а также, в общем случае, спецификация для кодирования информации и форматирования сообщений таким образом, чтобы их можно было пересылать по Интернету. Content-Type response header это и есть MIME тип. Сервер посылает MIME тип клиенту для того, чтобы он понял какой тип данных пересылается. Это помогает верно отобразить полученные данные на клиенте. Наиболее часто используемые MIME типы: text/html, text/xml, application/xml и многие др. В ServletContext существует метод getMimeType() для получения корректного MIME типа файла и дальнейшего использования этой информации для указания типа контента в ответе.
Какие различные методы управления сессией в сервлетах вы знаете?	Сессия является обычным состоянием взаимодействия сервера и клиента и может содержать в себе множество запросов и ответов клиент-сервер. Т.к. HTTP и веб сервер не запоминают состояния (stateless), то единственным способом поддерживать сессию является пересылка уникальной информации (session id) в каждом запросе и ответе между клиентом и сервером. Существуют несколько распространенных способов управления сессией в сервлетах: Аутентификация пользователя HTML hidden field (скрытое поле) Cookies URL Rewriting Session Management API
Как применяются Cookies в сервлетах?	Cookies (куки) используются в клиент-серверном взаимодействии и они не являются чем-то конкретным к Java. Servlet API предоставляет поддержку cookies через класс javax.servlet.http.Cookie implements Serializable, Cloneable. Для получения массива cookies из запроса необходимо воспользоваться методом HttpServletRequest getCookies(). Для добавления cookies в запрос методов не предусмотрено. Аналогично HttpServletResponse addCookie(Cookie c) — может добавить cookie в response header, но не существует геттера для этого типа передачи данных.
Что такое аутентификация и авторизация?	Аутентификация — процесс верификации пользователя компьютерной системы.Вот как он происходит в Spring: 1) Полученные пароль и имя пользователя преобразуются в экземпляр UsernamePasswordAuthenticationToken. Он реализует интерфейс Authentication.Токен передается объекту AuthenticationManager для проверки 3) В случае удачной проверки AM возвращает заполненный объект Authentication 4) Устанавливается security context, с помощью вызова SecurityContextHolder.getContext().setAuthentication(...)  Авторизация это процесс удостоверения в том, что у пользователя есть роль, требуемая чтобы сделать какое-либо действие. При авторизации проверяется, есть ли у вас соответствующие права на доступ к ресурсу. Процесс: 1) По принципалу(principal) пользователя отображается его роль 2) Роль пользователя сверяется с ролью ресурса Сначала происходит аутентификация, а потом — авторизация.
Как Security работает внутри?	Используя Spring AOP proxy, которые наследуются от класса AbstractSecurityInterceptor. Применяется для методов вызывающих авторизацию. Веб-инфраструктура в Security основана на servlet-фильтрах. Первым делом конфигурируется фильтр DelegatingFilterProxy. Он делегирует запрос в FilterChainProxy. FilterChainProxy это бин, который принимает в конструкторе один или несколько SecurityFilterChain. SeccurityFilterChain сравнивает URL в запросе со списком фильтров.
Основные объекты, участвующие в Spring Security	SecurityContextHolder — содержит и предоставляет доступ к SecurityContext в приложении. SecurityContext — дефолтная реализация Spring Security содержащая объект Authentication. Authentication — предоставляет токен для запроса аутентификации или для принципала, который прошел аутентификацию. Также содержит список полномочий, к которым получил доступ принципал. GrantedAuthority — содержит полномочия выданные прошедшему проверку принципалу. UserDetails — содержит информацию о пользователе: пароль, логин, полномочия. Эта информация используется для создания объекта Authentication после удачной аутентификации. UserDetailsService — этот сервис извлекает информацию о пользователе из хранилища(память программы, бд, и т.п.) и кладет ее в UserDetails.
Что такое делегирующий прокси фильтр?	Класс DelegatingFilterProxy это класс, который реализует интерфейс javax.Servlet.Filter. Это специальный фильтр, который делегирует работу другим бинам, которые также являются фильтрами.
Что такое security filter chain?	Цепочка фильтров имплементит интерфейс SecurityFilterChain. Имплементацией, поставляемой Spring Security, является DefaultSecurityFilterChain. Конструктор DSFC принимает несколько параметров. Первый параметр — request matcher. Остальные параметры это фильтры, реализующие интерфейс servlet.Filter. Вот все фильтры, принимаемые DSFC: ChannelProcessingFilter SecurityContextPersistenceFilter ConcurrentSessionFilter Любой auth. фильтр: UserNamePasswordAuthenticationFilter / CasAythenticationFilter / BasicAuthenticationFilter SecurityContextHolderAwareRequestFilter JaasApiIntegrationFilter RemeberMeAuthenticationFilter AnonymusAuthenticationFilter ExceptionTranslationFilter FilterSecurityInterceptor
Что такое security context?	Основной объект это SecurityContextHolder. Это место, где хранятся детали о текущем security context, например детали принципала который в текущий момент пользуется приложением. По умолчанию для хранения используется ThreadLocal. //получение SecurityContext SecurityHolderContext.getContext() Объект, возвращаемый методом getContext() это SecurityContext. Он позволяет получать и устанавливать объект Authentication. Authentication представляет следующие свойства: Коллекцию полномочий выданных принципалу Данные для удостоверения пользователя(логин, пароль) Details — доп. информация, если она нужна. Может быть равно null Принципал Authentication flag — boolean переменная, которая показывает успешно ли прошел проверку принципал
Как установить перехват перехода пользователя по определенным URL?	@Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests()  //игнорирование всех запросов на /resources .antMatchers("/resources/**").permitAll()  //для остальных запросов требуется одна из 2 ролей  .antMatchers("/").hasAnyRole("ANONYMOUS", "USER") .antMatchers("/login)*").hasAnyRole("ANONYMOUS", "USER") .antMatchers("/logoutr").hasAnyRole("ANONYMOUS", "USER")  //запрос на ресурсы ниже требуют роль ADMIN .antMatchers("iadmin/*").hasRole("ADMIN") .antMatchers("/events/").hasRole("ADMIN") }
Что означает * в методах antMatchers и mvcMatchers()?	Это выражение означает "любой". Есть 2 вида: * — перехватывает только на том уровне, на котором используется. Например, паттерн "/orders/*" проверит права пользователя, если пользователь перейдет по /orders/aliens или /orders/1, но не /orders/alien/1. ** — перехватывает на всех уровнях.Будут проверены любые запросы, /orders/aliens, /orders/1, /orders/alien/1.
Почему mvcMatcher более защищенный чем antMatcher?	Потому что antMatcher("/service") сопоставляет путь запроса только с "/service", в то время как mvcMatcher("/service") сопоставляет с "/service", "/service.html", "/service.abc".
Spring поддерживает хэширование паролей? Что такое соль?	Да, поддерживает. Для хэширования существует интерфейс PasswordEncoder, который содержит только один метод: static PasswordEncoder createDelegatingPasswordEncoder(), который возвращает DelegatePasswordEncoder, настроенный по умолчанию. Соль используется для вычисления хеш-значения пароля. Это последовательность рандомных чисел, которые используются для преобразования текстового пароля в хеш. Соль хранится в открытом виде рядом с хеш-паролем и может использоваться в дальнейшем при конвертации чистого пароля в хеш при новом логине пользователя.
Зачем нужна защита для методов? Как ее установить?	Spring Security поддерживает защиту отдельных методов в бинах(например, в контроллерах). Это дополнительный слой защиты для приложения. Ее требуется указать явно, используя аннотацию @EnableGlobalMethodSecurity.
Что делает аннотация @RolesAllowed?	Эта аннотация основана на JSR-250. @RolesAllowed позволяет настроить доступ к методам(например, в классе-контроллере) с помощью ролей.Пример: @RolesAllowed("ADMIN") будет пропускать только пользователей с ролью ADMIN Для использования нужно установить @EnableGlobalMethodSecurity(jsr250Enabled=true) на @Configuration классе + нужно чтобы эта аннотация была в classpath.
Расскажите про @PreAuthorize	@PreAuthorize позволяет настроить доступ к методу используя SpEL.Для использования нужно установить @EnableGlobalMethodSecurity(prePostEnabled=true)
Как реализованы все эти аннотации?	Используется сквозная функциональность, с помощью Spring AOP(прокси-объекты).
Что такое «база данных»?	База данных — организованный и адаптированный для обработки вычислительной системой набор информации.
Что такое «система управления базами данных»?	Система управления базами данных (СУБД) - набор средств общего или специального назначения, обеспечивающий создание, доступ к материалам и управление базой данных. Основные функции СУБД: управление данными  журнализация изменений данных  резервное копирование и восстановление данных;  поддержка языка определения данных и манипулирования ими.
Что такое реляционная база данных?	Реляционная база данных — база данных, основанная на реляционной модели данных.
Что такое «реляционная модель данных»?	Реляционная модель данных это логическая модель данных и прикладная теория построения реляционных баз данных. Реляционная модель данных включает в себя следующие компоненты: Структурный аспект — данные представляют собой набор отношений. Аспект целостности — отношения отвечают определенным условиям целостности: уровня домена (типа данных), уровня отношения и уровня базы данных. Аспект обработки (манипулирования) — поддержка операторов манипулирования отношениями (реляционная алгебра, реляционное исчисление). Нормальная форма - свойство отношения в реляционной модели данных, характеризующее его с точки зрения избыточности и определённое как совокупность требований, которым должно удовлетворять отношение.
Дайте определение терминам «простой», «составной» (composite), «потенциальный» (candidate) и «альтернативный» (alternate) ключ.	Простой ключ состоит из одного атрибута (поля). Составной - из двух и более. Потенциальный ключ - простой или составной ключ, который уникально идентифицирует каждую запись набора данных. При этом потенциальный ключ должен обладать критерием неизбыточности: при удалении любого из полей набор полей перестает уникально идентифицировать запись. Из множества всех потенциальных ключей набора данных выбирают первичный ключ, все остальные ключи называют альтернативными.
Что такое «первичный ключ» (primary key)? Каковы критерии его выбора?	Первичный ключ (primary key) в реляционной модели данных один из потенциальных ключей отношения, выбранный в качестве основного ключа (ключа по умолчанию). Если в отношении имеется единственный потенциальный ключ, он является и первичным ключом. Если потенциальных ключей несколько, один из них выбирается в качестве первичного, а другие называют «альтернативными». В качестве первичного обычно выбирается тот из потенциальных ключей, который наиболее удобен. Поэтому в качестве первичного ключа, как правило, выбирают тот, который имеет наименьший размер (физического хранения) и/или включает наименьшее количество атрибутов. Другой критерий выбора первичного ключа — сохранение его уникальности со временем. Поэтому в качестве первичного ключа стараются выбирать такой потенциальный ключ, который с наибольшей вероятностью никогда не утратит уникальность.
Что такое «внешний ключ» (foreign key)?	Внешний ключ (foreign key) — подмножество атрибутов некоторого отношения A, значения которых должны совпадать со значениями некоторого потенциального ключа некоторого отношения B.
Что такое «нормализация»?	Нормализация - подход к проектированию, который минимизирует избыточность данных и оптимизирует структуру данных, правильно размещая элементы данных в соответствующие группы. Нормализация - это процесс преобразования отношений базы данных к виду, отвечающему нормальным формам (пошаговый, обратимый процесс замены исходной схемы другой схемой, в которой наборы данных имеют более простую и логичную структуру). Нормализация предназначена для приведения структуры базы данных к виду, обеспечивающему минимальную логическую избыточность, и не имеет целью уменьшение или увеличение производительности работы или же уменьшение или увеличение физического объёма базы данных. Конечной целью нормализации является уменьшение потенциальной противоречивости хранимой в базе данных информации.
Какие существуют нормальные формы?	Первая нормальная форма (1NF) - Отношение находится в 1NF, если значения всех его атрибутов атомарны (неделимы). Вторая нормальная форма (2NF) - Отношение находится в 2NF, если оно находится в 1NF, и при этом все неключевые атрибуты зависят только от ключа целиком, а не от какой-то его части. Третья нормальная форма (3NF) - Отношение находится в 3NF, если оно находится в 2NF и все неключевые атрибуты не зависят друг от друга. Четвёртая нормальная форма (4NF) - Отношение находится в 4NF , если оно находится в 3NF и если в нем не содержатся независимые группы атрибутов, между которыми существует отношение «многие-ко-многим». Пятая нормальная форма (5NF) - Отношение находится в 5NF, когда каждая нетривиальная зависимость соединения в ней определяется потенциальным ключом (ключами) этого отношения. Шестая нормальная форма (6NF) - Отношение находится в 6NF, когда она удовлетворяет всем нетривиальным зависимостям соединения, т.е. когда она неприводима, то есть не может быть подвергнута дальнейшей декомпозиции без потерь. Каждая переменная отношения, которая находится в 6NF, также находится и в 5NF. Введена как обобщение пятой нормальной формы для хронологической базы данных. Нормальная форма Бойса-Кодда, усиленная 3 нормальная форма (BCNF) - Отношение находится в BCNF, когда каждая её нетривиальная и неприводимая слева функциональная зависимость имеет в качестве своего детерминанта некоторый потенциальный ключ. Доменно-ключевая нормальная форма (DKNF) - Отношение находится в DKNF, когда каждое наложенное на неё ограничение является логическим следствием ограничений доменов и ограничений ключей, наложенных на данное отношение.
Что такое «денормализация»? Для чего она применяется?	Денормализация - это процесс осознанного приведения базы данных к виду, в котором она не будет соответствовать правилам нормализации. Обычно это необходимо для повышения производительности и скорости извлечения данных, за счет увеличения избыточности данных. Если приложению необходимо часто выполнять выборки, которые занимают слишком много времени (например, объединение данных из множества таблиц), то следует рассмотреть возможность проведения денормализации. Возможное решение следующее: вынести результаты выборки в отдельную таблицу. Это позволит увеличить скорость выполнения запросов, но также означает появление необходимости в постоянном обслуживании этой новой таблицы. Прежде чем приступать к денормализации, необходимо убедится, что ожидаемые результаты оправдывают издержки, с которыми придется столкнуться.
Какие существуют типы связей в базе данных? Приведите примеры.	Один к одному - любому значению атрибута А соответствует только одно значение атрибута В, и наоборот. Каждый университет гарантированно имеет 1-го ректора: 1 университет → 1 ректор.  Один ко многим - любому значению атрибута А соответствует 0, 1 или несколько значений атрибута В. В каждом университете есть несколько факультетов: 1 университет → много факультетов.  Многие ко многим - любому значению атрибута А соответствует 0, 1 или несколько значений атрибута В, и любому значению атрибута В соответствует 0, 1 или несколько значение атрибута А. 1 профессор может преподавать на нескольких факультетах, в то же время на 1-ом факультете может преподавать несколько профессоров: Несколько профессоров ↔ Несколько факультетов.
Что такое «индексы»? Для чего их используют? В чём заключаются их преимущества и недостатки?	Индекс (англ. index) — объект базы данных, создаваемый с целью повышения производительности поиска данных. Таблицы в базе данных могут иметь большое количество строк, которые хранятся в произвольном порядке, и их поиск по заданному критерию путем последовательного просмотра таблицы строка за строкой может занимать много времени. Индекс формируется из значений одного или нескольких столбцов таблицы и указателей на соответствующие строки таблицы и, таким образом, позволяет искать строки, удовлетворяющие критерию поиска. Ускорение работы с использованием индексов достигается в первую очередь за счёт того, что индекс имеет структуру, оптимизированную под поиск — например, сбалансированного дерева.  Преимущества: ускорение поиска и сортировки по определенному полю или набору полей.  обеспечение уникальности данных.  Недостатки: требование дополнительного места на диске и в оперативной памяти и чем больше/длиннее ключ, тем больше размер индекса замедление операций вставки, обновления и удаления записей, поскольку при этом приходится обновлять сами индексы.  Индексы предпочтительней для:  Поля-счетчика, чтобы в том числе избежать и повторения значений в этом поле;  Поля, по которому проводится сортировка данных;  Полей, по которым часто проводится соединение наборов данных. Поскольку в этом случае данные располагаются в порядке возрастания индекса и соединение происходит значительно быстрее;  Поля, которое объявлено первичным ключом (primary key);  Поля, в котором данные выбираются из некоторого диапазона. В этом случае как только будет найдена первая запись с нужным значением, все последующие значения будут расположены рядом.  Использование индексов нецелесообразно для:  Полей, которые редко используются в запросах;  Полей, которые содержат всего два или три значения, например: мужской, женский пол или значения «да», «нет».
Какие типы индексов существуют?	По порядку сортировки упорядоченные — индексы, в которых элементы упорядочены; возрастающие; убывающие; неупорядоченные — индексы, в которых элементы неупорядочены. По источнику данных индексы по представлению (view); индексы по выражениям. По воздействию на источник данных кластерный индекс - при определении в наборе данных физическое расположение данных перестраивается в соответствии со структурой индекса. Логическая структура набора данных в этом случае представляет собой скорее словарь, чем индекс. Данные в словаре физически упорядочены, например по алфавиту. Кластерные индексы могут дать существенное увеличение производительности поиска данных даже по сравнению с обычными индексами. Увеличение производительности особенно заметно при работе с последовательными данными. некластерный индекс — наиболее типичные представители семейства индексов. В отличие от кластерных, они не перестраивают физическую структуру набора данных, а лишь организуют ссылки на соответствующие записи. Для идентификации нужной записи в наборе данных некластерный индекс организует специальные указатели, включающие в себя: информацию об идентификационном номере файла, в котором хранится запись; идентификационный номер страницы соответствующих данных; номер искомой записи на соответствующей странице; содержимое столбца. По структуре B*-деревья; B+-деревья; B-деревья; Хэши. По количественному составу простой индекс (индекс с одним ключом) — строится по одному полю; составной (многоключевой, композитный) индекс — строится по нескольким полям при этом важен порядок их следования; индекс с включенными столбцами — некластеризованный индекс, дополнительно содержащий кроме ключевых столбцов еще и неключевые; главный индекс (индекс по первичному ключу) это тот индексный ключ, под управлением которого в данный момент находится набор данных. Набор данных не может быть отсортирован по нескольким индексным ключам одновременно. Хотя, если один и тот же набор данных открыт одновременно в нескольких рабочих областях, то у каждой копии набора данных может быть назначен свой главный индекс. По характеристике содержимого уникальный индекс состоит из множества уникальных значений поля; плотный индекс (NoSQL) — индекс, при котором, каждом документе в индексируемой коллекции соответствует запись в индексе, даже если в документе нет индексируемого поля. разреженный индекс (NoSQL) — тот, в котором представлены только те документы, для которых индексируемый ключ имеет какое-то определённое значение (существует). пространственный индекс — оптимизирован для описания географического местоположения. Представляет из себя многоключевой индекс состоящий из широты и долготы. составной пространственный индекс — индекс, включающий в себя кроме широты и долготы ещё какие-либо мета-данные (например теги). Но географические координаты должны стоять на первом месте. полнотекстовый (инвертированный) индекс — словарь, в котором перечислены все слова и указано, в каких местах они встречаются. При наличии такого индекса достаточно осуществить поиск нужных слов в нём и тогда сразу же будет получен список документов, в которых они встречаются. хэш-индекс предполагает хранение не самих значений, а их хэшей, благодаря чему уменьшается размер (а, соответственно, и увеличивается скорость их обработки) индексов из больших полей. Таким образом, при запросах с использованием хэш-индексов, сравниваться будут не искомое со значения поля, а хэш от искомого значения с хэшами полей. Из-за нелинейнойсти хэш-функций данный индекс нельзя сортировать по значению, что приводит к невозможности использования в сравнениях больше/меньше и «is null». Кроме того, так как хэши не уникальны, то для совпадающих хэшей применяются методы разрешения коллизий. битовый индекс (bitmap index) — метод битовых индексов заключается в создании отдельных битовых карт (последовательностей 0 и 1) для каждого возможного значения столбца, где каждому биту соответствует запись с индексируемым значением, а его значение равное 1 означает, что запись, соответствующая позиции бита содержит индексируемое значение для данного столбца или свойства. обратный индекс (reverse index) — B-tree индекс, но с реверсированным ключом, используемый в основном для монотонно возрастающих значений (например, автоинкрементный идентификатор) в OLTP системах с целью снятия конкуренции за последний листовой блок индекса, т.к. благодаря переворачиванию значения две соседние записи индекса попадают в разные блоки индекса. Он не может использоваться для диапазонного поиска. функциональный индекс, индекс по вычисляемому полю (function-based index) — индекс, ключи которого хранят результат пользовательских функций. Функциональные индексы часто строятся для полей, значения которых проходят предварительную обработку перед сравнением в команде SQL. Например, при сравнении строковых данных без учета регистра символов часто используется функция UPPER. Кроме того, функциональный индекс может помочь реализовать любой другой отсутствующий тип индексов данной СУБД. первичный индекс — уникальный индекс по полю первичного ключа. вторичный индекс — индекс по другим полям (кроме поля первичного ключа). XML-индекс — вырезанное материализованное представление больших двоичных XML-объектов (BLOB) в столбце с типом данных xml. По механизму обновления полностью перестраиваемый — при добавлении элемента заново перестраивается весь индекс. пополняемый (балансируемый) — при добавлении элементов индекс перестраивается частично (например, одна из ветви) и периодически балансируется. По покрытию индексируемого содержимого полностью покрывающий (полный) индекс — покрывает всё содержимое индексируемого объекта. частичный индекс (partial index) это индекс, построенный на части набора данных, удовлетворяющей определенному условию самого индекса. Данный индекс создан для уменьшения размера индекса. инкрементный (delta) индекс — индексируется малая часть данных(дельта), как правило, по истечении определённого времени. Используется при интенсивной записи. Например, полный индекс перестраивается раз в сутки, а дельта-индекс строится каждый час. По сути это частичный индекс по временной метке. индекс реального времени (real-time index) — особый вид инкрементного индекса, характеризующийся высокой скоростью построения. Предназначен для часто меняющихся данных. Индексы в кластерных системах глобальный индекс — индекс по всему содержимому всех сегментов БД (shard). сегментный индекс — глобальный индекс по полю-сегментируемому ключу (shard key). Используется для быстрого определения сегмента, на котором хранятся данные в процессе маршрутизации запроса в кластере БД. локальный индекс — индекс по содержимому только одного сегмента БД.
В чем отличие между кластерными и некластерными индексами?	Некластерные индексы - данные физически расположены в произвольном порядке, но логически упорядочены согласно индексу. Такой тип индексов подходит для часто изменяемого набора данных. При кластерном индексировании данные физически упорядочены, что серьезно повышает скорость выборок данных (но только в случае последовательного доступа к данным). Для одного набора данных может быть создан только один кластерный индекс.
Имеет ли смысл индексировать данные, имеющие небольшое количество возможных значений?	Примерное правило, которым можно руководствоваться при создании индекса - если объем информации (в байтах) НЕ удовлетворяющей условию выборки меньше, чем размер индекса (в байтах) по данному условию выборки, то в общем случае оптимизация приведет к замедлению выборки.
Когда полное сканирование набора данных выгоднее доступа по индексу?	Полное сканирование производится многоблочным чтением. Сканирование по индексу - одноблочным. Также, при доступе по индексу сначала идет сканирование самого индекса, а затем чтение блоков из набора данных. Число блоков, которые надо при этом прочитать из набора зависит от фактора кластеризации. Если суммарная стоимость всех необходимых одноблочных чтений больше стоимости полного сканирования многоблочным чтением, то полное сканирование выгоднее, и оно выбирается оптимизатором. Таким образом, полное сканирование выбирается при слабой селективности предикатов запроса и/или слабой кластеризации данных, либо в случае очень маленьких наборов данных.
Что такое «транзакция»?	Транзакция - это воздействие на базу данных, переводящее её из одного целостного состояния в другое и выражаемое в изменении данных, хранящихся в базе данных.
Назовите основные свойства транзакции.	Атомарность (atomicity) гарантирует, что никакая transaction не будет зафиксирована в системе частично. Будут либо выполнены все её подоперации, либо не выполнено ни одной.  Согласованность (consistency). Транзакция, достигающая своего нормального завершения и, тем самым, фиксирующая свои результаты, сохраняет согласованность базы данных.  Изолированность (isolation). Во время выполнения транзакции параллельные транзакции не должны оказывать влияние на её результат.  Долговечность (durability). Независимо от проблем на нижних уровнях (к примеру, обесточивание системы или сбои в оборудовании) изменения, сделанные успешно завершённой транзакцией, должны остаться сохранёнными после возвращения системы в работу.
Какие существуют уровни изолированности transaction?	В порядке увеличения изолированности transaction и, соответственно, надёжности работы с данными:  Чтение неподтверждённых данных (грязное чтение) (read uncommitted, dirty read) — чтение незафиксированных изменений как своей транзакции, так и параллельных transaction. Нет гарантии, что данные, изменённые другими транзакциями, не будут в любой момент изменены в результате их отката, поэтому такое чтение является потенциальным источником ошибок. Невозможны потерянные изменения, возможны неповторяемое чтение и фантомы.  Чтение подтверждённых данных (read committed) — чтение всех изменений своей транзакции и зафиксированных изменений параллельных transaction. Потерянные изменения и грязное чтение не допускается, возможны неповторяемое чтение и фантомы.  Повторяемость чтения (repeatable read, snapshot) — чтение всех изменений своей транзакции, любые изменения, внесённые параллельными транзакциями после начала своей, недоступны. Потерянные изменения, грязное и неповторяемое чтение невозможны, возможны фантомы.  Упорядочиваемость (serializable) — результат параллельного выполнения сериализуемой транзакции с другими транзакциями должен быть логически эквивалентен результату их какого-либо последовательного выполнения. Проблемы синхронизации не возникают.
Какие проблемы могут возникать при параллельном доступе с использованием transaction?	При параллельном выполнении transaction возможны следующие проблемы: Потерянное обновление (lost update) — при одновременном изменении одного блока данных разными транзакциями одно из изменений теряется; «Грязное» чтение (dirty read) — чтение данных, добавленных или изменённых транзакцией, которая впоследствии не подтвердится (откатится); Неповторяющееся чтение (non-repeatable read) — при повторном чтении в рамках одной транзакции ранее прочитанные данные оказываются изменёнными; Фантомное чтение (phantom reads) — одна transaction в ходе своего выполнения несколько раз выбирает множество записей по одним и тем же критериям. Другая transaction в интервалах между этими выборками добавляет или удаляет записи или изменяет столбцы некоторых записей, используемых в критериях выборки первой транзакции, и успешно заканчивается. В результате получится, что одни и те же выборки в первой транзакции дают разные множества записей. Предположим, имеется две транзакции, открытые различными приложениями, в которых выполнены следующие SQL-операторы: Транзакция 1 2)INSERT INTO tbl1 (f1,f2) VALUES (15,20); 3)COMMIT; Транзакция 2  1) SELECT SUM(f2) FROM tbl1; 4)SELECT SUM(f2) FROM tbl1;  В транзакции 2 выполняется SQL-оператор, использующий все значения поля f2. Затем в транзакции 1 выполняется вставка новой строки, приводящая к тому, что повторное выполнение SQL-оператора в транзакции 2 выдаст другой результат. Такая ситуация называется чтением фантома (фантомным чтением). От неповторяющегося чтения оно отличается тем, что результат повторного обращения к данным изменился не из-за изменения/удаления самих этих данных, а из-за появления новых (фантомных) данных.
Какие компромиссы предлагает использование индексов?	Некоторые из них: Более быстрые выборки, но более медленные изменения. (При изменениях тратиться время на перестройку индекса). Для хранения индексов необходимо дополнительное дисковое пространство.
Первая нормальная форма	Отношение находится в 1НФ, если все его атрибуты являются простыми, все используемые домены должны содержать только скалярные значения. Не должно быть повторений строк в таблице.  (First Normal Form, 1NF) является одной из нормальных форм реляционных баз данных. Она устанавливает базовые требования к структуре таблицы. Чтобы таблица находилась в 1NF, каждая ячейка должна содержать только атомарные значения, то есть значения, которые нельзя дальше разделить на более мелкие части. Кроме того, каждая колонка в таблице должна иметь уникальное имя, а порядок строк не должен иметь значения. Перевод данных в 1NF обычно включает разделение повторяющихся групп данных в отдельные таблицы и использование первичных ключей для связи этих таблиц между собой.
Вторая нормальная форма	Отношение находится во 2НФ, если оно находится в 1НФ и каждый не ключевой атрибут неприводимо зависит от Первичного Ключа(ПК).Неприводимость означает, что в составе потенциального ключа отсутствует меньшее подмножество атрибутов, от которого можно также вывести данную функциональную зависимость.Например, дана таблица: Модель | Фирма | Цена | Скидка M5 | BMW | 5500000 | 5% X5M | BMW | 6000000 | 5% M1 | BMW | 2500000 | 5% GT-R | Nissan | 5000000 | 10% Таблица находится в первой нормальной форме, но не во второй. (Second Normal Form, 2NF) является одной из нормальных форм реляционных баз данных. Она расширяет требования первой нормальной формы (1NF) и дополнительно требует, чтобы каждый неключевой атрибут в таблице полностью зависел от ключа. Другими словами, каждый неключевой атрибут должен быть функционально зависим от всего составного первичного ключа, а не только от его части. Если таблица содержит составной первичный ключ, то атрибуты должны зависеть от всего ключа, а не только от его отдельных составляющих. Если атрибуты не удовлетворяют этому требованию, их следует выделить в отдельные таблицы.
Третья нормальная форма	Отношение находится в 3НФ, когда находится во 2НФ и каждый не ключевой атрибут нетранзитивно зависит от первичного ключа. Проще говоря, второе правило требует выносить все не ключевые поля, содержимое которых может относиться к нескольким записям таблицы в отдельные таблицы. (Third Normal Form, 3NF) является одной из нормальных форм реляционных баз данных. Она представляет собой критерий нормализации, который помогает устранить транзитивные зависимости атрибутов в таблице. В 3NF каждый неключевой атрибут должен зависеть только от ключа целиком, а не от других неключевых атрибутов. Если таблица находится в 3NF, это гарантирует отсутствие дублирования данных и помогает обеспечить более эффективную модель данных. Для достижения 3NF может потребоваться декомпозиция (разделение) таблицы на несколько более мелких таблиц с использованием связей между ними.
Нормальная форма Бойса-Кодда (НФБК) (частная форма третьей нормальной формы)	 (Boyce-Codd Normal Form, BCNF) является одной из нормальных форм реляционных баз данных. Она представляет собой более строгий критерий нормализации, чем третья нормальная форма (3NF). В BCNF каждый атрибут зависит только от ключа целиком, а не от его части. Это означает, что в таблице не должно быть нетривиальных функциональных зависимостей атрибутов от ключа, кроме зависимостей, где ключ является полным составным атрибутом. Если таблица находится не в BCNF, она может подвергаться проблемам аномалий вставки, обновления и удаления данных. Для приведения таблицы к BCNF может потребоваться декомпозиция (разделение) на несколько таблиц.
Четвертая нормальная форма	Отношение находится в 4НФ, если оно находится в НФБК и все нетривиальные многозначные зависимости фактически являются функциональными зависимостями от ее потенциальных ключей.В отношении R (A, B, C) существует многозначная зависимость R.A -> -> R.B в том и только в том случае, если множество значений B, соответствующее паре значений A и C, зависит только от A и не зависит от С.Предположим, что рестораны производят разные виды пиццы, а службы доставки ресторанов работают только в определенных районах города. Составной первичный ключ соответствующей переменной отношения включает три атрибута: {Ресторан, Вид пиццы, Район доставки}.Такая переменная отношения не соответствует 4НФ, так как существует следующая многозначная зависимость:{Ресторан} → {Вид пиццы}{Ресторан} → {Район доставки}То есть, например, при добавлении нового вида пиццы придется внести по одному новому кортежу для каждого района доставки. Возможна логическая аномалия, при которой определенному виду пиццы будут соответствовать лишь некоторые районы доставки из обслуживаемых рестораном районов.Для предотвращения аномалии нужно декомпозировать отношение, разместив независимые факты в разных отношениях. В данном примере следует выполнить декомпозицию на {Ресторан, Вид пиццы} и {Ресторан, Район доставки}.Однако, если к исходной переменной отношения добавить атрибут, функционально зависящий от потенциального ключа, например цену с учётом стоимости доставки ({Ресторан, Вид пиццы, Район доставки} → Цена), то полученное отношение будет находиться в 4НФ и его уже нельзя подвергнуть декомпозиции без потерь.
Пятая нормальная форма	Отношения находятся в 5НФ, если оно находится в 4НФ и отсутствуют сложные зависимые соединения между атрибутами.Если «Атрибут_1» зависит от «Атрибута_2», а «Атрибут_2» в свою очередь зависит от «Атрибута_3», а «Атрибут_3» зависит от «Атрибута_1», то все три атрибута обязательно входят в один кортеж.Это очень жесткое требование, которое можно выполнить лишь при дополнительных условиях. На практике трудно найти пример реализации этого требования в чистом виде.Например, некоторая таблица содержит три атрибута «Поставщик», «Товар» и «Покупатель». Покупатель_1 приобретает несколько Товаров у Поставщика_1. Покупатель_1 приобрел новый Товар у Поставщика_2. Тогда в силу изложенного выше требования Поставщик_1 обязан поставлять Покупателю_1 тот же самый новый Товар, а Поставщик_2 должен поставлять Покупателю_1, кроме нового Товара, всю номенклатуру Товаров Поставщика_1. Этого на практике не бывает. Покупатель свободен в своем выборе товаров. Поэтому для устранения отмеченного затруднения все три атрибута разносят по разным отношениям (таблицам). После выделения трех новых отношений (Поставщик, Товар и Покупатель) необходимо помнить, что при извлечении информации (например, о покупателях и товарах) необходимо в запросе соединить все три отношения. Любая комбинация соединения двух отношений из трех неминуемо приведет к извлечению неверной (некорректной) информации. Некоторые СУБД снабжены специальными механизмами, устраняющими извлечение недостоверной информации. Тем не менее, следует придерживаться общей рекомендации: структуру базы данных строить таким образом, чтобы избежать применения 4НФ и 5НФ.Пятая нормальная форма ориентирована на работу с зависимыми соединениями. Указанные зависимые соединения между тремя атрибутами встречаются очень редко. Зависимые соединения между четырьмя, пятью и более атрибутами указать практически невозможно.
Доменно-ключевая нормальная форма	Переменная отношения находится в ДКНФ тогда и только тогда, когда каждое наложенное на неё ограничение является логическим следствием ограничений доменов и ограничений ключей, наложенных на данную переменную отношения.Ограничение домена - ограничение, предписывающее использовать для определённого атрибута значения только из некоторого заданного домена. Ограничение по своей сути является заданием перечня (или логического эквивалента перечня) допустимых значений типа и объявлением о том, что указанный атрибут имеет данный тип.Ограничение ключа - ограничение, утверждающее, что некоторый атрибут или комбинация атрибутов является потенциальным ключом.Любая переменная отношения, находящаяся в ДКНФ, обязательно находится в 5НФ. Однако не любую переменную отношения можно привести к ДКНФ.
Шестая нормальная форма	Переменная отношения находится в шестой нормальной форме тогда и только тогда, когда она удовлетворяет всем нетривиальным зависимостям соединения. Из определения следует, что переменная находится в 6НФ тогда и только тогда, когда она неприводима, то есть не может быть подвергнута дальнейшей декомпозиции без потерь. Каждая переменная отношения, которая находится в 6НФ, также находится и в 5НФ.Идея «декомпозиции до конца» выдвигалась до начала исследований в области хронологических данных, но не нашла поддержки. Однако для хронологических баз данных максимально возможная декомпозиция позволяет бороться с избыточностью и упрощает поддержание целостности базы данных.Для хронологических баз данных определены U_операторы, которые распаковывают отношения по указанным атрибутам, выполняют соответствующую операцию и упаковывают полученный результат. В данном примере соединение проекций отношения должно производится при помощи оператора U_JOIN. Работники Таб.№ | Время | Должность | Домашний адрес 6575Переменная отношения находится в шестой нормальной форме тогда и только тогда, когда она удовлетворяет всем нетривиальным зависимостям соединения. Из определения следует, что переменная находится в 6НФ тогда и только тогда, когда она неприводима, то есть не может быть подвергнута дальнейшей декомпозиции без потерь. Каждая переменная отношения, которая находится в 6НФ, также находится и в 5НФ.Идея «декомпозиции до конца» выдвигалась до начала исследований в области хронологических данных, но не нашла поддержки. Однако для хронологических баз данных максимально возможная декомпозиция позволяет бороться с избыточностью и упрощает поддержание целостности базы данных.Для хронологических баз данных определены U_операторы, которые распаковывают отношения по указанным атрибутам, выполняют соответствующую операцию и упаковывают полученный результат. В данном примере соединение проекций отношения должно производится при помощи оператора
Как работают индексы	Принцип работы индекса на основе B-дерева основан на рассмотренном нами ранее алгоритме бинарного поиска: т. к. все значения упорядочены, мы можем быстро определять области, в которых гарантированно не может быть данных, удовлетворяющих запрос, существенно снижая таким образом количество перебираемых записей. Однако хранить индекс просто в виде отсортированного массива мы не можем, т. к. данные могут модифицироваться: значения могут меняться, записи — удаляться или добавляться. Чтобы эффективно поддерживать хранение индексируемых данных в отсортированном виде, индекс хранят в виде сбалансированного сильно ветвящегося дерева, называемого B-деревом (B-tree).  Корневой узел B-дерева содержит в упорядоченном виде несколько значений из общего набора, допустим, t элементов. Тогда все остальные элементы можно распределить по t+1 дочерним поддеревьям по следующему правилу: Первое поддерево будет содержать элементы, которые меньше, чем 1-й элемент корневого узла (на рисунке выше первое поддерево содержит числа, меньшие 30). Второе поддерево будет содержать элементы, которые находятся между 1-м и 2-м элементами корневого узла (на рисунке выше второе поддерево содержит числа между 30 и 70). И т. д. — последнее поддерево будет содержать элементы, большие элемента корневого узла с номером t (на рисунке выше третье поддерево содержит элементы, большие 70). Каждое поддерево, в свою очередь, тоже является B-деревом, имеет корневой элемент и строится далее рекурсивно по такому же принципу. За счет того что элементы в каждом узле отсортированы, при поиске мы сможем быстро определить, в каком поддереве может находиться искомый элемент, и не рассматривать вообще другие поддеревья. Допустим, нам нужно найти число 67: Корневой узел содержит числа 30 и 70, значит, искомый элемент следует искать во втором поддереве, т.к. 67 > 30 и 67 < 70. Корневой узел второго поддерева содержит элементы 40 и 50. Т. к. 67 > 50, искомый элемент следует искать в третьем потомке этого узла. На третьем шаге мы получили узел, не имеющий потомков, среди элементов которого находим искомое число 67. Таким образом, при поиске в B-дереве необходимо максимум h раз выполнить линейный или бинарный поиск в относительно небольших списках, где h это высота дерева. Т.к. B-дерево — сильно-ветвящееся и сбалансированное (т. е. при его построении и модификации применяются алгоритмы, сохраняющие его высоту минимальной, см. статью), число h обычно совсем невелико, и при росте общего количества элементов оно растет логарифмически. Как мы уже видели ранее, это приносит очень хорошие результаты.  Кроме того, важное и полезное свойство B-дерева при его использовании в СУБД — возможность эффективно хранить его во внешней памяти. Каждый узел B-дерева обычно хранит такой объем данных, который может быть эффективно записан на диск или прочитан за одну операцию ввода-вывода. B-дерево даже может не помещаться целиком в оперативной памяти. В этом случае СУБД может держать в памяти только узлы верхнего уровня (которые вероятно будут часто использоваться при поиске), читая узлы нижних уровней только при необходимости.
Что такое ООП?	Объектно-ориентированное программирование (ООП) — методология программирования, основанная на представлении программы в виде совокупности объектов, каждый из которых является экземпляром определенного класса, а классы образуют иерархию наследования.  - объектно-ориентированное программирование использует в качестве основных логических конструктивных элементов объекты, а не алгоритмы; - каждый объект является экземпляром определенного класса - классы образуют иерархии.  Программа считается объектно-ориентированной, только если выполнены все три указанных требования. В частности, программирование, не использующее наследование, называется не объектно-ориентированным, а программированием с помощью абстрактных типов данных. Согласно парадигме ООП программа состоит из объектов, обменивающихся сообщениями. Объекты могут обладать состоянием, единственный способ изменить состояние объекта - послать ему сообщение, в ответ на которое, объект может изменить собственное состояние.
Назовите основные принципы ООП.	Инкапсуляция - сокрытие реализации. Наследование - создание новой сущности на базе уже существующей. Полиморфизм - возможность иметь разные формы для одной и той же сущности. Абстракция - набор общих характеристик.
Что такое «инкапсуляция»?	Инкапсуляция - это свойство системы, позволяющее объединить данные и методы, работающие с ними, в классе и скрыть детали реализации от пользователя, открыв только то, что необходимо при последующем использовании. Цель инкапсуляции — уйти от зависимости внешнего интерфейса класса (то, что могут использовать другие классы) от реализации. Чтобы малейшее изменение в классе не влекло за собой изменение внешнего поведения класса.
Что такое «наследование»?	Наследование - это свойство системы, позволяющее описать новый класс на основе уже существующего с частично или полностью заимствующейся функциональностью. Класс, от которого производится наследование, называется предком, базовым или родительским. Новый класс - потомком, наследником или производным классом.
Что такое «полиморфизм»?	Полиморфизм - это свойство системы использовать объекты с одинаковым интерфейсом без информации о типе и внутренней структуре объекта. Преимуществом полиморфизма является то, что он помогает снижать сложность программ, разрешая использование одного и того же интерфейса для задания единого набора действий. Выбор же конкретного действия, в зависимости от ситуации, возлагается на компилятор языка программирования. Отсюда следует ключевая особенность полиморфизма - использование объекта производного класса, вместо объекта базового (потомки могут изменять родительское поведение, даже если обращение к ним будет производиться по ссылке родительского типа). В более общем смысле, концепцией полиморфизма является идея "один интерфейс, множество методов". Это означает, что можно создать общий интерфейс для группы близких по смыслу действий.  Полиморфная переменная, это переменная, которая может принимать значения разных типов, а полиморфная функция, это функция, у которой хотя бы один аргумент является полиморфной переменной. Выделяют два вида полиморфных функций:  Полиморфизм используется, чтобы сделать приложения более модульными и расширяемыми. Вместо беспорядочных условных выражений, описывающих различные варианты действий, вы создаете взаимозаменяемые объекты, которые выбираете в зависимости от ваших потребностей. Это основная цель полиморфизма.
Что такое «абстракция»?	Абстракция - это выделение общих характеристик объекта,исключая набор незначительных. С помощью принципа абстракции данных, данные преобразуются в объекты. Данные обрабатываются в виде цепочки сообщений между отдельными объектами. Все объекты проявляют свои уникальные признаки поведения. Огромный плюс абстракции в том, что она отделяет реализацию объектов от их деталей, что в свою очередь позволяет управлять функциями высокого уровня через функции низкого уровня.
Расскажите про основные понятия ООП: «класс», «объект», «интерфейс».	Класс - это способ описания сущности, определяющий состояние и поведение, зависящее от этого состояния, а также правила для взаимодействия с данной сущностью (контракт). С точки зрения программирования класс можно рассматривать как набор данных (полей, атрибутов, членов класса) и функций для работы с ними (методов). С точки зрения структуры программы, класс является сложным типом данных. Объект (экземпляр) - это отдельный представитель класса, имеющий конкретное состояние и поведение, полностью определяемое классом. Каждый объект имеет конкретные значения атрибутов и методы, работающие с этими значениями на основе правил, заданных в классе. Интерфейс - это набор методов класса, доступных для использования. Интерфейсом класса будет являться набор всех его публичных методов в совокупности с набором публичных атрибутов. По сути, интерфейс специфицирует класс, чётко определяя все возможные действия над ним.
В чем заключаются преимущества и недостатки объектно-ориентированного подхода в программировании?	Преимущества: Объектная модель вполне естественна, поскольку в первую очередь ориентирована на человеческое восприятие мира, а не на компьютерную реализацию.  Классы позволяют проводить конструирование из полезных компонентов, обладающих простыми инструментами, что позволяет абстрагироваться от деталей реализации.  Данные и операции над ними образуют определенную сущность, и они не разносятся по всей программе, как нередко бывает в случае процедурного программирования, а описываются вместе. Локализация кода и данных улучшает наглядность и удобство сопровождения программного обеспечения.  Инкапсуляция позволяет привнести свойство модульности, что облегчает распараллеливание выполнения задачи между несколькими исполнителями и обновление версий отдельных компонентов. Возможность создавать расширяемые системы.  Использование полиморфизма оказывается полезным при: - Обработке разнородных структур данных. Программы могут работать, не различая вида объектов, что существенно упрощает код. Новые виды могут быть добавлены в любой момент. - Изменении поведения во время исполнения. На этапе исполнения один объект может быть заменен другим, что позволяет легко, без изменения кода, адаптировать алгоритм в зависимости от того, какой используется объект. - Реализации работы с наследниками. Алгоритмы можно обобщить настолько, что они уже смогут работать более чем с одним видом объектов. - Возможности описать независимые от приложения части предметной области в виде набора универсальных классов, или фреймворка, который в дальнейшем будет расширен за счет добавления частей, специфичных для конкретного приложения.  Повторное использование кода: - Сокращается время на разработку, которое может быть отдано другим задачам. - Компоненты многоразового использования обычно содержат гораздо меньше ошибок, чем вновь разработанные, ведь они уже не раз подвергались проверке. - Когда некий компонент используется сразу несколькими клиентами, улучшения, вносимые в его код, одновременно оказывают положительное влияние и на множество работающих с ним программ. - Если программа опирается на стандартные компоненты, ее структура и пользовательский интерфейс становятся более унифицированными, что облегчает ее понимание и упрощает использование.  Недостатки: В сложных иерархиях классов поля и методы обычно наследуются с разных уровней. И не всегда легко определить, какие поля и методы фактически относятся к данному классу.  Код для обработки сообщения иногда «размазан» по многим методам (иначе говоря, обработка сообщения требует не одного, а многих методов, которые могут быть описаны в разных классах).  Документирование классов - задача более трудная, чем это было в случае процедур и модулей. Поскольку любой метод может быть переопределен, в  документации должно говориться не только о том, что делает данный метод, но и о том, в каком контексте он вызывается.  Неэффективность и неэкономное распределения памяти на этапе выполнения (по причине издержек на динамическое связывание и проверки типов на этапе выполнения).  Излишняя универсальность. Часто содержится больше методов, чем это реально необходимо текущей программе. А поскольку лишние методы не могут быть удалены, они становятся мертвым грузом.
Что подразумевают в плане принципов ООП выражения «IS-A» и «HAS-A»?	Между классами в Java есть два вида отношений: отношения IS-A Принцип IS-A в ООП основан на наследовании классов или реализации интерфейсов. К примеру, если класс Lion наследует Cat, мы говорим, что Lion является Cat:  Lion IS-A Cat  (но не всякий Cat является Lion-ом) Точно такая же ситуация с интерфейсами. Если класс Lion реализует интерфейс WildAnimal, то они также находятся в отношении:  Lion IS-A WildAnimal   отношения HAS-A Данный тип отношений основан на использовании классов другими классами, ещё называемый "ассоциация". Ассоциация это один класс ссылается на другой класс (или даже друг на друга). Например, класс Car может ссылаться на класс Passenger, и это будет отношение:  Car HAS-A Passenger  И наоборот: если Passenger имеет ссылку на Car, то это будет отношение:  Passenger HAS-A Car
В чем разница между композицией и агрегацией?	Агрегация и композиция — не что иное, как частные случаи ассоциации.  Агрегация — отношение, когда один объект является частью другого. Например, пассажир может находиться в машине. Также пассажиров может быть несколько или не быть вовсе Также композиция подразумевает, что при использовании объекта другим объектом первый не может принадлежать кому-либо другому. Если вернуться к нашему примеру, двигатель может принадлежать только одной машине, но никак не двум или более одновременно.
Что такое статическое и динамическое связывание?	Присоединение вызова метода к телу метода называется связыванием. Если связывание проводится компилятором (компоновщиком) перед запуском программы, то оно называется статическим или ранним связыванием (early binding). В свою очередь, позднее связывание (late binding) это связывание, проводимое непосредственно во время выполнения программы, в зависимости от типа объекта. Позднее связывание также называют динамическим (dynamic) или связыванием на стадии выполнения (runtime binding). В языках, реализующих позднее связывание, должен существовать механизм определения фактического типа объекта во время работы программы, для вызова подходящего метода. Иначе говоря, компилятор не знает тип объекта, но механизм вызова методов определяет его и вызывает соответствующее тело метода. Механизм позднего связывания зависит от конкретного языка, но нетрудно предположить, что для его реализации в объекты должна включаться какая-то дополнительная информация. Для всех методов Java используется механизм позднего (динамического) связывания, если только метод не был объявлен как final (приватные методы являются final по умолчанию).
Что такое перегрузка метода и переопределение метода?	Перегрузка метода: При перегрузке методов методы одного класса имеют одно и то же имя, но каждый метод должен иметь разное количество параметров или параметров, имеющих разные типы и порядок. Перегрузка метода - это «добавить» или «расширить» поведение метода. Это полиморфизм времени компиляции. У методов должна быть другая подпись. Может потребоваться или не потребоваться наследование в перегрузке метода.  Переопределение метода: При переопределении метода подкласс имеет тот же метод с тем же именем, точно такое же количество и тип параметров и тот же тип возвращаемого значения, что и суперкласс. Переопределение метода заключается в «изменении» существующего поведения метода. Это полиморфизм времени выполнения. Методы должны иметь одинаковую подпись. Это всегда требует наследования в переопределении метода.
В чем разница между процедурным программированием и ООП?	Объектно-ориентированного программирования На основе объектов Важность состояний и поведения объекта Поддерживает инкапсуляцию Следует восходящему подходу Лучшая возможность повторного использования кода Менее сложный и простой в расширении и изменении кода  Процедурное программирование На основе функций Более важна последовательность выполняемых функций Не поддерживает инкапсуляцию Следует подходу сверху вниз Меньше повторного использования кода Более сложный для расширения и изменения кода
Можно ли вызвать метод базового класса без создания экземпляра класса?	Да, это возможно при использовании статического метода или когда базовый класс наследуется каким-либо другим подклассом.
Виды полиморфизма	Полиморфизм подтипов - этот тип как раз таки и подразумевают в контексте ООП. Суть в том, что сущность некоторого класса так же может представляться базовым классом или интерфейсом. Это позволяет переиспользовать код, отдавая в один и тот же метод/функцию сущности с разными классами, но с общим интерфейсом.Параметрический полиморфизм - используется уже не только в ООП, но и в других парадигмах. Опять таки полиморфная функция принимает аргумент разных типов, при этом сам тип так же передается как параметр функции, а следовательно функция может оперировать составными типами на основе переданного. Или например возвращать результат того же или производного типа, сохраняя тем самым тип для вызывающего кода. Чаще всего представлено дженериками, но могут быть и другие формы (например template в C++). Как правило не имеет смысла в языках с динамической типизацией. А еще часто сопровождается контрактами на получаемый тип (например типами высшего порядка или типажами), что позволяет с одной стороны ограничить возможные типы, а с другой - воспользоваться характеристиками типа обусловленными контрактом.ad-hoc полиморфизм - способность функции предоставить разную реализацию в зависимости от запрашиваемой сигнатуры. Чаще всего выражено перегрузкой функций/методов. Как правило не реализуем средствами языка с динамической типизацией, хотя может быть реализован в рантайме (например в js функция всегда принимает произвольное количество аргументов и может проанализировать их в рантайме с помощью arguments).
Какие существуют типы наследования?	Java поддерживает четыре типа наследования:  Одиночное наследование: при одиночном наследовании один класс наследует свойства другого, то есть будет только один родительский и один дочерний класс. Многоуровневое наследование: когда класс является производным от класса, который также является производным от другого класса, то есть класса, имеющего более одного родительского класса, но на разных уровнях, такой тип наследования называется многоуровневым наследованием. Иерархическое наследование: когда класс имеет несколько дочерних классов (подклассов) или, другими словами, несколько дочерних классов имеют один и тот же родительский класс, тогда такой вид наследования называется иерархическим. Гибридное наследование. Гибридное наследование - это комбинация двух или более типов наследования.
Можете ли вы переопределить частный или статический метод?	Вы не можете переопределить частный или статический метод. Если вы создаете аналогичный метод с тем же возвращаемым типом и теми же аргументами метода в дочернем классе, он скроет метод суперкласса; это известно как метод сокрытия. Точно так же вы не можете переопределить частный метод в подклассе, потому что он там недоступен. Что вы можете сделать, так это создать другой частный метод с тем же именем в дочернем классе. Давайте посмотрим на пример ниже, чтобы лучше понять это.
Расскажите о наследовании в Java. Каковы особенности использования ключевого слова super?	Возможно наследование лишь одного класса: множественное наследование в Java отсутствует (но с появлением дефолтных методов в Java 8 это утверждение станет весьма спорным).  Приватные методы и поля наследуются тоже, просто к ним не будет доступа с наследника (но если у нас, к примеру, приватное поле и к нему есть public или protected — геттеры и сеттеры, с полем можно работать через них).  final классы не наследуются.  final методы не переопределяются (но их можно наследовать и перегружать).  static методы и переменные не наследуются (т. к. они привязаны не к объектам, а к классам).  При наследовании от абстрактных классов, обязательна реализация их абстрактных методов, либо текущий класс тоже нужно объявить абстрактным.  При наличии не дефолтных конструкторов в родителе, в классе потомке их обязательно нужно переопределять (но @Override над ними не пишется).  Переопределенным методам в наследнике можно расширять модификатор доступа: private -> default -> protected -> public.  Переопределенным методам в наследнике можно сужать прописываемые исключения, например: Exception -> IOException -> FileNotFoundException.
Почему запрещено множественное наследование java?	Множественное наследование это возможность создания одного класса с несколькими суперклассами. Java не обеспечивает поддержку множественного наследования в классах . Java не поддерживает множественное наследование в классах, потому что это может привести к проблеме с бриллиантами, и вместо того, чтобы предоставлять какой-то сложный способ ее решения, существуют более эффективные способы, с помощью которых мы можем достичь того же результата, что и множественное наследование.  Допустим, SuperClass это абстрактный класс, объявляющий некоторый метод, а ClassA, ClassB это конкретные классы которые его реализуют. Теперь предположим, что реализация ClassC она расширяет как ClassA, так и ClassB. Обратите внимание, что метод test() вызывает метод суперкласса doSomething() , что приводит к неоднозначности, поскольку компилятор не знает, какой метод суперкласса следует выполнить, и из-за диаграммы классов в форме ромба он называется Diamond Problem, и это Основная причина, по которой Java не поддерживает множественное наследование в классах.
Расскажите о Spring Framework.	Spring Framework (или коротко Spring) — универсальный фреймворк с открытым исходным кодом для Java-платформы. Несмотря на то, что Spring Framework не обеспечивает какую-либо конкретную модель программирования, он стал широко распространённым в Java-сообществе главным образом как альтернатива и замена модели Enterprise JavaBeans. Spring Framework предоставляет бо́льшую свободу Java-разработчикам в проектировании; кроме того, он предоставляет хорошо документированные и лёгкие в использовании средства решения проблем, возникающих при создании приложений корпоративного масштаба. Обычно Spring описывают как облегченную платформу для построения Java-приложений, но с этим утверждением связаны два интересных момента. Во-первых, Spring можно использовать для построения любого приложения на языке Java (т.е. автономных, веб приложений, приложений JEE и т.д.), что отличает Spring от многих других платформ, таких как Apache Struts, которая ограничена только веб-приложениями. Во-вторых, характеристика "облегченная" в действительности не имеет никакого отношения к количеству классов или размеру дистрибутива; напротив, она определяет принцип всей философии Spring — минимальное воздействие. Платформа Spring является облегченной в том смысле, что для использования ядра Spring вы должны вносить минимальные (если вообще какие-либо) изменения в код своего приложения, а если в какой-то момент вы решите больше не пользоваться Spring, то и это сделать очень просто. Обратите внимание, что речь идет только о ядре Spring — многие дополнительные компоненты Spring, такие как доступ кданным, требуют более тесной привязки к Spring Framework.
Какие некоторые из важных особенностей и преимуществ Spring Framework?	Spring Framework обеспечивает решения многих задач, с которыми сталкиваются Java-разработчики и организации, которые хотят создать информационную систему, основанную на платформе Java. Из-за широкой функциональности трудно определить наиболее значимые структурные элементы, из которых он состоит. Spring Framework не всецело связан с платформой Java Enterprise, несмотря на его масштабную интеграцию с ней, что является важной причиной его популярности.  Spring Framework, вероятно, наиболее известен как источник расширений (features), нужных для эффективной разработки сложных бизнес-приложений вне тяжеловесных программных моделей, которые исторически были доминирующими в промышленности. Ещё одно его достоинство в том, что он ввел ранее неиспользуемые функциональные возможности в сегодняшние господствующие методы разработки, даже вне платформы Java. Этот фреймворк предлагает последовательную модель и делает её применимой к большинству типов приложений, которые уже созданы на основе платформы Java. Считается, что Spring Framework реализует модель разработки, основанную на лучших стандартах индустрии, и делает её доступной во многих областях Java. Таким образом к достоинствам Spring можно отнести:  Относительная легкость в изучении и применении фреймворка в разработке и поддержке приложения.  Внедрение зависимостей (DI) и инверсия управления (IoC) позволяют писать независимые друг от друга компоненты, что дает преимущества в командной разработке, переносимости модулей и т.д..  Spring IoC контейнер управляет жизненным циклом Spring Bean и настраивается наподобие JNDI lookup (поиска).  Проект Spring содержит в себе множество подпроектов, которые затрагивают важные части создания софта, такие как вебсервисы, веб программирование, работа с базами данных, загрузка файлов, обработка ошибок и многое другое. Всё это настраивается в едином формате и упрощает поддержку приложения.
Объясните суть паттерна DI или IoC.	Dependency injection (DI) - паттерн проектирования и архитектурная модель, так же известная как Inversion of Control (IoC). DI описывает ситуацию, когда один объект реализует свой функционал через другой объект. Например, соединение с базой данных передается конструктору объекта через аргумент, вместо того чтобы конструктор сам устанавливал соединение. Существуют три формы внедрения (но не типа) зависимостей: сэттер, конструктор и внедрение путем интерфейса. DI - это способ достижения слабой связанности. IoC предоставляет возможность объекту получать ссылки на свои зависимости. Обычно это реализуется через lookup-метод. Преимущество IoC в том, что эта модель позволяет отделить объекты от реализации механизмов, которые он использует. В результате мы получаем большую гибкость как при разработке приложений, так и при их тестировании.
Какие преимущества применения Dependency Injection (DI)?	К преимуществам DI можно отнести:  Сокращение объема связующего кода. Одним из самых больших плюсов DI является возможность значительного сокращения объема кода, который должен быть написан для связывания вместе различных компонентов приложения. Зачастую этот код очень прост - при создании зависимости должен создаваться новый экземпляр соответствующего объекта.  Упрощенная конфигурация приложения. За счет применения DI процесс конфигурирования приложения значительно упрощается. Для конфигурирования классов, которые могут быть внедрены в другие классы, можно использовать аннотации или XML-файлы.  Возможность управления общими зависимостями в единственном репозитории. При традиционном подходе к управлению зависимостями в общих службах, к которым относятся, например, подключение к источнику данных, транзакция, удаленные службы и т.п., вы создаете экземпляры (или получаете их из определенных фабричных классов) зависимостей там, где они нужны - внутри зависимого класса. Это приводит к распространению зависимостей по множеству классов в приложении, что может затруднить их изменение. В случае использования DI вся информация об общих зависимостях содержится в единственном репозитории (в Spring есть возможность хранить эту информацию в XML-файлах или Java классах).  Улучшенная возможность тестирования. Когда классы проектируются для DI, становится возможной простая замена зависимостей. Это особенно полезно при тестировании приложения.  Стимулирование качественных проектных решений для приложений. Вообще говоря, проектирование для DI означает проектирование с использованием интерфейсов. Используя Spring, вы получаете в свое распоряжение целый ряд средств DI и можете сосредоточиться на построении логики приложения, а не на поддерживающей DI платформе.
Какие IoC контейнеры вы знаете?	Spring является IoC контейнером. Помимо него существуют HiveMind, Avalon, PicoContainer и т.д.
Как реализуется DI в Spring Framework?	Внедрение зависимостей (DI) - это концепция, которая определяет, как должно быть связано несколько классов. Это один из примеров Инверсии контроля. Вам не нужно явно подключать службы и компоненты в коде при использовании внедрения зависимостей. Вместо этого вы описываете службы, необходимые каждому компоненту, в файле конфигурации XML и разрешаете контейнеру IOC автоматически подключать их. Реализация DI в Spring основана на двух ключевых концепциях Java - компонентах JavaBean и интерфейсах. При использовании Spring в качестве поставщика DI вы получаете гибкость определения конфигурации зависимостей внутри своих приложений разнообразными путями (т.е. внешне в XML-файлах, с помощью конфигурационных Java классов Spring или посредством аннотаций Java в коде). Компоненты JavaBean (также называемые POJO (Plain Old Java Object — простой старый объект Java)) предоставляют стандартный механизм для создания ресурсов Java, которые являются конфигурируемыми множеством способов. За счет применения DI объем кода, который необходим при проектировании приложения на основе интерфейсов, снижается почти до нуля. Кроме того, с помощью интерфейсов можно получить максимальную отдачу от DI, потому что бины могут использовать любую реализацию интерфейса для удовлетворения их зависимости.ff
Какие существуют виды DI? Приведите примеры.	Существует два типа DI: через сэттер и через конструктор. Через сэттер: обычно во всех java beans используются гэттеры и сэттеры для их свойств: public class NameBean { String name; public void setName(String a) { name = a; } public String getName() { return name;} }  Мы создаем экземпляр бина NameBean (например, bean1) и устанавливаем нужное свойство, например: bean1.setName("Marfa");  Используя Spring реализация была бы такой: <bean id="bean1" class="NameBean"> <property name="name"> <value>Marfa</value> </property> </bean>  Это и называет DI через сэттер. Пример внедрения зависимости между объектами: <bean id="bean1" class="bean1impl"> <property name="game"> <ref bean="bean2" /> </property> </bean> <bean id="bean2" class="bean2impl" />  Через конструктор: используется конструктор с параметрами. Например: public class NameBean { String name; public NameBean(String name) { this. name = name; }}  Теперь мы внедряем объект на этапе создания экземпляра класса, т.е. bean1 = new NameBean("Marfa");  Используя Spring это выглядело бы так: <bean id="bean1" class="NameBean"> <constructor-arg> <value>Marfa</value> </constructor-arg> </bean>
Что такое Spring? Из каких частей состоит Spring Framework?	Spring - фреймворк с открытым исходным кодом, предназначеный для упрощения разработки enterprise-приложений. Одним из главным преимуществом Spring является его слоистая архитектура, позволяющая вам самим определять какие компоненты будут использованы в вашем приложении. Модули Spring построены на базе основного контейнера, который определяет создание, конфигурация и менеджмент бинов. Основные модули: Основной контейнер - предоставляет основной функционал Spring. Главным компонентом контейнера является BeanFactory - реализация паттерна Фабрика. BeanFactory позволяет разделить конфигурацию приложения и информацию о зависимостях от кода. Spring context - конфигурационный файл, который предоставляет информация об окружающей среде для Spring. Сюда входят такие enterprise-сервисы, как JNDI, EJB, интернационализация, валиадция и т.п. Spring AOP - отвечает за интеграцию аспектно-ориентированного программирования во фреймворк. Spring AOP обеспечивает сервис управления транзакциями для Spring-приложения. Spring DAO - абстрактный уровень Spring JDBC DAO предоставляет иерархию исключений и множество сообщений об ошибках для разных БД. Эта иерархия упрощает обработку исключений и значительно уменьшает количество кода, которое вам нужно было бы написать для таких операций, как, например, открытие и закрытие соединения. Spring ORM - отвечает за интеграцию Spring и таких популярных ORM-фреймворков, как Hibernate, iBatis и JDO. Spring Web module - классы, которые помогают упростить разработку Web (авторизация, доступ к бинам Spring-а из web). Spring MVC framework - реализация паттерна MVC для построения Web-приложений.
Назовите некоторые из шаблонов проектирования, используемых в Spring Framework?	Spring Framework использует множество шаблонов проектирования, например:  Singleton Pattern: Creating beans with default scope. Factory Pattern: Bean Factory classes Prototype Pattern: Bean scopes Adapter Pattern: Spring Web and Spring MVC Proxy Pattern: Spring Aspect Oriented Programming support Template Method Pattern: JdbcTemplate, HibernateTemplate etc Front Controller: Spring MVC DispatcherServlet Data Access Object: Spring DAO support Dependency Injection and Aspect Oriented Programming
Каковы некоторые из важных особенностей и преимуществ Spring Framework?	Spring Framework обеспечивает решения многих задач, с которыми сталкиваются Java-разработчики и организации, которые хотят создать информационную систему, основанную на платформе Java. Из-за широкой функциональности трудно определить наиболее значимые структурные элементы, из которых он состоит. Spring Framework не всецело связан с платформой Java Enterprise, несмотря на его масштабную интеграцию с ней, что является важной причиной его популярности.  Относительная легкость в изучении и применении фреймворка в разработке и поддержке приложения.  Внедрение зависимостей (DI) и инверсия  управления (IoC) позволяют писать независимые друг от друга компоненты, что дает преимущества в командной разработке, переносимости модулей и т.д..  Spring IoC контейнер управляет жизненным циклом Spring Bean и настраивается наподобие JNDI lookup (поиска).  Проект Spring содержит в себе множество подпроектов, которые затрагивают важные части создания софта, такие как вебсервисы, веб программирование, работа с базами данных, загрузка файлов, обработка ошибок и многое другое. Всё это настраивается в едином формате и упрощает поддержку приложения.
Каковы преимущества использования Spring Tool Suite?	Для упрощения процесса разработки основанных на Spring приложений в Eclipse (наиболее часто используемая IDE-среда для разработки Java-приложений), в рамках Spring создан проект Spring IDE. Проект бесплатный. Он интегрирован в Eclipse IDE, Spring IDE, Mylyn (среда разработки в Eclipse, основанная на задачах), Maven for Eclipse, AspectJ Development Tool.
Что такое AOP? Как это относиться к IoC?	Аспектно-ориентированное программирование (АОП) - парадигма программирования, основанная на идее разделения функциональности для улучшения разбиения программы на модули. AOP и Spring - взаимодополняющие технологии, которые позволяют решать сложные проблемы путем разделения функционала на отдельные модули. АОП предоставляет возможность реализации сквозной логики - т.е. логики, которая применяется к множеству частей приложения - в одном месте и обеспечения автоматического применения этой логики по всему приложению. Подход Spring к АОП заключается в создании "динамических прокси" для целевых объектов и "привязывании" объектов к конфигурированному совету для выполнения сквозной логики.
В чем разница между Сквозной Функциональностью (Cross Cutting Concerns) и АОП (аспектно оринтированное программирование)?	Сквозная Функциональность — функциональность, которая может потребоваться вам на нескольких различных уровнях — логирование, управление производительностью, безопасность и т.д. АОП — один из подходов к реализации данной проблемы
Почему возвращаемое значение при применении аспекта @Around может потеряться? Назовите причины.	Метод, помеченный аннотацией @Around, должен возвращать значение, которое он (метод) получил из joinpoint.proceed() @Around("trackTimeAnnotation()")  public Object around(ProceedingJoinPoint joinPoint) throws Throwable{ long startTime = System.currentTimeMillis(); Object retVal = joinPoint.proceed();  long timeTaken = System.currentTimeMillis() - startTime;  logger.info("Time taken by {} is equal to {}",joinPoint, timeTaken);  return retVal; }
Что такое Aspect, Advice, Pointcut, JointPoint и Advice Arguments в АОП?	Основные понятия АОП: Аспект (англ. aspect) - модуль или класс, реализующий сквозную функциональность. Аспект изменяет поведение остального кода, применяя совет в точках соединения, определённых некоторым срезом. Совет (англ. advice) - фрагмент кода, который должен выполняться в отдельной точке соединения. Существует несколько типов советов, совет может быть выполнен до, после или вместо точки соединения. Точка соединения (англ. joinpoint) - это четко определенная точка в выполняемой программе, где следует применить совет. Типовые примеры точек соединения включают обращение к методу, собственно Method Invocation, инициализацию класса и создание экземпляра объекта. Многие реализации АОП позволяют использовать вызовы методов и обращения к полям объекта в качестве точек соединения. Срез (англ. pointcut) - набор точек соединения. Срез определяет, подходит ли данная точка соединения к данному совету. Самые удобные реализации АОП используют для определения срезов синтаксис основного языка (например, в AspectJ применяются Java-сигнатуры) и позволяют их повторное использование с помощью переименования и комбинирования. Связывание(англ. weaving) представляет собой процесс действительной вставки аспектов в определенную точку кода приложения. Для решений АОП времени компиляции это делается на этапе компиляции, обычно в виде дополнительного шага процесса сборки. Аналогично, для решений АОП времени выполнения связывание происходит динамически во время выполнения. В AspectJ поддерживается еще один механизм связывания под названием связывание во время загрузки (load-time weaving - LTW), который перехватывает лежащий в основе загрузчик классов JVM и обеспечивает связывание с байт-кодом, когда он загружается загрузчиком классов. Цель(англ. target) - это объект, поток выполнения которого изменяется каким-то процессом АОП. На целевой объект часто ссылаются как на объект, снабженный советом. Внедрение (англ. introduction, введение) - представляет собой процесс, посредством которого можно изменить структуру объекта за счет введения в него дополнительных методов или полей, изменение иерархии наследования для добавления функциональности аспекта в инородный код. Обычно реализуется с помощью некоторого метаобъектного протокола (англ. metaobject protocol, MOP).
В чем разница между Spring AOP и AspectJ АОП?	AspectJ де-факто является стандартом реализации АОП. Реализация АОП от Spring имеет некоторые отличия: Spring AOP немного проще, т.к. нет необходимости следить за процессом связывания. Spring AOP поддерживает аннотации AspectJ, таким образом мы можем работать в спринг проекте похожим образом с AspectJ проектом. Spring AOP поддерживает только proxy-based АОП и может использовать только один тип точек соединения - Method Invocation. AspectJ поддерживает все виды точек соединения. Недостатком Spring AOP является работа только со своими бинами, которые существуют в Spring Context.
Что такое Advice в Spring?	Advice - это действие, предпринятое в данной точке соединения. AOП использует Advice в качестве перехватчика до завершения выполнения метода.
Каковы типы рекомендаций для структуры Spring?	До: Это советы, которые выполняются до методов joinpoint. Они помечены знаком @before. После возврата: они выполняются после того, как метод joinpoint завершит выполнение без проблем. Они помечены знаком аннотации @AfterReturning. После выполнения: Они выполняются только в том случае, если метод joinnpoint заканчивается созданием исключения. Они помечены с помощью метки аннотации @AfterThrowing. После: Они выполняются после метода joinpoint, независимо от того, как он завершается. Они помечены знаком @After. Вокруг: Они выполняются до и после точки соединения и помечаются с помощью метки @Around аннотации.
Что такое Weaving?	Weaving Spring - это процесс связывания элементов с другими типами приложений или объектами для создания рекомендуемых объектов.
Что такое прокси-объекты и какие типы прокси-объектов может создавать Spring?	Прокси это специальный объект, который имеет такие же публичные методы как и бин, но у которого есть дополнительная функциональность.  Два вида прокси: JDK-proxy — динамическое прокси. API встроены в JDK. Для него необходим интерфейс CGLib proxy — не встроен в JDK. Используется когда интерфейс объекта недоступен Плюсы прокси-объектов: Позволяют добавлять доп. логику — управление транзакциями, безопасность, логирование Отделяет некоторый код(логирование и т.п.) от основной логики
Что такое IoC контейнер Spring?	По своей сути IoC, а, следовательно, и DI, направлены на то, чтобы предложить простой механизм для предоставления зависимостей компонента (часто называемых коллабораторами объекта) и управления этими зависимостями на протяжении всего их жизненного цикла. Компонент, который требует определенных зависимостей, зачастую называют зависимым объектом или, в случае IoC, целевым объектом. IoC предоставляет службы, через которые компоненты могут получать доступ к своим зависимостям, и службы для взаимодействия с зависимостями в течение их времени жизни. В общем случае IoC может быть расщеплена на два подтипа: инверсия управления (Dependency Injection) и инверсия поиска (Dependency Lookup). Инверсия управления это крупная часть того, делает Spring, и ядро реализации Spring основано на инверсии управления, хотя также предоставляются и средства Dependency Lookup. Когда платформа Spring предоставляет коллабораторы зависимому объекту автоматически, она делает это с использованием инверсии управления (Dependency Injection). В приложении, основанном на Spring, всегда предпочтительнее применять Dependency Injection для передачи коллабораторов зависимым объектам вместо того, чтобы заставлять зависимые объекты получать коллабораторы через поиск.
Что такое контейнер и какой у него жизненный цикл?	Основа Spring Framework — контейнер, и наши объекты "живут" в этом контейнере.Контейнер обычно создает множество объектов на основе их конфигураций и управляет их жизненным циклом от создания объекта до уничтожения. Контейнер это объект, реализующий интерфейс ApplicationContext.
Жизненный цикл контейнера	Контейнер создается при запуске приложения Контейнер считывает конфигурационные данные Из конфигурационных данных создается описание бинов BeanFactoryPostProcessors обрабатывают описание бина Контейнер создает бины используя их описание Бины инициализируются — значения свойств и зависимости внедряются в бин BeanPostProcessor запускают методы обратного вызова(callback methods) Приложение запущено и работает Инициализируется закрытие приложения Контейнер закрывается Вызываются callback methods
Что такое Spring бин?	Термин бин (англ. Bean) - в Spring используется для ссылки на любой компонент, управляемый контейнером. Обычно бины на определенном уровне придерживаются спецификации JavaBean, но это не обязательно особенно если для связывания бинов друг с другом планируется применять Constructor Injection. Для получения экземпляра бина используется ApplicationContext. IoC контейнер управляет жизненным циклом спринг бина, областью видимости и внедрением.
Какое значение имеет конфигурационный файл Spring Bean?	Конфигурационный файл спринг определяет все бины, которые будут инициализированы в Spring Context. При создании экземпляра Spring ApplicationContext будет прочитан конфигурационный xml файл и выполнены указанные в нем необходимые инициализации. Отдельно от базовой конфигурации, в файле могут содержаться описание перехватчиков (interceptors), view resolvers, настройки локализации и др...
Каковы различные способы настроить класс как Spring Bean?	Существует несколько способов работы с классами в Spring: XML конфигурация:  Java based конфигурация. Все настройки и указания бинов прописываются в java коде:  Annotation based конфигурация. Можно использовать внутри кода аннотации @Component, @Service, @Repository, @Controller для указания классов в качестве спринг бинов. Для их поиска и управления контейнером прописывается настройка в xml файле:
Какие вы знаете различные scope у Spring Bean?	В Spring предусмотрены различные области времени действия бинов: singleton - может быть создан только один экземпляр бина. Этот тип используется спрингом по умолчанию, если не указано другое. Следует осторожно использовать публичные свойства класса, т.к. они не будут потокобезопасными. prototype - создается новый экземпляр при каждом запросе. request - аналогичен prototype, но название служит пояснением к использованию бина в веб приложении. Создается новый экземпляр при каждом HTTP request. session - новый бин создается в контейнере при каждой новой HTTP сессии. Application Область видимости — жизненный цикл ServletContext WebSocket Область видимости — жизненный цикл WebSocket
Как связаны различные скоупы и многопоточность?	Prototype Scope не потокбезопасный, т.к. он не гарантирует что один и тот же экземпляр будет вызываться только в 1 потоке. Singleton Scope же наоборот потокобезопасный.
Как создаются бины: сразу или лениво? Как изменить это поведение?	Singleton-бины обычно создаются сразу при сканировании.Prototype-бины обычно создаются только после запроса. Чтобы указать способ инициализации, можно использовать аннотацию @Lazy. Она ставится на @Bean-методы, на @Configuration-классы, или на @Component-классы.В зависимости от параметра(true или false), который принимает аннотация, инициализация будет или ленивая, или произойдет сразу. По умолчанию(т.е. без указания параметра) используется true.
Что будет если бин с одним скоупом внедрить в бин с другим скоупом?	Singleton bean можно внедрять в любой другой бин. В сам singleton можно внедрить только prototype или singleton.Если внедрять prototype, то для каждого singleton будет создан уникальный prototype. Prototype может быть зависимостью для любого бина.Внедрять можно только singleton или prototype.
Как работает инъекция прототипа в синглтон?	Раньше мы уже рассматривали различия скоупов singleton и prototype в Spring Framework. Допустим ситуацию, когда в singleton-компонент внедряется зависимость со скоупом prototype - когда будет создан её объект?Если просто добавить к определению бина аннотацию @Scope(SCOPE_PROTOTYPE), и использовать этот бин в синглтоне через аннотацию @Autowired - будет создан только один объект. Потому что синглтон создается только однажды, и обращение к прототипу случится тоже однажды при его создании (при внедрении зависимости).Примитивный способ получать новый объект при каждом обращении - отказаться от @Autowired, и доставать его из контекста вручную. Для этого нужно вызывать context.getBean(MyPrototype.class).Воспользоваться автоматическим внедрением зависимостей можно через внедрение метода (паттерн «Команда»). Автовайрится не сам объект, а производящий его метод.Более красивый декларативный способ - правильно настроить определение бина. В аннотации @Scope кроме самого scopeName доступен второй параметр - proxyMode. По умолчанию его значение NO - прокси не создается. Но если указать INTERFACES или TARGET_CLASS, то под @Autowired будет внедряться не сам объект, а сгенерированный фреймворком прокси. И когда проксируемый бин имеет скоуп prototype, то объект внутри прокси будет пересоздаваться при каждом обращении.
Что такое жизненный цикл Spring Bean?	Beans - центральный объект заботы Spring Framework. За кулисами фреймворка с ними происходит множество процессов. Во многие из них можно вмешаться, добавив собственную логику в разные этапы жизненного цикла. Через следующие этапы проходит каждый отдельно взятый бин: 1. Инстанцирование объекта. Техническое начало жизни бина, работа конструктора его класса; 2. Установка свойств из конфигурации бина, внедрение зависимостей; 3. Нотификация aware-интерфейсов. BeanNameAware, BeanFactoryAware и другие. Мы уже писали о таких интерфейсах ранее. Технически, выполняется системными подтипами BeanPostProcessor, и совпадает с шагом 4; 4. Пре-инициализация - метод postProcessBeforeInitialization() интерфейса BeanPostProcessor; 5. Инициализация. Разные способы применяются в таком порядке: • Метод бина с аннотацией @PostConstruct из стандарта JSR-250 (рекомендуемый способ); • Метод afterPropertiesSet() бина под интерфейсом InitializingBean; • Init-метод. Для отдельного бина его имя устанавливается в параметре определения initMethod. В xml-конфигурации можно установить для всех бинов сразу, с помощью default-init-method; 6. Пост-инициализация - метод postProcessAfterInitialization() интерфейса BeanPostProcessor.  Когда IoC-контейнер завершает свою работу, мы можем кастомизировать этап штатного уничтожения бина. Как со всеми способами финализации в Java, при жестком выключении (kill -9) гарантии вызова этого этапа нет. Три альтернативных способа «деинициализации» вызываются в том же порядке, что симметричные им методы инициализации: 1. Метод с аннотацией @PreDestroy; 2. Метод с именем, которое указано в свойстве destroyMethod определния бина (или в глобальном default-destroy-method); 3. Метод destroy() интерфейса DisposableBean.Не следует путать жизненный цикл отдельного бина с жизненным циклом контекста и этапами подготовки фабрик бинов. О них мы поговорим в будущих публикациях.
Объясните работу BeanFactory в Spring.	это реализация паттерна Фабрика, его функицональность покрывает создание бинов. Так как эта фабрика знает многие об объектах приложения, то она может создавать связи между объектами на этапе создания экземпляра. Существует несколько реализаций BeanFactory, самая используемся - "org.springframework.beans.factory.xml.XmlBeanFactory". Она загружает бины на основе конфигурационного XML-файла. Чтобы создать XmlBeanFactory передайте конструктору InputStream, например:  BeanFactory factory = new XmlBeanFactory(new FileInputStream("myBean.xml"));  После этой строки фабрика знает о бинах, но их экземпляры еще не созданы. Чтобы инстанцировать бин нужно вызвать метод getBean().
В чем разница между BeanFactory и ApplicationContext?	BeanFactory - это базовый, компактный контейнер с ограниченной функциональностью. Его лучше всего использовать для простых задач или при использовании машин с низким ресурсом. ApplicationContext - это расширенный, более интенсивный контейнер с расширенным интерфейсом и дополнительными возможностями, такими как AOP. Этот контейнер лучше всего использовать, когда вам требуется больше функциональности, чем на заводе Bean, и у вас достаточно ресурсов, доступных на машине.
Как получить объекты ServletContext и ServletConfig внутри Spring Bean?	Доступны два способа для получения основных объектов контейнера внутри бина: Реализовать один из Spring*Aware (ApplicationContextAware, ServletContextAware, ServletConfigAware и др.) интерфейсов. Использовать автоматическое связывание @Autowired в спринг. Способ работает внутри контейнера спринг.
В чем роль ApplicationContext в Spring?	В то время, как BeanFactory используется в простых приложениях, Application Context - это более сложный контейнер. Как и BeanFactory он может быть использован для загрузки и связывания бинов, но еще он предоставляет:  возможность получения текстовых сообщений, в том числе поддержку интернационализации;  общий механизм работы с ресурсами;  события для бинов, которые зарегестрированы как слушатели.  Из-за большей функциональности рекомендуется использование Application Context вместо BeanFactory. Последний используется только в случаях нехватки ресурсов, например при разработке для мобильных устройств
Как получить ApplicationContext в интеграционном тесте?	Если вы используете JUnit 5, то вам нужно указать 2 аннотации: @ExtendWith(TestClass.class) — используется для указания тестового класса @ContextConfoguration(classes = JavaConfig.class) — загружает java/xml конфигурацию для создания контекста в тесте Можно использовать аннотацию @SpringJUnitConfig, которая сочетает обе эти аннотации.Для теста веб-слоя можно использовать аннотацию @SpringJUnitWebConfig.
Как завершить работу контекста в приложении?	Если это не веб-приложение, то есть 2 способа: Регистрация shutdown-hook с помощью вызова метода registerShutdownHook(), он также реализован в классе AbstractApplicationContext. Это предпочтительный способ. Можно вызвать метод close() из класса AbstractApplicationContext. В Spring Boot приложении: Spring Boot самостоятельно зарегистрирует shutdown-hook за вас.
Для чего нужен Component Scan?	Если вы понимаете как работает Component Scan, то вы понимаете Spring Первый шаг для описания Spring Beans это добавление аннотации — @Component, или @Service, или @Repository. Однако, Spring ничего не знает об этих бинах, если он не знает где искать их. То, что скажет Spring где искать эти бины и называется Component Scan. В @ComponentScan вы указываете пакеты, которые должны сканироваться. Spring будет искать бины не только в пакетах для сканирования, но и в их подпакетах.
Как вы добавите Component Scan в Spring Boot?	 @SpringBootApplication определяет автоматическое сканирование пакета, где находится класс Application Всё будет в порядке, ваш код целиком находится в указанном пакете или его подпакетах. Однако, если необходимый вам компонент находится в другом пакете, вы должны использовать дополнительно аннотацию @ComponentScan, где перечислите все дополнительные пакеты для сканирования
В чём отличие между @Component и @ComponentScan?	@Component и @ComponentScan предназначены для разных целей @Component помечает класс в качестве кандидата для создания Spring бина.@ComponentScan указывает где Spring искать классы, помеченные аннотацией @Component или его производной
Для чего используется аннотация @Bean?	В классах конфигурации Spring, @Bean используется для определения компонентов с кастомной логикой.
Почему для создания Spring beans рекомендуются интерфейсы?	Улучшенное тестирование. В тестах бин может быть заменен специальным объектом(mock или stub), который реализует интерфейс бина. Позволяет использовать механизм динамических прокси из JDK(например, при создании репозитория через Spring Data) Позволяет скрывать реализацию
Как внедряется singleton-бин?	Если в контейнере нет экземпляра бина, то вызывается @Bean-метод. Если экземпляр бина есть, то возвращается уже созданный бин.
В чём разница между @Bean и @Component?	@Bean используется в конфигурационных классах Spring. Он используется для непосредственного создания бина. @Component используется со всеми классами, которыми должен управлять Spring. Когда Spring видит класс с @Component, Spring определяет этот класс как кандидата для создания bean.
Как выглядит типичная реализция метода используя Spring?	Для типичного Spring-приложения нам необходимы следующие файлы:  Интерфейс, описывающий функционал приложения  Реализация интерфейса, содержащая свойства, сэттеры-гэттеры, функции и т.п.  Конфигурационный XML-файл Spring'а.  Клиентское приложение, которое использует функцию.
Можем ли мы применить @Autowired с не сеттерами и не конструкторами методами?	Да, конечно. @Autowired может использоваться вместе с конструкторами, сеттерами или любым другими методами. Когда Spring находит @Autowired на методе, Spring автоматически вызовет этот метод, после создания экземпляра бина. В качестве аргументов, будут подобраны подходящие объекты из контекста Spring.
Как внедрить простые значения в свойства в Spring?	Для этого можно использовать аннотацию @Value.Такие значения можно получать из property файлов, из бинов, и т.п. @Value("$some.key") public String stringWithDefaultValue; В эту переменную будет внедрена строка, например из property или из view.
Как вы решаете какой бин инжектить, если у вас несколько подходящих бинов. Расскажите о @Primary и @Qualifier?	Если есть бин, который вы предпочитаете большую часть времени по сравнению с другими, то используйте @Primary, и используйте @Qualifier для нестандартных сценариев. Если все бины имеют одинаковый приоритет, мы всегда будем использовать @Qualifier Если бин надо выбрать во время исполнения программы, то эти аннотации вам не подойдут. Вам надо в конфигурационном классе создать метод, пометить его аннотацией @Bean, и вернуть им требуемый бин.
Как произвести DI в private поле?	Вы можете использовать разные типы внедрения: Конструктор Сеттер Field-injection Value
Что такое связывание в Spring и расскажите об аннотации @Autowired?	Процесс внедрения зависимостей в бины при инициализации называется Spring Bean Wiring. Считается хорошей практикой задавать явные связи между зависимостями, но в Spring предусмотрен дополнительный механизм связывания @Autowired. может использоваться над полем или методом для связывания по типу. Чтобы аннотация заработала, необходимо указать небольшие настройки в конфигурационном файле спринг с помощью элемента context:annotation-config.
Опишите поведение аннотации @Autowired	 Контейнер определяет тип объекта для внедрения 2) Контейнер ищет бины в контексте(он же контейнер), которые соответствуют нужному типу 3) Если есть несколько кандидатов, и один из них помечен как @Primary, то внедряется он 4) Если используется аннотации @Autowire + Qualifier, то контейнер будет использовать информацию из @Qualifier, чтобы понять, какой компонент внедрять 5) В противном случае контейнер попытается внедрить компонент, основываясь на его имени или ID 6) Если ни один из способов не сработал, то будет выброшено исключение Контейнер обрабатывает DI с помощью AutowiredAnnotationBeanPostProcessor. В связи с этим, аннотация не может быть использована ни в одном BeanFactoryPP или BeanPP. Если внедряемый объект массив, коллекция, или map с дженериком, то Spring внедрит все бины подходящие по типу в этот массив(или другую структуру данных). В случае с map ключом будет имя бина. //параметр указывает, требуется ли DI @Authowired(required = true/false)
Как можно использовать аннотацию @Autowire и в чем отличие между способами?	Ниже перечислены типы DI, которые могут быть использованы в вашем приложении: Constructor DI Setter DI Field DI DI через конструктор считается самым лучшим способом, т.к. для него не надо использовать рефлексию, а также он не имеет недостатков DI через сеттер.DI через поле не рекомендуется использовать, т.к. для этого применяется рефлексия, снижающая производительность.DI через конструктор может приводить к циклическим зависимостям. Чтобы этого избежать, можно использовать ленивую инициализацию бинов или DI через сеттер.
Qualifier	Данная аннотация позволяет несколько специфицировать бин, который необходим для @Autowired. @Qualifier принимает один входной параметр — имя бина.  @Autowired@Qualifier("specialTestBean") private TestBean bean; * This source code was highlighted with Source Code Highlighter.  Эта конструкция будет искать в контексте бин с именем specialTestBean и в нашем примере мы соответственно получим исключение, так как TestBean объявлен с именем 'testBean' (@Service(«testBean»)).На основе @Qualifier можно создавать свои признаки бинов, об этом достаточно хорошо написано (и, что немаловажно, с огромным количеством примеров) в Spring Reference Manual.
Каковы различные типы автоматического связывания в Spring?	Существует четыре вида связывания в спринг: autowire byName, autowire byType, autowire by constructor, autowiring by @Autowired and @Qualifier annotations
Приведите пример часто используемых аннотаций Spring.	@Controller - класс фронт контроллера в проекте Spring MVC. @RequestMapping - позволяет задать шаблон маппинга URI в методе обработчике контроллера. @ResponseBody - позволяет отправлять Object в ответе. Обычно используется для отправки данных формата XML или JSON. @PathVariable - задает динамический маппинг значений из URI внутри аргументов метода обработчика. @Autowired - используется для автоматического связывания зависимостей в spring beans. @Qualifier - используется совместно с @Autowired для уточнения данных связывания, когда возможны коллизии (например одинаковых имен\типов). @Service - указывает что класс осуществляет сервисные функции. @Scope - указывает scope у spring bean. @Configuration, @ComponentScan и @Bean - для java based configurations. AspectJ аннотации для настройки aspects и advices, @Aspect, @Before, @After,@Around, @Pointcut и др.
Что такое профили? Какие у них причины использования?	При использовании Java-конфигурации вы можете использовать аннотацию @Profile.Она позволяет использовать разные настройки для Spring в зависимости от указанного профиля.Ее можно ставить на @Configuration и Component классы, а также на Bean методы. Profile("!test") //загружать со всеми прифилями, кроме теста @Bean("dataSource") @Profile("production") public DataSource jndiDataSource() {...} @Bean("dataSource") @Profile("development") public DataSource standaloneDataSource() {...}
Можем ли мы послать объект как ответ метода обработчика контроллера?	Да, это возможно. Для этого используется аннотация @ResponseBody. Так можно отправлять ответы в виде JSON, XML в restful веб сервисах.
Является ли Spring bean потокобезопасным?	По умолчанию бин задается как синглтон в Spring. Таким образом все публичные переменные класса могут быть изменены одновременно из разных мест. Так что - нет, не является. Однако поменяв область действия бина на request, prototype, session он станет потокобезопасным, но это скажется на производительности.
Почему иногда мы используем @ResponseBody, а иногда ResponseEntity?	ResponseEntity необходим, только если мы хотим кастомизировать ответ, добавив к нему статус ответа. Во всех остальных случаях будем использовать @ResponseBody. @GetMapping(value="/resource") @ResponseBody public Resource sayHello() { return resource; }  @PostMapping(value="/resource") public ResponseEntity createResource() { .... return ResponseEntity.created(resource).build(); } Стандартные HTTP коды статусов ответов, которые можно использовать. 200 — SUCCESS 201 — CREATED 404 — RESOURCE NOT FOUND 400 — BAD REQUEST 401 — UNAUTHORIZED5 00 — SERVER ERROR Для @ResponseBody единственные состояния статуса это SUCCESS(200), если всё ок и SERVER ERROR(500), если произошла какая-либо ошибка. Допустим мы что-то создали и хотим отправить статус CREATED(201). В этом случае мы используем ResponseEntity.
Как создать ApplicationContext в программе Java?	В независимой Java программе ApplicationContext можно создать следующим образом: AnnotationConfigApplicationContext - при использовании Spring в качестве автономного приложения можно создать инициализировать контейнер с помощью аннотаций.  ClassPathXmlApplicationContext - получает информацию из xml-файла, находящегося в classpath.   FileSystemXmlApplicationContext - получает информацию из xml-файла, но с возможностью загрузки файла конфигурации из любого места файловой системы.   XmlWebApplicationContext - получает информацию из xml-файла за пределами web-приложения.
Можем ли мы иметь несколько файлов конфигурации Spring?	С помощью указания contextConfigLocation можно задать несколько файлов конфигурации Spring. Параметры указываются через запятую или пробел:  Поддерживается возможность указания нескольких корневых файлов конфигурации Spring:  Файл конфигурации можно импортировать:
Как внедрить java.util.Properties в Spring Bean?	Для возможности использования Spring EL для внедрения свойств (properties) в различные бины необходимо определить propertyConfigure bean, который будет загружать файл свойств. Или через аннотации @Value
Как настраивается соединение с БД в Spring?	Используя datasource "org.springframework.jdbc.datasource.DriverManagerDataSource".
Как сконфигурировать JNDI не через datasource в applicationContext.xml?	Используя "org.springframework.jndi.JndiObjectFactoryBean"
Каким образом можно управлять транзакциями в Spring?	Транзакциями в Spring управляют с помощью Declarative Transaction Management (программное управление). Используется аннотация @Transactional для описания необходимости управления транзакцией. В файле конфигурации нужно добавить настройку transactionManager для DataSource.
Каким образом Spring поддерживает DAO?	Spring DAO предоставляет возможность работы с доступом к данным с помощью технологий вроде JDBC, Hibernate в удобном виде. Существуют специальные классы: JdbcDaoSupport, HibernateDaoSupport, JdoDaoSupport, JpaDaoSupport. Класс HibernateDaoSupport является подходящим суперклассом для Hibernate DAO. Он содержит методы для получения сессии или фабрики сессий. Самый популярный метод - getHibernateTemplate(), который возвращает HibernateTemplate. Этот темплейт оборачивает checked-исключения Hibernate в runtime-исключения, позволяя вашим DAO оставаться независимыми от исключений Hibernate.
Как интегрировать Spring и Hibernate?	Для интеграции Hibernate в Spring необходимо подключить зависимости, а так же настроить файл конфигурации Spring. Т.к. настройки несколько отличаются между проектами и версиями, то смотрите официальную документацию Spring и Hibernate для уточнения настроек для конкретных технологий.
Как задаются файлы маппинга Hibernate в Spring?	Через applicationContext.xml в web/WEB-INF
Как добавить поддержку Spring в web-приложение	Достаточно просто указать ContextLoaderListener в web.xml файле
В чем различие между web.xml и the Spring Context - servlet.xml?	web.xml — Метаданные и конфигурация любого веб-приложения, совместимого с Java EE. Java EE стандарт для веб-приложений.servlet.xml — файл конфигурации, специфичный для Spring Framework.
Что предпочитаете использовать для конфигурации Spring - xml или аннотирование?	Предпочитаю аннотации, если кодовая база хорошо описывается такими элементами, как @Service, @Component, @Autowired Однако когда дело доходит до конфигурации, у меня нет каких-либо предпочтений. Я бы оставил этот вопрос команде.
Можно ли использовать xyz.xml вместо applicationContext.xml?	ContextLoaderListener - это ServletContextListener, который инициализируется когда ваше web-приложение стартует. По-умолчанию оно загружает файл WEB-INF/applicationContext.xml. Вы можете изменить значение по-умолчанию, указав параметр contextConfigLocation.
Расскажите о Spring Security.	Проект Spring Security предоставляет широкие возможности для защиты приложения. Кроме стандартных настроек для аутентификации, авторизации и распределения ролей и маппинга доступных страниц, ссылок и т.п., предоставляет защиту от различных вариантов атак (например CSRF). Имеет множество различных настроек, но остается легким в использовании.
Этапы инициализации контекста Spring	1. Парсирование конфигурации и создание BeanDefinition 2. Настройка созданных BeanDefinition 3. Создание кастомных FactoryBean 4. Создание экземпляров бинов 5. Настройка созданных бинов
Этап Парсирование конфигурации и создание BeanDefinition	После выхода четвертой версии спринга, у нас появилось четыре способа конфигурирования контекста: Xml конфигурация — ClassPathXmlApplicationContext("context.xml")  Конфигурация через аннотации с указанием пакета для сканирования — AnnotationConfigApplicationContext("package.name")  Конфигурация через аннотации с указанием класса (или массива классов) помеченного аннотацией @Configuration -AnnotationConfigApplicationContext(JavaConfig.class). Этот способ конфигурации называется — JavaConfig.  Groovy конфигурация — GenericGroovyApplicationContext("context.groovy")  Цель первого этапа это создание всех BeanDefinition. BeanDefinition это специальный интерфейс, через который можно получить доступ к метаданным будущего бина. В зависимости от того, какая у вас конфигурация, будет использоваться тот или иной механизм парсирования конфигурации.  Xml конфигурация Для Xml конфигурации используется класс — XmlBeanDefinitionReader, который реализует интерфейс BeanDefinitionReader. Тут все достаточно прозрачно. XmlBeanDefinitionReader получает InputStream и загружает Document через DefaultDocumentLoader. Далее обрабатывается каждый элемент документа и если он является бином, то создается BeanDefinition на основе заполненных данных (id, name, class, alias, init-method, destroy-method и др.). Каждый BeanDefinition помещается в Map. Map хранится в классе DefaultListableBeanFactory. В коде Map выглядит вот так. private final Map<String, BeanDefinition> beanDefinitionMap = new ConcurrentHashMap<String, BeanDefinition>(64);  Конфигурация через аннотации с указанием пакета для сканирования или JavaConfig Конфигурация через аннотации с указанием пакета для сканирования или JavaConfig в корне отличается от конфигурации через xml. В обоих случаях используется класс AnnotationConfigApplicationContext. new AnnotationConfigApplicationContext(JavaConfig.class); или new AnnotationConfigApplicationContext("package.name"); Если заглянуть во внутрь AnnotationConfigApplicationContext, то можно увидеть два поля. private final AnnotatedBeanDefinitionReader reader; private final ClassPathBeanDefinitionScanner scanner; ClassPathBeanDefinitionScanner сканирует указанный пакет на наличие классов помеченных аннотацией @Component (или любой другой аннотацией которая включает в себя @Component). Найденные классы парсируются и для них создаются BeanDefinition.Чтобы сканирование было запущено, в конфигурации должен быть указан пакет для сканирования. @ComponentScan({"package.name"}) или <context:component-scan base-package="package.name"/>  AnnotatedBeanDefinitionReader работает в несколько этапов. Первый этап это регистрация всех @Configuration для дальнейшего парсирования. Если в конфигурации используются Conditional, то будут зарегистрированы только те конфигурации, для которых Condition вернет true. Conditional появилась в четвертой версии спринга. Она используется в случае, когда на момент поднятия контекста нужно решить, создавать бин/конфигурацию или нет. Причем решение принимает специальный класс, который обязан реализовать интерфейс Condition. Второй этап это регистрация специального BeanFactoryPostProcessor, а именно BeanDefinitionRegistryPostProcessor, который при помощи класса ConfigurationClassParser парсирует JavaConfig и создает BeanDefinition.  Groovy конфигурация Данная конфигурация очень похожа на конфигурацию через Xml, за исключением того, что в файле не XML, а Groovy. Чтением и парсированием groovy конфигурации занимается класс GroovyBeanDefinitionReader.
Этап Создание экземпляров бинов	Созданием экземпляров бинов занимается BeanFactory при этом, если нужно, делегирует это кастомным FactoryBean. Экземпляры бинов создаются на основе ранее созданных BeanDefinition.
HTTP это?	Протокол передачи гипертекста HTTP (Hypertext Transfer Protocol) - это протокол для распределённых информационных систем. Он был создан для обмена данными по сети Интернет. HTTP базируется на протоколе TCP/IP, который используется для передачи данных (HTML страниц, результатов запросов, изображений и т.д.) по сети Интернет. По умолчанию, TCP использует 80-й порт, другие порты могут быть настроены дополнительно. TCP предоставляет стандартизированный способ взаимосвязи компьютеров между собой. Спецификация HTTP определяет, как именно запросы клиента должны быть построены и отправлен на сервер и то, как сервер должен отвечать на эти запросы.
Основные свойства HTTP	HTTP является простым, но в то же время сильным протоколом благодаря трем свойствам:  HTTP не зависит от соединения Клиент HTTP (чаще всего, браузер), отправляет HTTP запрос и, после отправки запроса, отсоединяется от сервера и ждёт ответа. Сервер обрабатывает запрос и создаёт новое соединение с клиентом для отправки ответа.  HTTP не привязан к конкретному типу данныхЭто означает, что с помощью HTTP мы можем передавать любой тип данных, при условии, что и клиент и сервер "умеют" работать с данным типом данных. Сервер и клиент должны определить тип контента с помощью определённого типа MIME.  HTTP взаимодействует только через соединениеКлиент и сервер могут взаимодействовать друг с другом только с помощью запроса. После этого они "забывают" друг о друге. Из-за этой особенности протокола ни клиент, ни сервер не могут получить информацию "за пределами" запроса.  HTTP/1.0 использует соединение для каждого цикла "запрос/ответ".  HTTP/1.1 может использовать один или несколько циклов "запрос-ответ" внутри одного соединения.
Идемпотентный метод	Метод HTTP является идемпотентным, если повторный идентичный запрос, сделанный один или несколько раз подряд, имеет один и тот же эффект, не изменяющий состояние сервера. Другими словами, идемпотентный метод не должен иметь никаких побочных эффектов (side-effects), кроме сбора статистики или подобных операций. Корректно реализованные методы GET, HEAD, PUT и DELETE идемпотентны, но не метод POST. Также все безопасные методы являются идемпотентными.  Для идемпотентности нужно рассматривать только изменение фактического внутреннего состояния сервера, а возвращаемые запросами коды статуса могут отличаться: первый вызов DELETE вернёт код 200, в то время как последующие вызовы вернут код 404. Из идемпотентности DELETE неявно следует, что разработчики не должны использовать метод DELETE при реализации RESTful API с функциональностью удалить последнюю запись.
Базовая архитектура HTTP	В крайне упрощённой форме, архитектуру HTTP можно представить следующим образом:  Протокол HTTP основан клиент-серверной архитектуре, в которой браузер, "поисковик" и т.д. действует как "клиент", а веб-сервер - как "сервер". Клиент Клиент HTTP отправляет запрос на сервер в виде метода запроса, URL и версии протокола, после которых идёт MIME сообщение, которое и содержит модификаторы запроса, информацию о клиенте и, возможно контент соединения TCP/IP. Сервер Сервер HTTP отвечает на запрос строкой статуса, которая включает в себя версию протокола и код успешного выполнения, либо ошибки, после которого идёт сообщение MIME, содержащее информацию о сервере, мета-информацию о сущности и, возможно, контент самой сущности.
Стартовая строка HTTP	Cтартовая строка является обязательным элементом, так как указывает на тип запроса/ответа, заголовки и тело сообщения могут отсутствовать. Стартовые строки различаются для запроса и ответа. Строка запроса выглядит так: Метод URI HTTP/Версия протокола Пример запроса: GET /web-programming/index.html HTTP/1.1 Стартовая строка ответа сервера имеет следующий формат: HTTP/Версия КодСостояния [Пояснение] Например, на предыдущий наш запрос клиентом данной страницы сервер ответил строкой: HTTP/1.1 200 Ok
Заголовки HTTP	HTTP header обеспечивает необходимую информацию о запросе, ответе или об отправленном объекте в теле сообщения. Существует четыре типа HTTP сообщений header'a: General-header Применимы как для запроса, так и для ответа. Request-header Применимы только для запроса. Response-header Применимы только для ответа. Entity-header Определяют метаинформацию об объекте, переданном в теле, либо, если сообщение не содержит тела, о ресурсе, определённом запросом.
Тело сообщения HTTP	Это опциональный (не обязательный) элемент HTTP сообщения, который содержит объект, связанный с запросом, либо с ответом. Если объект тела связан с обычным Content-Type и Content-Length, то строки элемента header определяют тип конкретного объекта. Тело сообщения содержит данные HTTP запроса (тип данных и т.д.), а HTTP ответ содержит данные, полученные от сервера (файлы, изображения и т.д.).
Метод запроса http	Данный элемент указывает метод, который должен быть вызван на стороне сервера по указанному идентификатору URI. В HTTP существует восемь методов: HEAD Используется для получения строки статуса и заголовка от сервера по URI. Не изменяет данные. GET Используется для получения данных от сервера по указанному URI. Не изменяет данные. POST Используется для отправки данных на сервер (например информации о разработчике и т.д.) с помощью форм HTML. PUT Замещает все предыдущие данные на ресурсе новыми загруженными данными. DELETE Удаляет все текущие данные на ресурсе, определённом URI. CONNECT Устанавливает туннельное соединение с сервером по указанному URI. OPTIONS Описывает свойства соединения для указанного ресурса. TRACE Предоставляет сообщение, содержащее обратный трейс расположения указанного в URI ресурса.  URI (Uniform Resource Identifier) - это идентификатор ресурса на который отправляется запрос.
Чем отличаются HTTP и HTTPS?	HTTP (HyperText Transfer Protocol - "протокол передачи гипертекста") - протокол прикладного уровня передачи данных (изначально - в виде гипертекстовых документов в формате HTML, в настоящий момент используется для передачи произвольных данных). Основой HTTP является технология "клиент-сервер", то есть предполагается существование потребителей (клиентов), которые инициируют соединение и посылают запрос, и поставщиков (серверов), которые ожидают соединения для получения запроса, производят необходимые действия и возвращают обратно сообщение с результатом. HTTPS (HyperText Transfer Protocol Secure) - расширение протокола HTTP, поддерживающее шифрование. Данные, передаваемые по протоколу HTTPS, "упаковываются" в криптографический протокол SSL или TLS. В отличие от HTTP, для HTTPS по умолчанию используется TCP-порт 443.
Чем отличаются методы get и post?	GET передает данные серверу используя URL, а POST передает данные, используя тело HTTP запроса. Длина URL'а ограничена 1024 символами, что и будет верхним пределом для данных, которые можно отослать GET'ом. POST может отправлять гораздо большие объемы данных. Кроме того, передача данных методом POST более безопасна, чем методом GET, так как секретные данные (например пароль) не отображаются напрямую в web-клиенте пользователя (в отличии от URL, который виден почти всегда).
Что такое www?	Всемирная паутина (сокращенно World Wide Web или WWW) - это единство информационных ресурсов, которые связаны между собой средствами телекоммуникаций и основаны на гипертекстовом представлении данных, разбросанных по всему миру.
Что такое w3c?	W3C - абревиатура, которая обозначает Консорциум мировой сети (World Wide Web Consortium), организацию, цель которой - разработка и внедрение единых стандартов работы Интернета. Главная задача - это постоянное внедрение принципов работы мировой сети, главным из которых является полная совместимость всех материалов, размещенных в сети, с програмным и аппаратным обеспечением пользователей.
Что такое URI?	URI, Uniform Resource Identifier (унифицированный идентификатор ресурса) - последовательность символов, идентифицирующая физический или абстрактный ресурс, который не обязательно должен быть доступен через сеть Интернет, причем, тип ресурса, к которому будет получен доступ, определяется контекстом и/или механизмом. Как правило делится на URL и URN, поэтому URL и URN это составляющие URI.
Что такое URL?	URL, Uniform Resource Locator (единообразный локатор (определитель местонахождения) ресурса). Также можно встретить более раннюю расшифровку аббревиатуры URL - Universal Resource Locator (универсальный локатор ресурсов) - другими словами это указатель размещения сайта в интернете, помимо идентификации ресурса, определяет местонахождение ресурса и способ обращения к нему. URL служит стандартизированным способом записи адреса ресурса в сети Интернет, URL-адрес содержит доменное имя и указание пути к странице, включая название файла этой страницы.
Что такое URN?	URN, Unifrorm Resource Name (унифицированное имя ресурса) - является уникальным именем объекта. URN включает в себя название пространства имен и идентификатора в этом пространстве. URN является частью концепции URI. Имена URN, в отличие от URL, не включают в себя указания на местонахождение и способ обращения к ресурсу. Смысл URN в том, что он определяет только название конкретного предмета, который может находится во множестве конкретных мест.
Что такое интернет протокол IP?	Интернет протокол (Internet Protocol, IP) - протокол сетевого уровня сетевой модели OSI (Open Systems Interconnection) и относится к протоколам, которые организуют соединения на основе коммутации каналов. Это один из самых распространенных протоколов является низкоуровневым маршрутизирующим сетевым протоколом, разбивающим данные на небольшие пакеты и посылающим их через сеть по определенному адресу, что не гарантирует доставки всех этих пакетов по этому адресу.
Что такое протокол управления ТСР?	ТСР, Transmission Control Protocol (Протокол Управления Передачей) - является сетевым протоколом более высокого уровня, обеспечивающим связывание, сортировку и повторную передачу пакетов, чтобы обеспечить надежную доставку данных.
Что такое TCP/IP?	Стек протоколов TCP/IP - набор сетевых протоколов передачи данных, используемых в сетях, включая сеть Интернет. Название TCP/IP происходит из двух наиважнейших протоколов семейства - Transmission Control Protocol (TCP) и Internet Protocol (IP), которые были разработаны и описаны первыми в данном стандарте.
Что такое FTP?	FTP (File Transfer Protocol - протокол передачи файлов) - стандартный протокол, предназначенный для передачи файлов по TCP-сетям (например, Интернет). Использует 21й порт. FTP часто используется для загрузки сетевых страниц и других документов с частного устройства разработки на открытые сервера хостинга.
Что такое UDP?	UDP (User Datagram Protocol - протокол пользовательских датаграмм) - один из ключевых элементов TCP/IP, набора сетевых протоколов для Интернета. С UDP компьютерные приложения могут посылать сообщения (в данном случае называемые датаграммами) другим хостам по IP-сети без необходимости предварительного сообщения для установки специальных каналов передачи или путей данных.
Что такое протокол передачи данных, какие вы знаете?	Протокол передачи данных - набор соглашений интерфейса логического уровня, которые определяют обмен данными между различными программами. Эти соглашения задают единообразный способ передачи сообщений и обработки ошибок при взаимодействии программного обеспечения разнесённой в пространстве аппаратуры, соединённой тем или иным интерфейсом. HTTP (Hyper Text Transfer Protocol) - это протокол передачи гипертекста. Протокол HTTP используется при пересылке Web-страниц с одного компьютера на другой. FTP (File Transfer Protocol) - это протокол передачи файлов со специального файлового сервера на компьютер пользователя. FTP дает возможность абоненту обмениваться двоичными и текстовыми файлами с любым компьютером сети. Установив связь с удаленным компьютером, пользователь может скопировать файл с удаленного компьютера на свой или скопировать файлсо своего компьютера на удаленный. POP (Post Office Protocol) - это стандартный протокол почтового соединения. Серверы POP обрабатывают входящую почту, а протокол POP предназначен для обработки запросов на получение почты от клиентских почтовых программ. SMTP (Simple Mail Transfer Protocol) - протокол, который задает набор правил для передачи почты. Сервер SMTP возвращает либо подтверждение о приеме, либо сообщение об ошибке, либо запрашивает дополнительную информацию.
Что такое web server?	Веб-сервер - сервер, принимающий HTTP-запросы от клиентов, обычно веб-браузеров, и выдающий им HTTP-ответы, как правило, вместе с HTML-страницей, изображением, файлом, медиа-потоком или другими данными.
Что такое web приложение?	Веб-приложение - клиент-серверное приложение, в котором клиентом выступает браузер, а сервером - веб-сервер. Логика веб-приложения распределена между сервером и клиентом, хранение данных осуществляется, преимущественно, на сервере, обмен информацией происходит по сети. Одним из преимуществ такого подхода является тот факт, что клиенты не зависят от конкретной операционной системы пользователя, поэтому веб-приложения являются межплатформенными сервисами.
Что такое application server?	Сервер приложений (application server) - это программная платформа (фреймворк), предназначенная для эффективного исполнения процедур (программ, механических операций, скриптов), которые поддерживают построение приложений. Сервер приложений действует как набор компонентов, доступных разработчику программного обеспечения через API (Интерфейс прикладного программирования), который определен самой платформой.
Чем отличаются web server и application server?	Сервер приложений - сервер, исполняющий некоторые прикладные программы. Веб-сервер - это сервер, принимающий HTTP-запросы от клиентов, обычно веб-браузеров, и выдающий им HTTP-ответы.
Что такое MIME type?	MIME (Multipurpose Internet Mail Extension, Многоцелевые расширения почты Интернета) - спецификация для передачи по сети файлов различного типа: изображений, музыки, текстов, видео, архивов и др. Указание MIME-типа используется в HTML обычно при передаче данных форм и вставки на страницу различных объектов.
Дайте определение понятиям "авторизация" и "аутентификация", в чем их различия?	Аутентификация - это проверка соответствия субъекта и того, за кого он пытается себя выдать, с помощью некой уникальной информации (отпечатки пальцев, цвет радужки, голос и тд.), в простейшем случае - с помощью имени входа и пароля. Авторизация - это проверка и определение полномочий на выполнение некоторых действий (например, чтение файла /var/mail/eltsin) в соответствии с ранее выполненной аутентификацией.
За что отвечает JVM:	Загрузка, проверка и исполнение байт кода; Предоставление среды выполнения для выполнения байт-кода; Управление памятью и очисткой мусора (Garbage collection); Виртуальная машина Java (Java Virtual Machine) - это механизм, предоставляющий среду выполнения для управления Java-кодом или приложениями. Виртуальная машина является независимой оболочкой исполнения кода, благодаря которой возможен её запуск на любой ОС, без влияния ОС на выполняемую программу. JVM работает с 2мя типами данных: примитивные типы (primitive types) и ссылочные типы (reference types). Примитивы JVM работает с примитивными значениями (целыми числами и числами с плавающей точкой). По сути, JVM - это 32-битная машина. Типы long и double, которые являются 64-битными, поддерживаются изначально, но занимают две единицы памяти в frame's local или стеке операндов, поскольку каждая единица составляет 32 бита. Типы boolean, byte, short и char имеют расширенный знак (кроме char с нулевым расширением) и работают как 32-разрядные целые числа, так же, как и типы int. Меньшие типы имеют только несколько специфических для типа инструкций для загрузки, хранения и преобразования типов. boolean значение работает как 8-битное byte значения, где 0 представляет значение false, а 1 - значение true. Типы ссылок и значения Существует три типа ссылочных типов: типы классов, типы массивов и типы интерфейсов. Их значения являются ссылками на динамически создаваемые экземпляры классов, массивы или экземпляры классов, которые реализуют интерфейсы соответственно.
Что такое ORM?	ORM (англ. Object-relational mapping, рус. Объектно-реляционное отображение) - технология программирования, которая связывает базы данных с концепциями объектно-ориентированных языков программирования, создавая "виртуальную объектную базу данных".
Какие преимущства от использования Hibernate?	Устраняет множество повторяющегося кода, который постоянно преследует разработчика при работе с JDBC. Скрывает от разработчика множество кода, необходимого для управления ресурсами и позволяет сосредоточиться на бизнес логике.  Поддерживает XML так же как и JPA аннотации, что позволяет сделать реализацию кода независимой.  Предоставляет собственный мощный язык запросов (HQL), который похож на SQL. Стоит отметить, что HQL полностью объектно-ориентирован и понимает такие принципы, как наследование, полиморфизм и ассоциации (связи).  Hibernate легко интегрируется с другими Java EE фреймворками, например, Spring Framework поддерживает встроенную интеграцию с Hibernate.  Поддерживает ленивую инициализацию используя proxy объекты и выполняет запросы к базе данных только по необходимости.  Поддерживает разные уровни cache, а следовательно может повысить производительность.  Важно, что Hibernate может использовать чистый SQL, а значит поддерживает возможность оптимизации запросов и работы с любым сторонним вендором БД.  Hibernate - open source проект. Благодаря этому доступны тысячи открытых статей, примеров, а так же документации по использованию фреймворка.
Как Hibernate помогает в программировании?	Hibernate реализует ряд фичь которые значительно упрощают работу разработчика.  Одной из таких фичь является то, что hibernate позволяет разработчику избежать написания большинства SQL запросов (они уже реализованы , вам надо просто использовать методы которые предоставляет фреймворк).  Под бортом у Hibernate есть куча полезных инструментов которые значительно ускоряют работу приложения, самыми примечательными из них являются двухуровневое кэширования и тонкие настройки lazy и fetch изъятия.  Сам генерирует таблицы в базу данных
Какие преимущества Hibernate над JDBC?	Hibernate имеет ряд преимуществ перед JDBC API:  Hibernate удаляет множество повторяющегося кода из JDBC API, а следовательно его легче читать, писать и поддерживать.  Hibernate поддерживает наследование, ассоциации и коллекции, что не доступно в JDBC API.  Hibernate неявно использует управление транзакциями. Большинство запросов нельзя выполнить вне транзакции. При использовании JDBC API для управления транзакциями нужно явно использовать commit и rollback.  JDBC API throws SQLException, которое относится к проверяемым исключениям, а значит необходимо постоянно писать множество блоков try-catch. В большинстве случаев это не нужно для каждого вызова JDBC и используется для управления транзакциями. Hibernate оборачивает исключения JDBC через непроверяемые JDBCException или HibernateException, а значит нет необходимости проверять их в коде каждый раз. Встроенная поддержка управления транзакциями в Hibernate убирает блоки try-catch.  Hibernate Query Language (HQL) более объектно ориентированный и близкий к Java язык программирования, чем SQL в JDBC.  Hibernate поддерживает кэширование, а запросы JDBC - нет, что может понизить производительность.  Hibernate предоставляет возможность управления БД (например создания таблиц), а в JDBC можно работать только с существующими таблицами в базе данных.  Конфигурация Hibernate позволяет использовать JDBC вроде соединения по типу JNDI DataSource для пула соединений. Это важная фича для энтерпрайз приложений, которая полностью отсутствует в JDBC API.  Hibernate поддерживает аннотации JPA, а значит код является переносимым на другие ORM фреймворки, реализующие стандарт, в то время как код JDBC сильно привязан к приложению.
Что такое конфигурационный файл Hibernate?	Файл конфигурации Hibernate содержит в себе данные о базе данных и необходим для инициализации SessionFactory. В .xml файле необходимо указать вендора базы данных или JNDI ресурсы, а так же информацию об используемом диалекте, что поможет hibernate выбрать режим работы с конкретной базой данных.
Способы конфигурации работы с Hibernate.	Существует четыре способа конфигурации работы с Hibernate   используя аннотации; hibernate.cfg.xml; hibernate.properties; persistence.xml.  Самый частый способ конфигурации: через аннотации и файл persistence.xml, что касается файлов hibernate.properties и hibernate.cfg.xml, то hibernate.cfg.xml главнее (если в приложение есть оба файла, то принимаются настройки из файла hibernate.cfg.xml). Конфигурация аннотациями, хоть и удобна, но не всегда возможна, к примеру, если для разных баз данных или для разных ситуаций вы хотите иметь разные конфигурацию сущностей, то следует использовать xml файлы конфигураций.
Что такое Hibernate mapping file?	Файл отображения (mapping file) используется для связи entity бинов и колонок в таблице базы данных. В случаях, когда не используются аннотации JPA, файл отображения .xml может быть полезен (например при использовании сторонних библиотек).
Что такое Переходные объекты (Transient Objects)?	Экземпляры долгоживущих классов, которые в настоящее время не связаны c Cессией. Они, возможно, были инициализированы в приложении и еще не сохранены, или же они были инициализированы закрытой Cессией.
Что такое постоянные объекты (Persistent objects)?	Короткоживущие, однопоточные объекты, содержащие постоянное состояние и бизнес-функции. Это могут быть простые Java Beans/POJOs (Plain Old Java Object). Они связаны только с одной Cессией. После того, как Cессия закрыта, они будут отделены и свободны для использования в любом протоколе прикладного уровня (например, в качестве объектов передачи данных в и из представления).
Что такое TransactionFactory?	Фабрика для экземпляров Transaction. Интерфейс не открыт для приложения, но может быть расширен или реализован разработчиком.
Что такое Трансакция (Transaction)?	Однопоточный, короткоживущий объект, используемый приложением для указания atomic переменных работы. Он абстрагирует приложение от основных JDBC, JTA или CORBA трансакций. Сессия может охватывать несколько Трансакций в некоторых случаях. Тем не менее, разграничение transaction, также используемое в основах API или Transaction, всегда обязателно.
Какие существуют стратегии загрузки объектов в Hibernate?	Существуют следующие типа fetch'a:  Join fetching: hibernate получает ассоциированные объекты и коллекции одним SELECT используя OUTER JOIN  Select fetching: использует уточняющий SELECT чтобы получить ассоциированные объекты и коллекции. Если вы не установите lazy fetching определив lazy="false", уточняющий SELECT будет выполнен только когда вы запрашиваете доступ к ассоциированным объектам  Subselect fetching: поведение такое же, как у предыдущего типа, за тем исключением, что будут загружены ассоциации для все других коллекций, "родительским" для которых является сущность, которую вы загрузили первым SELECT'ом.  Batch fetching: оптимизированная стратегия вида select fetching. Получает группу сущностей или коллекций в одном SELECT'е.
Какие ключевые интерфейсы использует Hibernate?	Существует пять ключевых интерфейсов которые используются в каждом приложении связанном с Hibernate: Session interface; SessionFactory interface; Configuration interface; Transaction interface; Query and Criteria interfaces.
Какая роль интерфейса Session в Hibernate?	Объект Hibernate Session является связью между кодом java приложения и hibernate. Это основной интерфейс для выполнения операций с базой данных. Жизненный цикл объекта session связан с началом и окончанием транзакции. Этот объект предоставляет методы для CRUD (create, read, update, delete) операций для объекта персистентности. С помощью этого экземпляра можно выполнять HQL, SQL запросы и задавать критерии выборки. (персистентный объект - объект который уже находится в базе данных; объект запроса - объект который получается когда мы получаем результат запроса в базу данных, именно с ним работает приложение). Обьект Session можно получить из SessionFactory :  Session session = sessionFactory.openSession();  Роль интерфейса Session: является оберткой для jdbc подключения к базе данных; является фабрикой для transaction (согласно официальной документации transaction - аllows the application to define units of work, что , по сути, означает что transaction определяет границы операций связанных с базой данных). является хранителем обязательного кэша первого уровня.
Какая роль интерфейса SessionFactory в Hibernate?	SessionFactory является фабрикой классов и используется для получения объектов session. SessionFactory отвечает за считывание параметров конфигурации Hibernate и подключение к базе данных. Обычно в приложении имеется только один экземпляр SessionFactory и потоки, обслуживающие клиентские запросы, получают экземпляры session с помощью объекта SessionFactory. Внутреннее состояние SessionFactory неизменно (immutable). Internal state (внутреннее состояние) включает в себя все метаданные об Object/ Relational Mapping и задается при создании SessionFactory. SessionFactory также предоставляет методы для получения метаданных класса и статистики, вроде данных о втором уровне кэша, выполняемых запросах и т.д. SessionFactory кэширует мета-дату и SQL запросы которые часто используются приложением во время работы. Так же оно кэширует информацию которая была получена в одной из transaction и может быть использована и в других транзакциях. Обьект SessionFactory можно получить следующим обращением: SessionFactory sessionFactory = configuration. buildSessionFactory();
Является ли Hibernate SessionFactory потокобезоспансым?	Т.к. объект SessionFactory immutable (неизменяемый), то да, он потокобезопасный. Множество потоков может обращаться к одному объекту одновременно.
В чем разница между openSession и getCurrentSession?	Hibernate SessionFactory getCurrentSession() возвращает сессию, связанную с контекстом. Но для того, чтобы это работало, нам нужно настроить его в конфигурационном файле hibernate. Так как этот объект session связан с контекстом hibernate, то отпадает необходимость к его закрытию. Объект session закрывается вместе с закрытием SessionFactory.  <property name="hibernate.current_session_context_class">thread</property>  Метод Hibernate SessionFactory openSession() всегда создает новую сессию. Мы должны обязательно контролировать закрытие объекта сеанса по завершению всех операций с базой данных. Для многопоточной среды необходимо создавать новый объект session для каждого запроса. Существует еще один метод openStatelessSession(), который возвращает session без поддержки состояния. Такой объект не реализует первый уровень кэширования и не взаимодействует с вторым уровнем. Сюда же можно отнести игнорирование коллекций и некоторых обработчиков событий. Такие объекты могут быть полезны при загрузке больших объемов данных без удержания большого кол-ва информации в кэше.
Какие типы коллекций представлены в Hibernate?	Bag, Set, List, Map, Array.
Какие типы менеджмента transaction поддерживаются в Hibernate?	Hibernate взаимодействует с БД через JDBC-соединение. Таким образом он поддерживает управляемые и не управляемые транзакции. Неуправляемые транзакции в web-контейнере:  <bean id="transactionManager" class="org.springframework. orm. hibernate. HibernateTransactionManager" <property name="sessionFactory"> <ref local="sessionFactory"/> </property> </bean>  Управляемые транзакции на сервере приложений, использующий JTA:  <bean id="transactionManager" class="org.springframework. transaction. jtaTransactionManager."> <property name="sessionFactory"> <ref local="sessionFactory" /> </property> </bean>
Что собой являет коллекция типа Bag и зачем она используется?	Своей реализации тип коллекции Bag очень напоминает Set, разница состоит в том, что Bag может хранить повторяющиеся значения. Bag хранит непроиндексированный список элементов. Большинство таблиц в базе данных имеют индексы отображающие положение элемента данных один относительно другого, данные индексы имеют представление в таблице в виде отдельной колонки. При объектно-реляционном маппинге, значения колонки индексов мапится на индекс в Array, на индекс в List или на key в Map. Если вам надо получить коллекцию объектов не содержащих данные индексы, то вы можете воспользоваться коллекциями типа Bag или Set (коллекции содержат данные в неотсортированном виде, но могут быть отсортированы согласно запросу).
Какие типы кэша используются в Hibernate?	Hibernate использует 2 типа кэша: кэш первого уровня и кэш второго уровня. Кэш первого уровня ассоциирован с объектом сесии, в то время, как кэш второго уровня ассоциирован с объектом фабрики сессий. По-умолчанию Hibernate использует кэш первого уровня для каждой операции в транзакции. В первую очередь кэш используется чтобы уменьшить количество SQL-запросов. Например если объект модифицировался несколько раз в одной и той же транзакции, то Hibernate сгенерирует только один UPDATE.  Если сессия обычно (у нас точно) привязана к транзакции и закрывается каждый раз по ее окончании, то SessionFactory создается один раз на все приложение. Этот кэш и считается кэшем второго уровня, но по умолчанию он не работает - его надо включать. Кэш второго уровня - это прослойка, общая для всех сессий. То есть одна сессия извлекла сущность, а другая может получить к этой сущности потом доступ. Очевидно, что с такой прослойкой есть проблема - ее данные могут устареть. В базе данные одни, а в кэше второго уровня - другие. Особенно, если помимо нашего приложения базу обновляет еще какой-то процесс. Но иногда все-таки от кэша второго уровня есть польза. Например, если наша сущность в принципе не редактируема (такой вот задан функционал), а доступна только для чтения. В этом случае почему бы не дать возможность всем сессиям брать готовую сущность, а не извлекать ее из базы каждый раз заново. Все равно сущность не устареет (так как она неизменяемая).  Таким образом если результат запроса находится в кэше, мы потенциально уменьшаем количество transaction к БД. EHCache - это быстрый и простой кэш. Он поддерживает read-only и read/write кэширование, а так же кэширование в память и на диск. Но не поддерживает кластеризацию. OSCache - это другая opensource реализация кэша. Помимо всего, что поддерживает EHCache, эта реализация так же поддерживает кластеризацию через JavaGroups или JMS. SwarmCache - это просто cluster-based решение, базирующееся на JavaGroups. Поддерживает read-only и нестрогое read/write кэширование. Этот тип кэширование полезен, когда количество операций чтения из БД превышает количество операций записи. JBoss TreeCache - предоставляет полноценный кэш транзакции.
Какие существуют типы стратегий кэша?	Read-only: эта стратегия используется когда данные вычитываются, но никогда не обновляется. Самая простая и производительная стратегия  Read/write: может быть использована, когда данные должны обновляться.  Нестрогий read/write: эта стратегия не гарантирует, что две транзакции не модифицируют одни и те же данные синхронно.  Transactional: полноценное кэширование transaction. Доступно только в JTA окружении.
Что вы знаете о кэширование в Hibernate? Объясните понятие кэш первого уровня в Hibernate?	Hibernate использует кэширование, чтобы сделать наше приложение быстрее. Кэш Hibernate может быть очень полезным в получении высокой производительности приложения при правильном использовании. Идея кэширования заключается в сокращении количества запросов к базе данных.  Кэш первого уровня - это кэш Сессии (Session), который является обязательным. Через него проходят все запросы. Перед тем, как отправить объект в БД, сессия хранит объект за счёт своих ресурсов. А именно: Hibernate хранит отслеживаемые сущности в Map, ключами которой являются id сущностей, а значениями - сами объекты-сущности. Если мы извлекаем из базы сущность по id с помощью EntityManager.find(), то сущность помещается в этот Map и хранится в нем до закрытия сессии. И при повторном find() SQL-команда select в базе данных выполнена не будет. Hibernate возьмет эту сущность из Map - карты отслеживаемых сущностей. В том случае, если мы выполняем несколько обновлений объекта, Hibernate старается отсрочить (насколько это возможно) обновление для того, чтобы сократить количество выполненных запросов. Если мы закроем сессию, то все объекты, находящиеся в кэше теряются, а далее - либо сохраняются, либо обновляются.
Как настраивается кэш второго уровня в Hibernate?	Чтобы указать кэш второго уровня нужно определить hibernate.cache.provider_class в hibernate.cfg.xml:  <hibernate-configuration> <session-factory> <property name="hibernate.cache.provider_class">org. hibernate, cache. EHCacheProvider</property> </session-factory> </hibernate-configuration>  По-умолчанию используется EHCache. Чтобы использвать кэш запросов нужно его включить установив свойство hibernate.cache.use_query_cache в true в hibernate.properties.  Использовать аннотацию @Cache и указание настройки стратегии кэширование над entity bean.  import org.hibernate.annotations.Cache; import org.hibernate.annotations.CacheConcurrencyStrategy; @Entity @Table(name = "ADDRESS") @Cache(usage=CacheConcurrencyStrategy.READ_ONLY, region="employee") public class Address { }
Какая разница в работе методов load(); и get();?	Hibernate session обладает различными методами для загрузки данных из базы данных. Наиболее часто используемые методы для этого - get() и load().  Метод load(); обычно используется когда в не уверен что запрашиваемый объект уже находится в базе данных. Если объект не найден, то метод кидает исключение Если объект найден — метод возвращает прокси объект, который является ссылкой на объект находящийся в базе данных (запрос в базу данных еще не был осуществлен, своего рода lazy изъятие), непосредственный запрос к базе данных когда мы непосредственно обращаемся к необходимому объекту через прокси объект.  Метод get(); используется тогда, вы на 100 процентов не уверены есть ли запрашиваемый объект в базе данных. В случае обращение к несуществующему объекту, метод get(); вернет null. В случае нахождения объект, метод get(); вернет сам объект и запрос в базу данных будет произведен немедленно.
Каковы существуют различные состояния у entity bean?	Transient: состояние, при котором объект никогда не был связан с какой-либо сессией и не является персистентностью. Этот объект находится во временном состоянии. Объект в этом состоянии может стать персистентным при вызове метода save(), persist() или saveOrUpdate(). Объект персистентности может перейти в transient состоянии после вызова метода delete().   Persistent: когда объект связан с уникальной сессией он находится в состоянии persistent (персистентности). Любой экземпляр, возвращаемый методами get() или load() находится в состоянии persistent.  Detached: если объект был персистентным, но сейчас не связан с какой-либо сессией, то он находится в отвязанном (detached) состоянии. Такой объект можно сделать персистентным используя методы update(), saveOrUpdate(), lock() или replicate(). Состояния transient или detached так же могут перейти в состояние persistent как новый объект персистентности после вызова метода merge().
Что произойдет, если будет отсутствовать конструктор без аргументов у Entity Bean?	Hibernate использует рефлексию для создания экземпляров Entity бинов при вызове методов get() или load(). Для этого используется метод Class.newInstance(), который требует наличия конструктора без параметров. Поэтому, в случае его отсутствия, вы получите ошибку HibernateException.
Как используется вызов метода Hibernate Session merge()?	Hibernate merge() может быть использован для обновления существующих значений, однако этот метод создает копию из переданного объекта сущности и возвращает его. Возвращаемый объект является частью контекста персистентности и отслеживает любые изменения, а переданный объект не отслеживается.
В чем разница между Hibernate save(), saveOrUpdate() и persist()?	Hibernate save() используется для сохранения сущности в базу данных. Проблема с использованием метода save() заключается в том, что он может быть вызван без транзакции. А следовательно если у нас имеется отображение нескольких объектов, то только первичный объект будет сохранен и мы получим несогласованные данные. Также save() немедленно возвращает сгенерированный идентификатор. Hibernate persist() аналогичен save() с транзакцией. persist() не возвращает сгенерированный идентификатор сразу. Hibernate saveOrUpdate() использует запрос для вставки или обновления, основываясь на предоставленных данных. Если данные уже присутствуют в базе данных, то будет выполнен запрос обновления. Метод saveOrUpdate() можно применять без транзакции, но это может привести к аналогичным проблемам, как и в случае с методом save().
Что такое Lazy fetching(изъятие) в Hibernate?	Тип изьятия Lazy, в Hibernate, связан с листовыми(дочерними) сущностями и определяют политику совместного изъятия, если идет запрос на изъятие сущности родителя. Простой пример: Есть сущность Дом. Он хранит информацию о своем номере, улице, количество квартир и информацию о семьях которые живут в квартирах, эти семьи формируют дочернюю сущность относительно сущности Дом. Когда мы запрашиваем информацию о Доме, нам может быть совершенно ненужным знать информацию семьях которые в нем проживают, тут нам на помощь приходит lazy(ленивое) изъятие(fetching) которая позволяет сконфигурировать сущность Дом, чтобы информацию о семьях подавалась только по востребованию, это значительно облегчает запрос и ускоряет работу приложения.
В чем разница между sorted collection и ordered collection? Какая из них лучше?	При использовании алгоритмов сортировки из Collection API для сортировки коллекции, то он вызывает отсортированный список (sorted list). Для маленьких коллекций это не приводит к излишнему расходу ресурсов, но на больших коллекциях это может привести к потери производительности и ошибкам OutOfMemory. Так же entity бины должны реализовывать интерфейс Comparable или Comparator для работы с сортированными коллекциями. При использовании фреймворка Hibernate для загрузки данных из базы данных мы можем применить Criteria API и команду order by для получения отсортированного списка (ordered list). Ordered list является лучшим выбором к sorted list, т.к. он использует сортировку на уровне базы данных. Она быстрее и не может привести к утечке памяти.  Пример запроса к БД для получения ordered list: List<Employee> empList = session.createCriteria(Employee.class) .addOrder(Order.desc("id")).list();
Как реализованы Join'ы Hibernate?	Существует несколько способов реализовать связи в Hibernate.  Использовать ассоциации, такие как one-to-one, one-to-many, many-to-many.  Использовать в HQL запросе команду JOIN. Существует другая форма «join fetch«, позволяющая загружать данные немедленно (не lazy).  Использовать чистый SQL запрос с командой join.
Почему мы не должны делать Entity class как final?	Хибернейт использует прокси классы для ленивой загрузки данных (т.е. по необходимости, а не сразу). Это достигается с помощью расширения entity bean и, следовательно, если бы он был final, то это было бы невозможно. Ленивая загрузка данных во многих случаях повышает производительность, а следовательно важна.
Что вы знаете о HQL и каковы его преимущества?	Hibernate Framework поставляется с мощным объектно-ориентированным языком запросов - Hibernate Query Language (HQL). Он очень похож на SQL, за исключением, что в нем используются объекты вместо имен таблиц, что делает язык ближе к объектно-ориентированному программированию. HQL является регистронезависимым, кроме использования в запросах имен java переменных и классов, где он подчиняется правилам Java. Например, SelECt то же самое, что и select, но com.blogspot.jsehelper.MyClass отличен от com.blogspot.jsehelper.MyCLASS. Запросы HQL кэшируются (это как плюс так и минус).
Что такое Query Cache в Hibernate?	Hibernate реализует область кэша для запросов resultset, который тесно взаимодействует с кэшем второго уровня Hibernate. Кэш запросов используется для кэширования результатов запроса. Когда кэш запроса включен, результаты запроса сохраняются вместе с комбинацией запросов и параметров вызова. Каждый раз запрос вызовет проверку на наличие результата у кэш менеджера. Если результаты найдены в кэше, они возвращаются, иначе инициализируется transaction в БД. Для подключения этой дополнительной функции требуется несколько дополнительных шагов в коде. Query Cache полезны только для часто выполняющихся запросов с повторяющимися параметрами. Для начала необходимо добавить эту запись в файле конфигурации Hibernate:  <property name="hibernate.cache.use_query_cache">true</property>  Уже внутри кода приложения для запроса применяется метод setCacheable(true), как показано ниже:  Query query = session. createQuery("from Employee"); query. setCacheable(true); query. setCacheRegion("ALL_EMP");
Назовите преимущества поддержки нативного sql в Hibernate.	Использование нативного SQL может быть необходимо при выполнении запросов к некоторым базам данных, которые могут не поддерживаться в Hibernate. Примером может служить некоторые специфичные запросы и «фишки» при работе с БД от Oracle.
Что такое Named SQL Query?	Hibernate поддерживает именованный запрос, который мы можем задать в каком-либо центральном месте и потом использовать его в любом месте в коде. Именованные запросы поддерживают как HQL, так и Native SQL. Создать именованный запрос можно с помощью JPA аннотаций @NamedQuery, @NamedNativeQuery или в конфигурационном файле отображения (mapping files).
Каковы преимущества Named SQL Query?	Именованный запрос Hibernate позволяет собрать множество запросов в одном месте, а затем вызывать их в любом классе.  Синтаксис Named Query проверяется при создании session factory, что позволяет заметить ошибку на раннем этапе, а не при запущенном приложении и выполнении запроса.  Named Query глобальные, т.е. заданные однажды, могут быть использованы в любом месте.  Однако одним из основных недостатков именованного запроса является то, что его очень трудно отлаживать (могут быть сложности с поиском места определения запроса).
Как добавить логирование log4j в Hibernate приложение?	Добавить зависимость log4j в проект. Создать log4j.xml или log4j.properties файл и добавить его в classpath. Для веб приложений используйте ServletContextListener, а для автономных приложений DOMConfigurator или PropertyConfigurator для настройки логирования. Создайте экземпляр org.apache.log4j.Logger и используйте его согласно задачи.
Как логировать созданные Hibernate SQL запросы в лог-файлы?	Для логирования запросов SQL добавьте в файл конфигурации Hibernate строчку:  <property name="hibernate.show_sql">true</property>
Что такое Hibernate?	Hibernate — библиотека для языка программирования Java, предназначенная для решения задач объектно-реляционного отображения (object-relational mapping — ORM). Она представляет собой свободное программное обеспечение с открытым исходным кодом (open source), распространяемое на условиях GNU Lesser General Public License. Данная библиотека предоставляет легкий в использовании каркас (фреймворк) для отображения объектно-ориентированной модели данных в традиционные реляционные базы данных. Hibernate совместима с JSR-220/317 и предоставляет стандартные средства JPA.  Основные возможности фреймворка: Автоматическая генерация и обновление таблиц в базах данных; Поскольку основные запросы к базе данных (сохранение, обновление, удаление и поиск) представлены как методы фрейморка, то значительно сокращается код, который пишется разработчиком; Обеспечивает использование SQL подобного языка (HQL - hibernate query language). Запросы HQL могут быть записаны рядом объектами данных (POJO классы подготовленные для работы с базой данных).
Что вы знаете о Hibernate прокси и как это помогает в ленивой загрузке (lazy load)?	Hibernate использует прокси объект для поддержки отложенной загрузки. Обычно при загрузке данных из таблицы Hibernate не загружает все отображенные (замаппинные) объекты. Как только вы ссылаетесь на дочерний объект или ищите объект с помощью геттера, если связанная сущность не находиться в кэше сессии, то прокси код перейдет к базе данных для загрузки связанной сущности. Для этого используется javassist, чтобы эффективно и динамически создавать реализации подклассов ваших entity объектов.
Как управлять транзакциями с помощью Hibernate?	Hibernate вообще не допускает большинство операций без использования transaction. Поэтому после получения экземпляра session от SessionFactory необходимо выполнить beginTransaction() для начала транзакции. Метод вернет ссылку, которую мы можем использовать для подтверждения или отката транзакции. В целом, управление транзакциями в фреймворке выполнено гораздо лучше, чем в JDBC, т.к. мы не должны полагаться на возникновение исключения для отката транзакции. Любое исключение автоматически вызовет rollback.
Что такое каскадные связи (обновления) в Hibernate?	Если у нас имеются зависимости между сущностями (entities), то нам необходимо определить как различные операции будут влиять на другую сущность. Это реализуется с помощью каскадных связей (или обновлений). Вот пример кода с использованием аннотации @Cascade: import org.hibernate.annotations.Cascade  @Entity @Table(name = "EMPLOYEE") public class Employee { @OneToOne(mappedBy = "employee") @Cascade(value = org.hibernate.annotations.CascadeType.ALL) private Address address; } Обратите внимание, что есть некоторые различия между enum CascadeType в Hibernate и в JPA. Поэтому обращайте внимание какой пакет вы импортируете при использовании аннотации и константы типа. Наиболее часто используемые CascadeType перечисления описаны ниже. None: без Cascading. Формально это не тип, но если мы не указали каскадной связи, то никакая операция для родителя не будет иметь эффекта для ребенка. ALL: Cascades save, delete, update, evict, lock, replicate, merge, persist. В общем - всё. SAVE_UPDATE: Cascades save и update. Доступно только для hibernate. DELETE: передает в Hibernate native DELETE действие. Только для hibernate. DETATCH, MERGE, PERSIST, REFRESH и REMOVE - для простых операций. LOCK: передает в Hibernate native LOCK действие. REPLICATE: передает в Hibernate native REPLICATE действие.
Какие каскадные типы есть в Hibernate?	Наиболее часто используемые CascadeType перечисления описаны ниже.  None: без Cascading. Формально это не тип, но если мы не указали каскадной связи, то никакая операция для родителя не будет иметь эффекта для ребенка.  ALL: Cascades save, delete, update, evict, lock, replicate, merge, persist. В общем — всё.  SAVE_UPDATE: Cascades save и update. Доступно только для hibernate.  DELETE: передает в Hibernate native DELETE действие. Только для hibernate.  DETATCH, MERGE, PERSIST, REFRESH и REMOVE - для простых операций.  LOCK: передает в Hibernate native LOCK действие.  REPLICATE: передает в Hibernate native REPLICATE действие.
Что такое сесиия и фаблика сессий в Hibernate? Как настроить session factory в конфигурационном файле Spring?	Hibernate сессия - это главный интерфейс взаимодействия Java-приложения и Hibernate. SessionFactory позволяет создавать сессии согласно конфигурации hibernate.cfg.xml. 
Как использовать JNDI DataSource сервера приложений с Hibernate Framework?	В веб приложении лучше всего использовать контейнер сервлетов для управления пулом соединений. Поэтому лучше определить JNDI ресурс для DataSource и использовать его в веб приложении. Для этого в Hibernate нужно удалить все специфичные для базы данных свойства из и использовать указания свойства JNDI DataSource:  <property name="hibernate. connection. datasource">java: comp/env/jdbc/MyLoca1DB</property>
Как интегрировать Hibernate и Spring?	Лучше всего прочитать о настройках на сайтах фреймворков для текущей версии. Оба фреймворка поддерживают интеграцию из коробки и в общем настройка их взаимодействия не составляет труда. Общие шаги выглядят следующим образом.  Добавить зависимости для hibernate-entitymanager, hibernate-core и spring-orm.  Создать классы модели и передать реализации DAO операции над базой данных. Важно, что DAO классы используют SessionFactory, который внедряется в конфигурации бинов Spring.  Настроить конфигурационный файл Spring (смотрите в офф. документации или из примера на этом сайте).  Дополнительно появляется возможность использовать аннотацию @Transactional и перестать беспокоиться об управлением транзакцией Hibernate.
Какие паттерны применяются в Hibernate?	Domain Model Pattern - объектная модель предметной области, включающая в себя как поведение так и данные. Data Mapper - слой мапперов (Mappers), который передает данные между объектами и базой данных, сохраняя их независимыми друг от друга и себя. Proxy Pattern - применяется для ленивой загрузки. Factory pattern - используется в SessionFactory
Расскажите о Hibernate Validator Framework.	Проверка данных является неотъемлемой частью любого приложения. Hibernate Validator обеспечивает эталонную реализацию двух спецификаций JSR-303 и JSR-349 применяемых в Java. Для настройки валидации в Hibernate необходимо сделать следующие шаги. Добавить hibernate validation зависимости в проект.  Так же требуются зависимости из JSR 341, реализующие Unified Expression Language для обработки динамических выражений и сообщений о нарушении ограничений.  Использовать необходимые аннотации в бинах.
Какие преимущества дает использование плагина Hibernate Tools Eclipse?	Плагин Hibernate Tools упрощает настройку маппинга, конфигурационного файла. Упрощает работы с файлами свойств или xml тегами. Помогает минимизировать ошибки написания кода.
Расскажите о преимуществах использования Hibernate Criteria API.	Hibernate Criteria API является более объектно-ориентированным для запросов, которые получают результат из базы данных. Для операций update, delete или других DDL манипуляций использовать Criteria API нельзя. Критерии используются только для выборки из базы данных в более объектно-ориентированном стиле.  Вот некоторые области применения Criteria API:  Criteria API поддерживает проекцию, которую мы можем использовать для агрегатных функций вроде sum(), min(), max() и т.д.  Criteria API может использовать ProjectionList для извлечения данных только из выбранных колонок.  Criteria API может быть использована для join запросов с помощью соединения нескольких таблиц, используя методы createAlias(), setFetchMode() и setProjection().  Criteria API поддерживает выборку результатов согласно условиям (ограничениям). Для этого используется метод add() с помощью которого добавляются ограничения (Restrictions).  Criteria API позволяет добавлять порядок (сортировку) к результату с помощью метода addOrder().
Что вы знаете о классе HibernateTemplate?	Spring Framework предоставляет различные подходы для интеграции с Hibernate. Тем не менее, мы наиболее часто будем использовать подход, использующий HibernateTemplate. Есть две основные причины: Класс скрывает детали управления сессиями и транзакциями. Предоставляет подход основанный на шаблонах HibernateTemplate класс скрывает трудности управления сессиями и транзакциями при использовании Hibernate для доступа к данным. Нужно только инициализировать HibernateTemplate путем передачи экземпляра SessionFactory. Spring Framework берет на себя беспокойство за детали связанные с сессиями и транзакциями. Это помогает устранить инфраструктурный код, который может вносить суматоху при увеличении сложности. HibernateTemplate, так же как и JdbcTemplate, предоставляет шаблонный подход для доступа к данным. Когда вы используете HibernateTemplate, вы будете работать с callbacks. Обратные вызовы - это единственный механизм в шаблонном подходе, который уведомляет шаблон запускать нужную задачу. Преимущество наличия обратного вызова в том, что там только одна точка входа в слой доступа к данным. И эта точка входа определяется шаблоном, в этом случае HibernateTemplate.  В комментариях дополнили, что использование HibernateTemplate не явлется рекомендуемым. Вместо использования HibernateTemplate из пакета org.springframework.orm рекомендуется использовать декларативный подход (@Transactional). Таким образом фреймворк сам позаботится об операциях open, commit, close, flush.
Как интегрировать Hibernate с Servlet или Struts2 веб приложением?	Для интеграции необходимо использовать ServletContextListener.
Best Practices в Hibernate	При использовании фреймворка Hibernate рекомендуется придерживаться некоторых правил.  Всегда проверяйте доступ к primary key. Если он создается базой данных, то вы не должны иметь сеттера.  По умолчанию hibernate устанавливает значения в поля напрямую без использования сеттеров. Если необходимо заставить хибернейт их применять, то проверьте использование аннотации @Access(value=AccessType.PROPERTY) над свойством.  Если тип доступа - property, то удостоверьтесь, что аннотация используется с геттером.  Избегайте смешивания использования аннотации над обоими полями и геттером.  Используйте нативный sql запрос только там, где нельзя использовать HQL.  Используйте ordered list вместо сортированного списка из Collection API, если вам необходимо получить отсортированные данные.  Применяйте именованные запросы разумно - держите их в одном месте и используйте только для часто применяющихся запросов. Для специфичных запросов пишите их внутри конкретного бина.  В веб приложениях используйте JNDI DataSource вместо файла конфигурации для соединения с БД.  Избегайте отношений многие-ко-многим, т.к. это можно заменить двунаправленной One-to-Many и Many-to-One связью.  Для collections попробуйте использовать Lists, maps и sets. Избегайте массивов (array), т.к. они не дают преимуществ ленивой загрузки.  Не обрабатывайте исключения, которые могут откатить транзакцию и закрыть сессию. Если это проигнорировать, то Hibernate не сможет гарантировать, что состояние в памяти соответствует состоянию персистентности (могут быть коллизии данных).  Применяйте шаблон DAO для методов, которые могут использоваться в entity бинах.  Предпочитайте ленивую выборку для ассоциаций.
Что такое Hibernate? В чём разница между JPA и Hibernate?	Я думаю, чтобы ответить на данный вопрос, нам сперва нужно понять, что такое JPA. JPA это спецификация, описывающая объектно-реляционное отображение простых Java объектов и предоставляющая API для сохранения, получения и управления такими объектами. То есть, как мы помним, реляционные базы данных (БД) представлены в виде множества связанных между собой таблиц. И JPA — общепринятый стандарт, который описывает, как объекты могут взаимодействовать с реляционными базами данных. Как видие, JPA это что-то абстрактное и неосязаемое. Это как бы сама идея, подход.В то же время Hibernate это конкретная библиотека, реализующая парадигмы JPA. То, есть с помощью этой библиотеки вы можете работать с реляционной базой данных через объекты, которые представляют данные с БД (Entity). Как говорят, данная библиотека очень близка к идеалам JPA и возможно, поэтому она стала популярна. А как вы понимаете, популярность использования — хороший аргумент для дальнешйей разработки и улучшений. К тому же за частым использованием стоит огромное комьюнити, которое разобрало уже все возможные и невозможные вопросы, связанные с данным инструментом.
Что такое каскадность? Как она используется в Hibernate?	Как я и сказал ранее, в Hibernate взаимодействие ведется через объекты данных, называемые entity. Эти entity представляют какие-то конкретные таблицы в базе данных, и как вы помните, в Java классы могут содержать ссылки на другие классы. Эти отношения отражаются и на базе данных. В БД, как правило, это либо внешние ключи (для OneToOne, OneToMany, ManyToOne), либо промежуточные таблицы (для ManyToMany) Подробнее о взаимосвязи между сущностями можно почитать в этой статье. Когда в вашем entity есть ссылки на другие связанные сущности, над этими ссылками ставятся аннотации для указания типа связи: @OneToOne, @OneToMany, @ManyToOne, @ManyToMane, в чьих параметрах вы можете указать значение свойства — cascade — тип каскаданости для данной связи. У JPA есть специфические методы для взаимодействия с сущностями (persist, save, merge...). Каскадные типы как раз используются для того, чтобы показать, как должны себя вести связанные данные при использовании этих методов на целевую сущность. Итак, какие же существуют стратегии каскаскадности (типы каскадности)? Стандарт JPA подразумевает использование шести видов каскадности: PERSIST — операции сохранения будут происходить каскадно (для методов save() и persist()). То есть, если мы сохраняем сущность, связанную с другими сущностями, они также сохраняются в БД (если их ещё там нет)  MERGE — операции обновления будут происходить каскадно (для метода merge()) REMOVE — операции удаления происходят каскадно (метод remove()) ALL — содержит сразу три каскадные операции — PERSIST - MERGE - REMOVE В JPA есть понятие персистентная (persistence) сущность — сущность, связанная с её данными в БД, которая управляется текущей сессией (соединением). Если её изменить, но при этом не сохранить изменения в БД, всё равно её данные в БД будут изменены. DETACH — связанные сущности не будут управляться сессией (метод detach()). То есть, при их изменении не будет автоматического изменения их данных в БД — они переводятся из состояния persistence в detached (сущность, не управляемая JPA) REFRESH — при каждом обновлении сущности данными из БД (refresh() — обновляет detached объекты) связанные сущности обновляются так же. Например, вы изменили как-то данные, взятые из БД, и хотите вернуть их изначальные значения. В таком случае вам и пригодится данная операция. Hibernate поддерживает все эти стандартные каскадные операции, но также привносит три свои: REPLICATE — используется, когда у нас есть более одного источника данных и мы хотим, чтобы данные синхронизировались (метод Hibernate — replicate). У всех сущностей должны быть идентификаторы (id), чтобы не было проблем с их генерацией (чтобы для разных БД одна и та же сущность не имела разных id) SAVE_UPDATE — каскадное сохранение/удаление (для метода Hibernate — saveOrUpdate) LOCK — операция, обратная к DETACHED: переводит detached сущность обратно в состояние persistence, т.е. entity станет снова отслеживаемой текущей сессией Если не выбран тип каскадирования, никакая операция с сущностью не будет иметь эффекта для связанных с ней других entity.
N+1 SELECT problem и пути ее решения?	Проблема n + 1 может возникнуть в случае, когда одна сущность (таблица) ссылается на другую сущность (таблицу). В такой ситуации получается, что для получения значения зависимой сущности выполняется n избыточных запросов, в то время как достаточно одного. Никого не нужно убеждать, что это негативно влияет на производительность системы и создает ненужную нагрузку на базу данных. Особенно то, что количество запросов увеличивается с ростом n. Сама проблема часто представляется как возникающая только в отношениях "один ко многим" (javax.persistence.OneToMany) или только в случае ленивой загрузки данных (javax.persistence.FetchType.LAZY). Это не так, и следует помнить, что эта проблема также может возникнуть в отношениях один-к-одному и при "жадной" загрузке зависимых сущностей.  Решение 1)Устранение проблемы с помощью Join Fetch 2)Добавив аннотацию @BatchSize над полем , Hibernate получит данные в рамках одного запроса. (Всего их будет два)
@Transactional	@Transactional указывает, что метод должен выполняться в транзакции. Менеджер transaction открывает новую транзакцию и создаёт для неё экземпляр Session, который доступен через sessionFactory.getCurrentSession(). Все методы, которые вызываются в методе с данной аннотацией, также имеют доступ к этой транзакции, потому что экземпляр Session является переменной потока (ThreadLocal). Вызов sessionFactory.openSession() откроет совсем другую сессию, которая не связана с транзакцией.
Параметр rollbackFor у @Transactional	Параметр rollbackFor указывает исключения, при выбросе которых должен быть произведён откат транзакции. Есть обратный параметр — noRollbackFor, указывающий, что все исключения, кроме перечисленных, приводят к откату транзакции.
Параметр propagation у @Transactional	Параметр propagation он указывает принцип propagation транзакции. Может принимать любое значение из перечисления  Propagation.REQUIRED — выполняться в существующей транзакции, если она есть, иначе создавать новую.  Propagation.MANDATORY — выполняться в существующей транзакции, если она есть, иначе генерировать исключение.  Propagation.SUPPORTS — выполняться в существующей транзакции, если она есть, иначе выполняться вне транзакции.  Propagation.NOT_SUPPORTED — всегда выполняться вне транзакции. Если есть существующая, то она будет остановлена.  Propagation.REQUIRES_NEW — всегда выполняться в новой независимой транзакции. Если есть существующая, то она будет остановлена до окончания выполнения новой транзакции.  Propagation.NESTED — если есть текущая транзакция, выполняться в новой, так называемой, вложенной транзакции. Если вложенная transaction будет отменена, то это не повлияет на внешнюю транзакцию; если будет отменена внешняя транзакция, то будет отменена и вложенная. Если текущей транзакции нет, то просто создаётся новая.  Propagation.NEVER — всегда выполнять вне транзакции, при наличии существующей генерировать исключение.
Что такое веб сервисы?	Веб-служба, веб-сервис (англ. web service) — идентифицируемая веб-адресом программная система со стандартизированными интерфейсами. Веб-службы могут взаимодействовать друг с другом и со сторонними приложениями посредством сообщений, основанных на определённых протоколах (SOAP, XML-RPC, REST и т. д.). Веб-служба является единицей модульности при использовании сервис-ориентированной архитектуры приложения. К характеристикам веб сервисов относят: Функциональная совместимость Расширяемость Возможность машинной обработки описания
В чем разница между SOA и web service?	Сервис-ориентированная архитектура (SOA, service-oriented architecture) — модульный подход к разработке программного обеспечения, основанный на использовании распределённых, слабо связанных (англ. loose coupling) заменяемых компонентов, оснащённых стандартизированными интерфейсами для взаимодействия по стандартизированным протоколам. Программные комплексы, разработанные в соответствии с сервис-ориентированной архитектурой, обычно реализуются как набор веб-служб, взаимодействующих по протоколу SOAP, но существуют и другие реализации (например, на базе jini, CORBA, на основе REST). Веб сервисы реализующие эту концепцию используют XML, JSON и др., а так же интернет протоколы вроде HTTP(S), SMTP и др..
Что такое SOAP?	SOAP (от англ. Simple Object Access Protocol — простой протокол доступа к объектам; вплоть до спецификации 1.2) — протокол обмена структурированными сообщениями в распределённой вычислительной среде. Первоначально SOAP предназначался в основном для реализации удалённого вызова процедур (RPC). Сейчас протокол используется для обмена произвольными сообщениями в формате XML, а не только для вызова процедур. Официальная спецификация последней версии 1.2 протокола никак не расшифровывает название SOAP. SOAP является расширением протокола XML-RPC. SOAP может использоваться с любым протоколом прикладного уровня: SMTP, FTP, HTTP, HTTPS и др. Однако его взаимодействие с каждым из этих протоколов имеет свои особенности, которые должны быть определены отдельно. Чаще всего SOAP используется поверх HTTP.
Что такое REST?	REST (сокр. от англ. Representational State Transfer — «передача состояния представления») — архитектурный стиль взаимодействия компонентов распределённого приложения в сети. REST представляет собой согласованный набор ограничений, учитываемых при проектировании распределённой гипермедиа-системы. В определённых случаях (интернет-магазины, поисковые системы, прочие системы, основанные на данных) это приводит к повышению производительности и упрощению архитектуры. В широком смысле компоненты в REST взаимодействуют наподобие взаимодействия клиентов и серверов во Всемирной паутине. REST является альтернативой RPC. В сети Интернет вызов удалённой процедуры может представлять собой обычный HTTP-запрос (обычно GET или POST; такой запрос называют REST-запрос), а необходимые данные передаются в качестве параметров запроса. Для веб-сервисов, построенных с учётом REST, то есть не нарушающих накладываемых им ограничений, применяют термин «RESTful».
Преимущества, которые дает REST	У приложений, которые соблюдают все вышеперечисленные ограничения, есть такие преимущества: надёжность (не нужно сохранять информацию о состоянии клиента, которая может быть утеряна);  производительность (за счёт использования кэша); масштабируемость; прозрачность системы взаимодействия; простота интерфейсов; портативность компонентов; лёгкость внесения изменений; способность эволюционировать, приспосабливаясь к новым требованиям.
REST принципы	Как было сказано выше, REST определяет, как компоненты распределенной системы должны взаимодействовать друг с другом. В общем случае это происходит посредством запросов-ответов. Компоненту, которая отправляет запрос называют клиентом; компоненту, которая обрабатывает запрос и отправляет клиенту ответ, называют сервером. Запросы и ответы, чаще всего, отправляются по протоколу HTTP (англ. HyperText Transfer Protocol — "протокол передачи гипертекста"). Как правило сервер это некое веб-приложение. Клиентом же может быть не то чтобы что угодно, но довольно многое. Например, мобильное приложение, которое запрашивает у сервера данные. Либо браузер, который отправляет запросы с веб-страницы на сервер для загрузки данных. Приложение А может запрашивать данные у приложения Б. Тогда А является клиентом по отношению к Б, а Б — сервером по отношению к А. Одновременно с этим, А может обрабатывать запросы от В, Г, Д и т.д. В таком случае, приложение А является одновременно и сервером, и клиентом. Все зависит от контекста. Однозначно одно: компонента которая шлет запрос это клиент. Компонента, которая принимает, обрабатывает и отвечает на запрос — сервер.
REST ограничения	Однако не каждая система, чьи компоненты обмениваются данными посредством запросов-ответов, является REST (или же RESTful) системой. Чтобы система считалась RESTful, она должна "вписываться" в шесть REST ограничений:  1. Приведение архитектуры к модели клиент-сервер В основе данного ограничения лежит разграничение потребностей. Необходимо отделять потребности клиентского интерфейса от потребностей сервера, хранящего данные. Данное ограничение повышает переносимость клиентского кода на другие платформы, а упрощение серверной части улучшает масштабируемость системы. Само разграничение на "клиент" и "сервер" позволяет им развиваться независимо друг от друга.  2. Отсутствие состояния Архитектура REST требует соблюдения следующего условия. В период между запросами серверу не нужно хранить информацию о состоянии клиента и наоборот. Все запросы от клиента должны быть составлены так, чтобы сервер получил всю необходимую информацию для выполнения запроса. Таким образом и сервер, и клиент могут "понимать" любое принятое сообщение, не опираясь при этом на предыдущие сообщения.  3. Кэширование Клиенты могут выполнять кэширование ответов сервера. У тех, в свою очередь, должно быть явное или неявное обозначение как кэшируемых или некэшируемых, чтобы клиенты в ответ на последующие запросы не получали устаревшие или неверные данные. Правильное использование кэширования помогает полностью или частично устранить некоторые клиент-серверные взаимодействия, ещё больше повышая производительность и расширяемость системы.  4. Единообразие интерфейса К фундаментальным требованиям REST архитектуры относится и унифицированный, единообразный интерфейс. Клиент должен всегда понимать, в каком формате и на какие адреса ему нужно слать запрос, а сервер, в свою очередь, также должен понимать, в каком формате ему следует отвечать на запросы клиента. Этот единый формат клиент-серверного взаимодействия, который описывает, что, куда, в каком виде и как отсылать и является унифицированным интерфейсом  5. Слои Под слоями подразумевается иерархическая структура сетей. Иногда клиент может общаться напрямую с сервером, а иногда — просто с промежуточным узлом. Применение промежуточных серверов способно повысить масштабируемость за счёт балансировки нагрузки и распределённого кэширования. Приведем пример. Представим себе некоторое мобильное приложение, которое пользуется популярностью во всем мире. Его неотъемлемая часть — загрузка картинок. Так как пользователей — миллионы человек, один сервер не смог бы выдержать такой большой нагрузки. Разграничение системы на слои решит эту проблему. Клиент запросит картинку у промежуточного узла, промежуточный узел запросит картинку у сервера, который наименее загружен в данный момент, и вернет картинку клиенту. Если здесь на каждом уровне иерархии правильно применить кэширование, то можно добиться хорошей масштабируемости системы.  6. Код по требованию (необязательное ограничение) Данное ограничение подразумевает, что клиент может расширять свою функциональность, за счет загрузки кода с сервера в виде апплетов или сценариев.
В чем разница между REST и SOAP веб сервисами?	REST поддерживает различные форматы: text, JSON, XML; SOAP - только XML, REST работает только по HTTP(S), а SOAP может работать с различными протоколами, REST может работать с ресурсами. Каждый URL это представление какого-либо ресурса. SOAP работает с операциями, которые реализуют какую-либо бизнес логику с помощью нескольких интерфейсов, SOAP на основе чтения не может быть помещена в кэш, а REST в этом случае может быть закэширован, SOAP поддерживает SSL и WS-security, в то время как REST - только SSL, SOAP поддерживает ACID (Atomicity, Consistency, Isolation, Durability). REST поддерживает транзакции, но ни один из ACID не совместим с двух фазовым коммитом.
Как бы вы решили какой из REST или SOAP веб сервисов использовать?	REST против SOAP можно перефразировать как "Простота против Стандарта". В случае REST (простота) у вас будет скорость, расширяемость и поддержка многих форматов. В случае с SOAP у вас будет больше возможностей по безопасности (WS-security) и транзакционная безопасность (ACID).
Объясните понятие WSDL.	WSDL (англ. Web Services Description Language) — язык описания веб-сервисов и доступа к ним, основанный на языке XML. Каждый документ WSDL 1.1 можно разбить на следующие логические части: определение типов данных (types) — определение вида отправляемых и получаемых сервисом XML-сообщений  элементы данных (message) — сообщения, используемые web-сервисом  абстрактные операции (portType) — список операций, которые могут быть выполнены с сообщениями  связывание сервисов (binding) — способ, которым сообщение будет доставлено
Что такое JAX-WS?	Java API for XML Web Services (JAX-WS) это прикладной программный интерфейс языка Java для создания веб-служб, являющийся частью платформы Java EE. JAX-WS является заменой технологии JAX-RPC, предоставляя более документо-ориентированную модель сообщений и упрощая разработку[1] веб-служб за счёт использования аннотаций, впервые появившихся в Java SE 5. Технология JAX-WS является стандартом и описана в JSR 224. Некоторые преимущества: Использование аннотаций устраняет необходимость создания дескрипторов веб-служб. Декларация конечных точек (endpoints) происходит непосредственно в классах Java. Прямая интеграция с JAXB 2.0. Внедрение ресурсов (Resource injection). Поддержка MTOM. Возможность выбора между двумя путями разработки: снизу-вверх (программист разрабатывает endpoint-классы сам) и сверху-вниз (Java классы генерируются по WSDL).
Расскажите о JAXB.	Java Architecture for XML Binding (JAXB) позволяет Java разработчикам ставить в соответствие Java классы и XML представления. JAXB предоставляет две основные возможности: сериализация Java объектов в XML и наоборот, то есть десериализация из XML обратно в Java объект. Другими словами, JAXB позволяет хранить и извлекать данные в памяти в любом XML-формате, без необходимости выполнения определенного набора процедур загрузки и сохранения XML. Он похож на xsd.exe и XmlSerializer в .NET Framework. JAXB особенно полезен, когда спецификация является сложной и меняющейся. В этом случае, постоянные изменения схемы XML определений для синхронизации их с определениями Java могут занять много времени и быть подвержены ошибкам.
Можем ли мы посылать soap сообщения с вложением?	Да, это возможно. Можно посылать вложением различные форматы: PDF, изображения или другие двоичные данные. Сообщения SOAP работают вместе с расширением MIME, в котором предусмотрено multipart/related: MIME-Version: 1.0 Content-Type: Multipart/Related; boundary=MIME_boundary; type=text/xml; start="<claim061400a.xml@ javastudy.ru>" Content-Description: This is the optional message description. <?xml version='1.0' ?> <SOAP-ENV:Envelope xmlns:SOAP-ENV="http://schemas.xmlsoap.org/soap/envelope/"> <SOAP-ENV:Body> .. <theSignedForm href="cid:claim061400a.tiff@javastudy.ru"/> .. </SOAP-ENV:Body> </SOAP-ENV:Envelope> --MIME_boundary Content-Type: image/tiff Content-Transfer-Encoding: binary Content-ID: <claim061400a.tiff@javastudy.ru> ...binary TIFF image... --MIME_boundary—
Что такое MTOM?	MTOM (Message Transmission Optimization Mechanism) - использование кодирования сообщений с помощью механизма оптимизации передачи сообщений. Это механизм передачи больших вложений в двоичном формате с сообщениями протокола SOAP как необработанных байтов, допустимых для меньших сообщений.
Что такое XOP?	XOP (XML-binary Optimized Packaging) — механизм, рекомендованный W3C для встраивания двоичных данных в набор информационных элементов XML (XML Information Set).
Объясните элемент SOAP envelope.	Элемент SOAP envelope является корневым элементом SOAP сообщения и определяет XML документ как SOAP сообщение.  <?xml version="1.0"?> <soap:Envelope xmlns:soap="http://www.w3.org/2001/12/soap-envelope" soap:encodingStyle="http://www.w3.org/2001/12/soap-encoding"> ... Message information ... </soap:Envelope>
Как определяется пространство имен SOAP?	xmlns:soap=http://www.w3.org/2001/12/soap-envelope
Что вы знаете о кодировании в SOAP (encoding)?	Кодирование SOAP представляет собой метод для структурирования запроса, который предлагается в рамках спецификации SOAP, известный как SOAP-сериализация.
Что определяет атрибут encodingStyle в SOAP?	SOAP encodingStyle определяет правила сериализации, используемые в сообщении SOAP. Этот атрибут может появиться на любом элементе, и область видимости этого атрибута будет распространяться на все дочерние элементы, даже на те, которые не имеют явно этого атрибута. Для сообщений SOAP по умолчанию кодирование не определено.  SOAP-ENV:encodingStyle="http://www.w3.org/2001/12/soap-encoding"
Какие два конечных типа веб сервисов используют JAX-WS?	RPC (remote procedure call) style web service в JAX-WS;  document style web service в JAX-WS.
Какие существуют правила для кодирования записи header?	заголовок должен быть идентифицирован с помощью полного имени, которое содержит пространство имен URI и локальное имя. Все непосредственные дочерние элементы SOAP заголовка должны быть заданы в пространстве имен,  атрибут SOAP encodingStyle должен использоваться для указания стиля кодирования заголовка,  атрибут SOAP mustUnderstand и атрибут SOAP actor должны использоваться для указания того, как обрабатывать запись и кем.
Что вы знаете об инструменте wsimport?	Инструмент wsimport используется для синтаксического анализа существующих Web Services Description Language (WSDL-файл) и генерации необходимых файлов (JAX-WS портируемые артефакты) для клиента веб-сервиса для доступа к опубликованному веб-сервису.
Что вы знаете об инструменте wsgen?	Инструмент wsgen используется для анализа существующего класса реализации веб-службы и создает необходимые файлы (JAX-WS портируемые артефакты) для развертывания веб-служб.
Какие вы можете выделить различия между SOAP и другими техниками удаленного доступа?	SOAP проще в использовании, т.к. он не симметричный вроде DCOM или COBRA,  SOAP является более независимым от платформы и языка в отличие от DCOM или CORBA,  SOAP использует HTTP в качестве транспортного протокола и данные сохраняются в формате XML, который может быть прочтен человеком, тогда как DCOM или CORBA имеют свои собственные бинарные форматы, которые используются для транспортировки данных сложным образом.  SOAP идентифицирует объект, отличный от конечного URL. Объекты SOAP являются независимыми и их сложно поддерживать. В случае других методов удаленного доступа работа в этом случае может быть проще.
Что такое resource в REST?	Это уникальный URL с представлением объекта, который может быть получен с помощью запросов GET и изменен с помощью PUT, POST, DELETE.
Какие HTTP методы поддерживаются в REST?	GET; POST; PUT; DELETE; OPTIONS; HEAD.
Когда можно использовать GET запрос вместо POST для создания ресурса?	Невозможно использовать GET запрос для изменения (создания) ресурса.
Какая разница между GET и POST запросами?	GET передает данные серверу используя URL, когда POST передает данные, используя тело HTTP запроса.  Длина URL'а ограничена 1024 символами, это и будет верхним ограничением для данных, которые можно отослать GET'ом.  POST может отправлять гораздо большие объемы данных. Лимит устанавливается веб-сервером и обычно равен около 2MB.  Передача данных методом POST более безопасна, чем методом GET, так как секретные данные (например пароль) не отображаются напрямую в web-клиенте пользователя (в отличии от URL, который виден почти всегда).
Что означает WADL?	Web Application Description Language (WADL) — машинно-читаемое XML-описание для web-приложений HTTP (как правило, веб-сервисы REST). Аналог WSDL для SOAP.  WADL моделирует ресурсы, предоставляемые сервисом, и взаимосвязи между ними. WADL был предложен как стандарт W3C компанией Sun Microsystems в августе 2009, но консорциум не имеет никаких планов насчёт него и WADL ещё не получил широкого применения.
Какие вы знаете фреймворки, которые реализуют REST веб сервисы?	Их много, вот некоторые из них: Jersey, Restlet, EasyRest.
Какая разница между AJAX и REST?	В AJAX запрос посылается к серверу с помощью объектов XMLHttpRequest. В REST используется структура URL и использование ресурсов вращается вокруг шаблона запрос\ответ. AJAX асинхронно исключает взаимодействие между клиентом и сервером, в то время как REST требует взаимодействия между клиентом и сервером. AJAX технология "set". REST - предоставляет методы для пользователей для запроса данных или информации от сервера.
Дайте определение понятию "исключение"	Исключение - это проблема(ошибка) возникающая во время выполнения программы. Исключения могут возникать во многих случаях, например:  Пользователь ввел некорректные данные. Файл, к которому обращается программа, не найден. Сетевое соединение с сервером было утеряно во время передачи данных. И т.д.  Все исключения в Java являются объектами. Поэтому они могут порождаться не только автоматически при возникновении исключительной ситуации, но и создаваться самим разработчиком.
Опишите иерархию исключений	Все классы-исключения расширяют класс Throwable - непосредственное расширение класса object. У класса Throwable и у всех его расширений по традиции два конструктора: Throwable о - конструктор по умолчанию; Throwable (String message) - создаваемый объект будет содержать произвольное сообщение message. Записанное в конструкторе сообщение можно получить затем методом getMessage (). Если объект создавался конструктором по умолчанию, то данный метод возвратит null. Метод toString возвращает краткое описание события, именно он работал в предыдущих листингах. Три метода выводят сообщения обо всех методах, встретившихся по пути "полета" исключения: printstackTrace() - выводит сообщения в стандартный вывод, как правило, это консоль; printStackTrace(PrintStream stream) - выводит сообщения в байтовый поток stream; printStackTrace(PrintWriter stream) - выводит сообщения в символьный поток stream. У класса Throwable два непосредственных наследника - классы Error и Exception. Они не добавляют новых методов, а служат для разделения классов-исключений на два больших семейства - семейство классов-ошибок (error) и семейство собственно классов-исключений (exception). Классы-ошибки, расширяющие класс Error, свидетельствуют о возникновении сложных ситуаций в виртуальной машине Java. Их обработка требует глубокого понимания всех тонкостей работы JVM. Ее не рекомендуется выполнять в обычной программе. Не советуют даже выбрасывать ошибки оператором throw. He следует делать свои классы-исключения расширениями класса Error или какого-то его подкласса. Имена классов-ошибок, по соглашению, заканчиваются словом Error. Классы-исключения, расширяющие класс Exception, отмечают возникновение обычной нештатной ситуации, которую можно и даже нужно обработать. Такие исключения следует выбросить оператором throw. Классов-исключений очень много, более двухсот. Они разбросаны буквально по всем пакетам J2SDK. В большинстве случаев вы способны подобрать готовый класс-исключение для обработки исключительных ситуаций в своей программе. При желании можно создать и свой класс-исключение, расширив класс Exception или любой его подкласс. Среди классов-исключений выделяется класс RuntimeException - прямое расширение класса Exception. В нем и его подклассах отмечаются исключения, возникшие при работе JVM, но не столь серьезные, как ошибки. Их можно обрабатывать и выбрасывать, расширять своими классами, но лучше доверить это JVM, поскольку чаще всего это просто ошибка в программе, которую надо исправить. Особенность исключений данного класса в том, что их не надо отмечать в заголовке метода пометкой throws. Имена классов-исключений, по соглашению, заканчиваются словом Exception.
Какие виды исключений в Java вы знаете, чем они отличаются?	Все исключительные ситуации можно разделить на две категории: проверяемые(checked) и непроверяемые(unchecked). Все исключения, порождаемые от Throwable, можно разбить на три группы. Они определяются тремя базовыми типами: наследниками Throwable - классами Errorи Exception, а также наследником Exception - RuntimeException. Ошибки, порожденные от Exception (и не являющиеся наследниками RuntimeException ), являются проверяемыми. Т.е. во время компиляции проверяется, предусмотрена ли обработка возможных исключительных ситуаций. Как правило, это ошибки, связанные с окружением программы (сетевым, файловым вводом-выводом и др.), которые могут возникнуть вне зависимости от того, корректно написан код или нет. Например, открытие сетевого соединения или файла может привести к возникновению ошибки и компилятор требует от программиста предусмотреть некие действия для обработки возможных проблем. Таким образом повышается надежность программы, ее устойчивость при возможных сбоях. Исключения, порожденные от RuntimeException, являются непроверяемыми и компилятор не требует обязательной их обработки. Как правило, это ошибки программы, которые при правильном кодировании возникать не должны (например, IndexOutOfBoundsException- выход за границы массива, java.lang.ArithmeticException- деление на ноль). Поэтому, чтобы не загромождать программу, компилятор оставляет на усмотрение программиста обработку таких исключений с помощью блоков try-catch. Исключения, порожденные от Error, также не являются проверяемыми. Они предназначены для того, чтобы уведомить приложение о возникновении фатальной ситуации, которую программным способом устранить практически невозможно (хотя формально обработчик допускается). Они могут свидетельствовать об ошибках программы, но, как правило, это неустранимые проблемы на уровне JVM. В качестве примера можно привести StackOverflowError (переполнение стека), OutOfMemoryError (нехватка памяти). Методы, код которых может порождать проверяемые исключения, должны либо сами их обрабатывать, либо в заголовке метода должно быть указано ключевое слово throws с перечислением необрабатываемых проверяемых исключений. На непроверяемые ошибки это правило не распространяется. Переопределенный (overridden) метод не может расширять список возможных исключений исходного метода.
Как написать собственное («пользовательское») исключение?	Необходимо унаследоваться от базового класса требуемого типа исключений (например, от Exception или RuntimeException)
Какие существуют unchecked exception?	Наиболее часто встречающиеся: ArithmeticException, ClassCastException, ConcurrentModificationException, IllegalArgumentException, IllegalStateException, IndexOutOfBoundsException, NoSuchElementException, NullPointerException, UnsupportedOperationException.
О чем говорит ключевое слово throws?	Модификатор throws прописывается в заголовке метода и указывает на то, что метод потенциально может выбросить исключение с указанным типом.
Какой оператор позволяет принудительно выбросить исключение?	Это оператор throw: throw new Exception();
Что такое Error?	Исключения, порожденные от Error, не являются проверяемыми. Они предназначены для того, чтобы уведомить приложение о возникновении фатальной ситуации, которую программным способом устранить практически невозможно (хотя формально обработчик допускается). Они могут свидетельствовать об ошибках программы, но, как правило, это неустранимые проблемы на уровне JVM. В качестве примера можно привести StackOverflowError (переполнение стека), OutOfMemoryError (нехватка памяти). Методы, код которых может порождать проверяемые исключения, должны либо сами их обрабатывать, либо в заголовке метода должно быть указано ключевое слово throws с перечислением необрабатываемых проверяемых исключений. На непроверяемые ошибки это правило не распространяется.
Что вы знаете о OutOfMemoryError?	OutOfMemoryError выбрасывается, когда виртуальная машина Java не может создать (разместить) объект из-за нехватки памяти, а сборщик мусора не может высвободить достаточное её количество. Область памяти, занимаемая java процессом, состоит из нескольких частей. Тип OutOfMemoryError зависит от того, в какой из них не хватило места: - java.lang.OutOfMemoryError: Java heap space: Не хватает места в куче, а именно, в области памяти в которую помещаются объекты, создаваемые в приложении программно. Обычно проблема кроется в утечке памяти. Размер задается параметрами -Xms и -Xmx. - java.lang.OutOfMemoryError: PermGen space: (до версии Java 8) Данная ошибка возникает при нехватке места в Permanent области, размер которой задается параметрами -XX:PermSize и -XX:MaxPermSize. - java.lang.OutOfMemoryError: GC overhead limit exceeded: Данная ошибка может возникнуть как при переполнении первой, так и второй областей. Связана она с тем, что памяти осталось мало и сборщик мусора постоянно работает, пытаясь высвободить немного места. Данную ошибку можно отключить с помощью параметра -XX:-UseGCOverheadLimit. - java.lang.OutOfMemoryError: unable to create new native thread: Выбрасывается, когда нет возможности создавать новые потоки.
Опишите работу блока try-catch-finally.	try — данное ключевое слово используется для отметки начала блока кода, который потенциально может привести к ошибке. catch — ключевое слово для отметки начала блока кода, предназначенного для перехвата и обработки исключений в случае их возникновения. finally — ключевое слово для отметки начала блока кода, который является дополнительным. Этот блок помещается после последнего блока catch. Управление передаётся в блок finally в любом случае, было выброшено исключение или нет.
Что такое механизм try-with-resources?	Данная конструкция, которая появилась в Java 7, позволяет использовать блок try-catch не заботясь о закрытии ресурсов, используемых в данном сегменте кода. Ресурсы объявляются в скобках сразу после try, а компилятор уже сам неявно создаёт секцию finally, в которой и происходит освобождение занятых в блоке ресурсов. Под ресурсами подразумеваются сущности, реализующие интерфейс java.lang.Autocloseable. Стоит заметить, что блоки catch и явный finally выполняются уже после того, как закрываются ресурсы в неявном finally.
Возможно ли использование блока try-finally (без catch)?	Такая запись допустима, но смысла в такой записи не так много, всё же лучше иметь блок catch, в котором будет обрабатываться необходимое исключение.
Может ли один блок catch отлавливать сразу несколько исключений?	В Java 7 стала доступна новая языковая конструкция, с помощью которой можно перехватывать несколько исключений одним блоком catch: try { //... }  catch(IOException | SQLException ex)  { //... }
Всегда ли исполняется блок finally?	Код в блоке finally будет выполнен всегда, независимо от того, выброшено исключение или нет.  Например в следующих ситуациях он может быть не выполнен:  Существуют потоки-демоны - потоки предоставляющие некие сервисы, работая в фоновом режиме во время выполнения программы, но при этом не являются ее неотъемлеммой частью.Таким образом когда все потоки не демоны завершаются, программа завершает свою работу. В потоках демонах блок finally не выполняеться, они прерываются внезапно.  System.exit(0)  если в блоке finally произошло исключение и нет обработчика, то оставшийся код в блоке finally может не выполнятся.
Может ли метод main() выбросить исключение во вне и если да, то где будет происходить обработка данного исключения?	Может и оно будет передано в виртуальную машину Java (JVM).
Какие существуют способы обработки исключений?	В Java есть пять ключевых слов для работы с исключениями: try - данное ключевое слово используется для отметки начала блока кода, который потенциально может привести к ошибке. catch - ключевое слово для отметки начала блока кода, предназначенного для перехвата и обработки исключений. finally - ключевое слово для отметки начала блока кода, которой является дополнительным. Этот блок помещается после последнего блока 'catch'. Управление обычно передаётся в блок 'finally' в любом случае. throw - служит для генерации исключений. throws - ключевое слово, которое прописывается в сигнатуре метода, и обозначающее что метод потенциально может выбросить исключение с указанным типом.
В чем особенность блока finally? Всегда ли он исполняется?	Когда исключение передано, выполнение метода направляется по нелинейному пути. Это может стать источником проблем. Например, при входе метод открывает файл и закрывает при выходе. Чтобы закрытие файла не было пропущено из-за обработки исключения, был предложен механизм finally. Ключевое слово finally создаёт блок кода, который будет выполнен после завершения блока try/catch, но перед кодом, следующим за ним. Блок будет выполнен, независимо от того, передано исключение или нет. Оператор finally не обязателен, однако каждый оператор try требует наличия либо catch, либо finally. Код в блоке finally будет выполнен всегда.
В чем особенность RuntimeException?	public class RuntimeException extends Exception - базовый класс для ошибок во время выполнения. Относится к необрабатываемым исключениям (uncatched\unchecked). Как сказано в описании класса - это суперкласс, исключения которого могут быть выброшены во время нормальной работы JVM.
Есть ли дополнительные условия к методу, который потенциально может выбросить исключение?	Если это проверяемое исключение, то оно должно быть задекларировано в сигнатуре метода.  public void someMethod() throws Exception { }
Если оператор return содержится и в блоке catch и в finally, какой из них "главнее"?	Вернется из блока finally.
Что вы знаете о SQLException? К какому типу checked или unchecked оно относится, почему?	SQLException предоставляет информацию об ошибках доступа к базе данных или других ошибках связанных с работой с базами данных. SQLException относится к checked исключениям, а значит проверяется на этапе компиляции. Споры об этом типе исключения идут о том, что разработчику приходится постоянно обрабатывать это исключение в коде, хотя большая часть ошибок возникает во время выполнения программы, т.е., по мнению многих, лучше бы отнести его к unchecked runtime исключениям.  Аргумент Joshua Bloch из Effective Java Second Edition такой: сделав SQLException проверяемым - это попытка заставить разработчиков обработать исключение и обернуть его в новом уровне абстракции.
Предположим, есть блок try-finally. В блоке try возникло исключение и выполнение переместилось в блок finally. В блоке finally тоже возникло исключение. Какое из двух исключений "выпадет" из блока try-finally? Что случится со вторым исключением?	Ответ аналогичный случаю с двумя return - будет обработано в finally блоке. Если было выброшено два исключения - одно в try, второе в finally, то исключение в finally "проглотит" исключение выше (см. пример). Если до блока finally исключение было обработано, то мы можем получить информацию об исключении в блоке try и тем самым не потерять исключение, которое впоследствии может быть перезаписано в finally другим исключением.
Какие есть правила для проверки исключений при наследовании?	Переопределяемый или реализуемый метод в наследнике / реализации не может выбрасывать контролируемые исключения, которые выше по иерархии чем исключения в методе суперкласса / интерфейса.
Дайте краткую характеристику Enum в Java	Enum — перечисление, набор строковых констант, объединенных общим типом. Объявляется через ключевое слово — enum. Вот пример с enum — допустимые роли в некоторой школе:   public enum Role { STUDENT, TEACHER, DIRECTOR, SECURITY_GUARD }   Слова, написанные большими буквами, и есть те самые константы перечисления, которые объявляются упрощенно, без использования оператора new. Использование перечислений заметно упрощает жизнь, так как они помогают избежать ошибок и путаницы в наименованиях (так как может быть только определенный перечень значений).
Может Enum реализовывать (implements) интерфейсы?	Да. Ведь перечисления должны представлять не просто пассивные наборы (как например, роли). В Java они могут представлять более сложные объекты с некоторым функционалом, поэтому вам, возможно, понадобится добавить к ним дополнительный функционал. Также это позволит использовать возможности полиморфизма, подставляя значение enum в места, где необходим тип имплементируемого интерфейса.
Может Enum расширять (extends) класс?	Нет, не может, так как перечисление это подкласс по умолчанию универсального класса Enum <T>, где T представляет универсальный тип перечисления. Это не что иное, как общий базовый класс для всех типов перечисления языка Java. Преобразование enum в класс выполняется компилятором Java во время компиляции. Это расширение явно в коде не указывается, но всегда незримо присутствует.
Можно ли мы переопределить метод toString() для Enum?	Да, конечно вы можете переопределить метод toString(), чтобы определить конкретный способ отображения вашего enum при вызове метода toString (при переводе enum в обычную строку, например, для вывод в консоль или логи).
Можно ли указывать конструктор внутри Enum?	Да, конечно. Именно через конструктор и задаются значения внутренних переменных enum. В качестве примера к предыдущему enum добавим два поля — ageFrom и ageTo — чтобы обозначить возрастные рамки для каждой роли:   public enum Role {  STUDENT(5,18),  TEACHER(20,60),  DIRECTOR(40,70),  SECURITY_GUARD(18,50); int ageFrom; int ageTo;  Role(int ageFrom, int ageTo)  { this.ageFrom = ageFrom;  this.ageTo = ageTo; }  }
Что делает метод ordinal() в Enum?	При вызове метода int ordinal() на элементе enum-а мы получим порядковый номер с нуля этого значения в общем ряде перечислений. Давайте используем данный метод на одном элементе из предыдущего рассмотренного enum-а — Role:  System.out.println(Role.DIRECTOR.ordinal());  Соответственно, в консоли выведется:  2
Как связаны методы ordinal() и compareTo() в Enum?	Как было сказано ранее, ordinal() возвращает порядковый номер значения в общем списке перечислений. Также в разборе предыдущего вопроса вы увидели, что элементы перечислений, попав, например, в TreeSet (отсортированное множество) принимают порядок, в котором они объявлены в enum. И как мы знаем, TreeSet и TreeMap сортируют элементы посредством вызова у них метода compareTo() интерфейса Comparable. Из этого можно сделать предположение, что класс Enum имплементирует интерфейс Comparable, реализуя его в метод compareTo(), внутри которого и используется ordinal() для задания порядка сортировки.
Можно ли использовать Enum в switch case?	Можно и нужно! Оглядываясь на свою практику, отмечу, что одним из наиболее частых мест применения enum являются логические конструкции типа switch. В таком случае вы можете предусмотреть все возможные вариации case, и после прописания логики для всех значений enum-а использование оператора default может даже не понадобиться! Ведь если вы используете String или числовое значение, например, типа int, вам может прийти не предусмотренное значение, что в свою очередь невозможно с использованием enum-а.
Как получить все имеющиеся значения в экземпляре Enum?	Если нужно получить все экземпляры перечисления, есть метод values(), который возвращает массив всех доступных значений определенного enum-а в естественно порядке (в порядке задания в enum).
Что такое JPA?	JPA - это технология, обеспечивающая объектно-реляционное отображение простых JAVA объектов и предоставляющая API для сохранения, получения и управления такими объектами. JPA - это спецификация (документ, утвержденный как стандарт, описывающий все аспекты технологии), часть EJB3 спецификации. Сам JPA не умеет ни сохранять, ни управлять объектами, JPA только определяет правила игры: как что-то будет действовать. JPA также определяет интерфейсы, которые должны будут быть реализованы провайдерами. Плюс к этому JPA определяет правила о том, как должны описываться метаданные отображения и о том, как должны работать провайдеры. Дальше, каждый провайдер, реализуя JPA определяет получение, сохранение и управление объектами. У каждого провайдера реализация разная. Реализации JPA: Hibernate Oracle TopLink Apache OpenJPA
Из чего состоит JPA?	JPA состоит из трех основных пунктов:  API - интерфейсы в пакете javax.persistance. Набор интерфейсов, которые позволяют организовать взаимодействие с ORM провайдером.  JPQL - объектный язык запросов. Очень похож на SQL, но запросы выполняются к объектам.  Metadata - аннотации над объектами. Набор аннотаций, которыми мы описываем метаданные отображения. Тогда уже JPA знает какой объект в какую таблицу нужно сохранить. Метаданные можно описывать двумя способами: XML-файлом или через аннотации.
В чем её отличие JPA от Hibernate?	Hibernate одна из самых популярных открытых реализаций последней версии спецификации (JPA 2.1). То есть JPA только описывает правила и API, а Hibernate реализует эти описания, впрочем у Hibernate (как и у многих других реализаций JPA) есть дополнительные возможности, не описанные в JPA (и не переносимые на другие реализации JPA).
В чем её отличие JPA от JDO?	JPA (Java Persistence API) и Java Data Objects (JDO) две спецификации сохранения java объектов в базах данных. Если JPA сконцентрирована только на реляционных базах, то JDO более общая спецификация которая описывает ORM для любых возможных баз и хранилищ. Также отличаются "разработчики" спецификаций - если JPA разрабатывается как JSR, то JDO сначала разрабатывался как JSR, теперь разрабатывается как проект Apache JDO.
Можно ли использовать JPA c noSQL базами?	Спецификация JPA говорит только о отображении java объектов в таблицы реляционных баз данных, но при этом существует ряд реализаций данного стандарта для noSql баз данных: Kundera, DataNucleus, ObjectDB и ряд других. Естественно, при это не все специфичные для реляционных баз данных особенности спецификации переносятся при этом на nosql базы полностью.
Что такое JPQL (Java Persistence query language) и чем он отличается от SQL?	JPQL (Java Persistence query language) это язык запросов, практически такой же как SQL, однако вместо имен и колонок таблиц базы данных, он использует имена классов Entity и их атрибуты. В качестве параметров запросов так же используются типы данных атрибутов Entity, а не полей баз данных. В отличии от SQL в JPQL есть автоматический полиморфизм. Также в JPQL используется функции которых нет в SQL: такие как KEY (ключ Map'ы), VALUE (значение Map'ы), TREAT (для приведение суперкласса к его объекту-наследнику, downcasting), ENTRY и т.п.
Что означает полиморфизм (polymorphism) в запросах JPQL (Java Persistence query language) и как его "выключить"?	В отличии от SQL в запросах JPQL есть автоматический полиморфизм, то есть каждый запрос к Entity возвращает не только объекты этого Entity, но так же объекты всех его классов-потомков, независимо от стратегии наследования (например, запрос select * from Animal, вернет не только объекты Animal, но и объекты классов Cat и Dog, которые унаследованы от Animal). Чтобы исключить такое поведение используется функция TYPE в where условии (например select * from Animal a where TYPE(a) IN (Animal, Cat) уже не вернет объекты класса Dog).
Что такое Criteria API и для чего он используется?	Criteria API это тоже язык запросов, аналогичным JPQL (Java Persistence query language), однако запросы основаны на методах и объектах, то есть запросы выглядят так:
Что такое Entity?	Entity это легковесный хранимый объект бизнес логики (persistent domain object). Основная программная сущность это entity класс, который так же может использовать дополнительные классы, который могут использоваться как вспомогательные классы или для сохранения состояния еntity.
Может ли Entity быть абстрактным классом?	Может, при этом он сохраняет все свойства Entity, за исключением того что его нельзя непосредственно инициализировать.
Какие требования JPA к Entity классам вы можете перечислить (не менее шести требований)?	 Entity класс должен быть отмечен аннотацией Entity или описан в XML файле конфигурации JPA, 2) Entity класс должен содержать public или protected конструктор без аргументов (он также может иметь конструкторы с аргументами), 3) Entity класс должен быть классом верхнего уровня (top-level class), 4) Entity класс не может быть enum или интерфейсом, 5) Entity класс не может быть финальным классом (final class), 6) Entity класс не может содержать финальные поля или методы, если они участвуют в маппинге (persistent final methods or persistent final instance variables), 7) Если объект Entity класса будет передаваться по значению как отдельный объект (detached object), например через удаленный интерфейс (through a remote interface), он так же должен реализовывать Serializable интерфейс, 8) Поля Entity класс должны быть напрямую доступны только методам самого Entity класса и не должны быть напрямую доступны другим классам, использующим этот Entity. Такие классы должны обращаться только к методам (getter/setter методам или другим методам бизнес-логики в Entity классе), 9) Entity класс должен содержать первичный ключ, то есть атрибут или группу атрибутов которые уникально определяют запись этого Entity класса в базе данных.
Что такое атрибут Entity класса в терминологии JPA?	JPA указывает что она может работать как с свойствами классов (property), оформленные в стиле JavaBeans, либо с полями (field), то есть переменными класса (instance variables). Оба типа элементов Entity класса называются атрибутами Entity класса.
Какие два типа элементов есть у Entity классов. Или другими словами перечислите два типа доступа (access) к элементам Entity классов.	JPA указывает что она может работать как с свойствами классов (property), оформленные в стиле JavaBeans, либо с полями (field), то есть переменными класса (instance variables). Соответственно, при этом тип доступа будет либо property access или field access.
Какие типы данных допустимы в атрибутах Entity класса (полях или свойствах)?	Допустимые типы атрибутов у Entity классов: примитивные типы и их обертки Java, строки, любые сериализуемые типы Java (реализующие Serializable интерфейс), enums; entity types; embeddable классы и коллекции типов 1-6
Какие типы данных можно использовать в атрибутах, входящих в первичный ключ Entity класса (составной или простой), чтобы полученный первичный ключ мог использоваться для любой базы данных? А в случае автогенерируемого первичного ключа (generated primary keys)?	Допустимые типы атрибутов, входящих в первичный ключ: примитивные типы и их обертки Java, строки, BigDecimal и BigInteger, java.util.Date и java.sql.Date,В случае автогенерируемого первичного ключа (generated primary keys) допустимы только числовые типы,В случае использования других типов данных в первичном ключе, он может работать только для некоторых баз данных, т.е. становится не переносимым (not portable).
Что такое встраиваемый (Embeddable) класс?	Встраиваемый (Embeddable) класс это класс который не используется сам по себе, только как часть одного или нескольких Entity классов. Entity класс могут содержать как одиночные встраиваемые классы, так и коллекции таких классов. Также такие классы могут быть использованы как ключи или значения map. Во время выполнения каждый встраиваемый класс принадлежит только одному объекту Entity класса и не может быть использован для передачи данных между объектами Entity классов (то есть такой класс не является общей структурой данных для разных объектов). В целом, такой класс служит для того чтобы выносить определение общих атрибутов для нескольких Entity, можно считать что JPA просто встраивает в Entity вместо объекта такого класса те атрибуты, которые он содержит.
Может ли встраиваемый (Embeddable) класс содержать связи (relationship) с другими Entity или коллекциями Entity? Если может, то существуют ли какие-то ограничение на такие связи (relationship)?	Может, но только в случае если такой класс не используется как первичный ключ или ключ map'ы.
Какие требования JPA устанавливает к встраиваемым (Embeddable) классам?	1. Такие классы должны удовлетворять тем же правилам что Entity классы, за исключением того что они не обязаны содержать первичный ключ и быть отмечены аннотацией Entity 2. Embeddable класс должен быть отмечен аннотацией Embeddable или описан в XML файле конфигурации JPA.
Какие типы связей (relationship) между Entity вы знаете (перечислите восемь типов, либо укажите четыре типа связей, каждую из которых можно разделить ещё на два вида)?	Существуют следующие четыре типа связей OneToOne (связь один к одному, то есть один объект Entity может связан не больше чем с один объектом другого Entity ), OneToMany (связь один ко многим, один объект Entity может быть связан с целой коллекцией других Entity), ManyToOne (связь многие к одному, обратная связь для OneToMany), ManyToMany (связь многие ко многим).  Каждую из которых можно разделить ещё на два вида:  Bidirectional - ссылка на связь устанавливается у всех Entity, то есть в случае OneToOne A-B в Entity A есть ссылка на Entity B, в Entity B есть ссылка на Entity A, Entity A считается владельцем этой связи (это важно для случаев каскадного удаления данных, тогда при удалении A также будет удалено B, но не наоборот).  Undirectional - ссылка на связь устанавливается только с одной стороны, то есть в случае OneToOne A-B только у Entity A будет ссылка на Entity B, у Entity B ссылки на A не будет.
Что такое Mapped Superclass?	Mapped Superclass это класс от которого наследуются Entity, он может содержать аннотации JPA, однако сам такой класс не является Entity, ему не обязательно выполнять все требования установленные для Entity (например, он может не содержать первичного ключа). Такой класс не может использоваться в операциях EntityManager или Query. Такой класс должен быть отмечен аннотацией MappedSuperclass или соответственно описан в xml файле.
Какие два типа fetch стратегии в JPA вы знаете?	В JPA описаны два типа fetch стратегии: LAZY - данные поля будут загружены только во время первого доступа к этому полю, EAGER - данные поля будут загружены немедленно.
Какие три типы стратегии наследования мапинга (Inheritance Mapping Strategies) описаны в JPA?	В JPA описаны три стратегии наследования мапинга (Inheritance Mapping Strategies), то есть как JPA будет работать с классами-наследниками Entity:  одна таблица на всю иерархию наследования (a single table per class hierarchy) - все enity, со всеми наследниками записываются в одну таблицу, для идентификации типа entity определяется специальная колонка "discriminator column". Например, если есть entity Animals c классами-потомками Cats и Dogs, при такой стратегии все entity записываются в таблицу Animals, но при это имеют дополнительную колонку animalType в которую соответственно пишется значение "cat" или "dog".Минусом является то что в общей таблице, будут созданы все поля уникальные для каждого из классов-потомков, которые будет пусты для всех других классов-потомков. Например, в таблице animals окажется и скорость лазанья по дереву от cats и может ли пес приносить тапки от dogs, которые будут всегда иметь null для dog и cat соответственно.  объединяющая стратегия (joined subclass strategy) - в этой стратегии каждый класс enity сохраняет данные в свою таблицу, но только уникальные колонки (не унаследованные от классов-предков) и первичный ключ, а все унаследованные колонки записываются в таблицы класса-предка, дополнительно устанавливается связь (relationships) между этими таблицами, например в случае классов Animals (см.выше), будут три таблицы animals, cats, dogs, причем в cats будет записана только ключ и скорость лазанья, в dogs - ключ и умеет ли пес приносить палку, а в animals все остальные данные cats и dogs c ссылкой на соответствующие таблицы. Минусом тут являются потери производительности от объединения таблиц (join) для любых операций.  одна таблица для каждого класса (table per concrete class strategy) - тут все просто каждый отдельный класс-наследник имеет свою таблицу, т.е. для cats и dogs все данные будут записываться просто в таблицы cats и dogs как если бы они вообще не имели общего суперкласса. Минусом является плохая поддержка полиморфизма (polymorphic relationships) и то что для выборки всех классов иерархии потребуются большое количество отдельных sql запросов или использование UNION запроса.
Что такое EntityManager и какие основные его функции вы можете перечислить?	EntityManager это интерфейс, который описывает API для всех основных операций над Enitity, получение данных и других сущностей JPA. По сути главный API для работы с JPA. Основные операции:  Для операций над Entity: persist (добавление Entity под управление JPA), merge (обновление), remove (удаления), refresh (обновление данных), detach (удаление из управление JPA), lock (блокирование Enity от изменений в других thread),  Получение данных: find (поиск и получение Entity), createQuery, createNamedQuery, createNativeQuery, contains, createNamedStoredProcedureQuery, createStoredProcedureQuery  Получение других сущностей JPA: getTransaction, getEntityManagerFactory, getCriteriaBuilder, getMetamodel, getDelegate  Работа с EntityGraph: createEntityGraph, getEntityGraph  Общие операции над EntityManager или всеми Entities: close, isOpen, getProperties, setProperty, clear.
Какие четыре статуса жизненного цикла Entity объекта (Entity Instance's Life Cycle) вы можете перечислить?	У Entity объекта существует четыре статуса жизненного цикла: new, managed, detached, или removed. Их описание  new - объект создан, но при этом ещё не имеет сгенерированных первичных ключей и пока ещё не сохранен в базе данных,  managed - объект создан, управляется JPA, имеет сгенерированные первичные ключи,  detached - объект был создан, но не управляется (или больше не управляется) JPA,  removed - объект создан, управляется JPA, но будет удален после commit'a транзакции.
Как влияет операция merge на Entity объекты каждого из четырех статусов?	1. Если статус detached, то либо данные будет скопированы в существующей managed entity с тем же первичным ключом, либо создан новый managed в который скопируются данные, 2. Если статус Entity new, то будет создана новый managed entity, в который будут скопированы данные прошлого объекта, 3. Если статус managed, операция игнорируется, однако операция merge сработает на каскадно зависимые Entity, если их статус не managed, 4. Если статус removed, будет выкинут exception сразу или на этапе commit'а транзакции.
Как влияет операция remove на Entity объекты каждого из четырех статусов?	1. Если статус Entity new, операция игнорируется, однако зависимые Entity могут поменять статус на removed, если у них есть аннотации каскадных изменений и они имели статус managed, 2. Если статус managed, то статус меняется на removed и запись объект в базе данных будет удалена при commit'е транзакции (так же произойдут операции remove для всех каскадно зависимых объектов), 3. Если статус removed, то операция игнорируется, 4. Если статус detached, будет выкинут exception сразу или на этапе commit'а транзакции.
Как влияет операция persist на Entity объекты каждого из четырех статусов?	1. Если статус Entity new, то он меняется на managed и объект будет сохранен в базу при commit'е транзакции или в результате flush операций, 2. Если статус уже managed, операция игнорируется, однако зависимые Entity могут поменять статус на managed, если у них есть аннотации каскадных изменений, 3. Если статус removed, то он меняется на managed, 4. Если статус detached, будет выкинут exception сразу или на этапе commit'а транзакции.
Как влияет операция refresh на Entity объекты каждого из четырех статусов?	1. Если статус Entity managed, то в результате операции будут востановленны все изменения из базы данных данного Entity, так же произойдет refresh всех каскадно зависимых объектов, 2. Если статус new, removed или detached, будет выкинут exception.
Как влияет операция detach на Entity объекты каждого из четырех статусов?	1. Если статус Entity managed или removed, то в результате операции статус Entity (и всех каскадно-зависимых объектов) станет detached. 2. Если статус new или detached, то операция игнорируется.
Для чего нужна аннотация Access?	Она определяет тип доступа (access type) для класса entity, суперкласса, embeddable или отдельных атрибутов, то есть как JPA будет обращаться к атрибутам entity, как к полям класса (FIELD) или как к свойствам класса (PROPERTY), имеющие гетеры (getter) и сетеры (setter).
Для чего нужна аннотация Basic?	Basic - указывает на простейший тип маппинга данных на колонку таблицы базы данных. Также в параметрах аннотации можно указать fetch стратегию доступа к полю и является ли это поле обязательным или нет.
Какой аннотациями можно перекрыть связи (override entity relationship) или атрибуты, унаследованные от суперкласса, или заданные в embeddable классе при использовании этого embeddable класса в одном из entity классов и не перекрывать в остальных?	Для такого перекрывания существует четыре аннотации:  AttributeOverride чтобы перекрыть поля, свойства и первичные ключи,  AttributeOverrides аналогично можно перекрыть поля, свойства и первичные ключи со множественными значениями,  AssociationOverride чтобы перекрывать связи (override entity relationship),  AssociationOverrides чтобы перекрывать множественные связи (multiple relationship).
Какие аннотации служит для задания класса преобразования basic атрибута Entity в другой тип при сохранении/получении данных их базы (например, работать с атрибутом Entity boolean типа, но в базу сохранять его как число)?	Convert и Converts - позволяют указать класс для конвертации Basic атрибута Entity в другой тип (Converts - позволяют указать несколько классов конвертации). Классы для конвертации должны реализовать интерфейс AttributeConverter и могут быть отмечены (но это не обязательно) аннотацией Converter.
Какой аннотацией можно управлять кешированием JPA для данного Entity?	Cacheable - позволяет включить или выключить использование кеша второго уровня (second-level cache) для данного Entity (если провайдер JPA поддерживает работу с кешированием и настройки кеша (second-level cache) стоят как ENABLE_SELECTIVE или DISABLE_SELECTIVE, см вопрос 41). Обратите внимание свойство наследуется и если не будет перекрыто у наследников, то кеширование измениться и для них тоже.
Какой аннотацией можно задать класс, методы которого должен выполнится при определенных JPA операциях над данным Enitity или Mapped Superclass (такие как удаление, изменение данных и т.п.)?	EntityListeners позволяет задать класс Listener, который будет содержать методы обработки событий (сallback methods) определенных Entity или Mapped Superclass.
Для чего нужны callback методы в JPA? К каким сущностям применяются аннотации callback методов? Перечислите семь callback методов (или что тоже самое аннотаций callback методов).	Callback методы служат для вызова при определенных событиях Entity (то есть добавить обработку например удаления Entity методами JPA), могут быть добавлены к entity классу, к mapped superclass, или к callback listener классу, заданному аннотацией EntityListeners (см предыдущий вопрос). Существует семь callback методов (и аннотаций с теми же именами): PrePersist PostPersist PreRemove PostRemove PreUpdate PostUpdate PostLoad
Какой аннотацей можно исключить поли и свойства Entity из маппинга (property or field is not persistent)?	Для этого служит аннотация Transient.
Какие аннотации служить для установки порядка выдачи элементов коллекций Entity?	Для этого служит аннотация OrderBy и OrderColumn.
Какие шесть видов блокировок (lock) описаны в спецификации JPA (или какие есть значения у enum LockModeType в JPA)?	У JPA есть шесть видов блокировок, перечислим их в порядке увеличения надежности (от самого ненадежного и быстрого, до самого надежного и медленного): NONE - без блокировки OPTIMISTIC (или синоним READ, оставшийся от JPA 1) - оптимистическая locking OPTIMISTIC_FORCE_INCREMENT (или синоним WRITE, оставшийся от JPA 1) - оптимистическая locking с принудительным увеличением поля версионности PESSIMISTIC_READ - пессимистичная locking на чтение PESSIMISTIC_WRITE - пессимистичная locking на запись (и чтение) PESSIMISTIC_FORCE_INCREMENT - пессимистичная locking на запись (и чтение) с принудительным увеличением поля версионности.
Какие два вида кэшей (cache) вы знаете в JPA и для чего они нужны?	JPA говорит о двух видов кэшей (cache):  first-level cache (кэш первого уровня) - кэширует данные одной транзакции,  second-level cache (кэш второго уровня) - кэширует данные дольше чем одна транзакция. Провайдер JPA может, но не обязан реализовывать работу с кэшем второго уровня. Такой вид кэша позволяет сэкономить время доступа и улучшить производительность, однако оборотной стороной является возможность получить устаревшие данные.
Какие есть варианты настройки second-level cache (кэша второго уровня) в JPA или что аналогично опишите какие значения может принимать элемент shared-cache-mode из persistence.xml?	JPA говорит о пяти значениях shared-cache-mode из persistence.xml, который определяет как будет использоваться second-level cache: ALL - все Entity могут кэшироваться в кеше второго уровня NONE - кеширование отключено для всех Entity ENABLE_SELECTIVE - кэширование работает только для тех Entity, у которых установлена аннотация Cacheable(true) или её xml эквивалент, для всех остальных кэширование отключено DISABLE_SELECTIVE - кэширование работает для всех Entity, за исключением тех у которых установлена аннотация Cacheable(false) или её xml эквивалент UNSPECIFIED - кеширование не определенно, каждый провайдер JPA использует свою значение по умолчанию для кэширования
Как можно изменить настройки fetch стратегии любых атрибутов Entity для отдельных запросов (query) или методов поиска (find), то если у Enity есть атрибут с fetchType = LAZY, но для конкретного запроса его требуется сделать EAGER или наоборот?	Для этого существует EntityGraph API, используется он так: с помощью аннотации NamedEntityGraph для Entity, создаются именованные EntityGraph объекты, которые содержат список атрибутов у которых нужно поменять fetchType на EAGER, а потом данное имя указывается в hits запросов или метода find. В результате fetchType атрибутов Entity меняется, но только для этого запроса. Существует две стандартных property для указания EntityGraph в hit:  javax.persistence.fetchgraph - все атрибуты перечисленные в EntityGraph меняют fetchType на EAGER, все остальные на LAZY  javax.persistence.loadgraph - все атрибуты перечисленные в EntityGraph меняют fetchType на EAGER, все остальные сохраняют свой fetchType (то есть если у атрибута, не указанного в EntityGraph, fetchType был EAGER, то он и останется EAGER)С помощью NamedSubgraph можно также изменить fetchType вложенных объектов Entity.
Каким способом можно получить метаданные JPA (сведения о Entity типах, Embeddable и Managed классах и т.п.)?	Для получения такой информации в JPA используется интерфейс Metamodel. Объект этого интерфейса можно получить методом getMetamodel у EntityManagerFactory или EntityManager.
Каким способом можно в коде работать с кэшем второго уровня (удалять все или определенные Entity из кеша, узнать закэшировался ли данное Entity и т.п.)?	Для работы с кэшем второго уровня (second level cache) в JPA описан Cache интерфейс, содержащий большое количество методов по управлению кэшем второго уровня (second level cache), если он поддерживается провайдером JPA, конечно. Объект данного интерфейса можно получить с помощью метода getCache у EntityManagerFactory.
В чем разница в требованиях к Entity в Hibernate, от требований к Entity, указанных в спецификации JPA?	1. Конструктор без аргументов не обязан быть public или protected, рекомендуется чтобы он был хотя бы package видимости, однако это только рекомендация, если настройки безопасности Java позволяют доступ к приватным полям, то он может быть приватным, 2. JPA категорически требует не использовать final классы, Hibernate лишь рекомендует не использовать такие классы чтобы он мог создавать прокси для ленивой загрузки, однако позволяет либо выключить прокси Proxy(lazy=false), либо использовать в качестве прокси интерфейс, содержащий все методы маппинга для данного класса (аннотацией Proxy(proxyClass=интерфейс.class) )
Какая уникальная стратегия наследования есть в Hibernate, но нет в спецификации JPA?	В отличии JPA в Hibernate есть уникальная стратегия наследования, которая называется implicit polymorphism.
Какие основные новые возможности появились в спецификации JPA 2.1 по сравнению с JPA 2.0 (перечислите хотя бы пять-шесть новых возможностей)?	В спецификации JPA 2.1 появились:  Entity Graphs - механизм динамического изменения  fetchType для каждого запроса  Converters - механизм определения конвертеров для задания функций конвертации атрибутов Entity в поля базы данных  DDL генерация - автоматическая генерация таблиц, индексов и схем  Stored Procedures - механизм вызова хранимых процедур из JPA  Criteria Update/Delete - механизм вызова bulk updates или deletes, используя Criteria API  Unsynchronized persistence contexts - появление возможности указать SynchronizationType  Новые возможности в JPQL/Criteria API: арифметические подзапросы, generic database functions, join ON clause, функция TREAT  Динамическое создание именованных запросов (named queries)  Интерфейс EntityManager получил новые методы createStoredProcedureQuery, isJoinedToTransaction и createQuery(CriteriaUpdate или CriteriaDelete)  Абстрактный класс AbstractQuery стал наследоваться от класса CommonAbstractCriteria, появились новые интерфейсы CriteriaUpdate, CriteriaDelete унаследованные CommonAbstractCriteria,  PersistenceProvider получил новые функции generateSchema позволяющие генерить схемы,  EntityManagerFactory получил методы addNamedQuery, unwrap, addNamedEntityGraph, createEntityManager (с указанием SynchronizationType)  Появился новый enum SynchronizationType, Entity Graphs, StoredProcedureQuery и AttributeConverter интерфейсы.
В чём заключается разница между IO и NIO?	- Java IO (input-output) является потокоориентированным, а Java NIO (new/non-blocking io) - буфер-ориентированным. Потокоориентированный ввод/вывод подразумевает чтение/запись из потока/в поток одного или нескольких байт в единицу времени поочередно. Данная информация нигде не кэшируются. Таким образом, невозможно произвольно двигаться по потоку данных вперед или назад. В Java NIO данные сначала считываются в буфер, что дает больше гибкости при обработке данных. - Потоки ввода/вывода в Java IO являются блокирующими. Это значит, что когда в потоке выполнения вызывается read() или write() метод любого класса из пакета java.io.*, происходит locking до тех пор, пока данные не будут считаны или записаны. Поток выполнения в данный момент не может делать ничего другого. Неблокирующий режим Java NIO позволяет запрашивать считанные данные из канала (channel) и получать только то, что доступно на данный момент, или вообще ничего, если доступных данных пока нет. Вместо того, чтобы оставаться заблокированным пока данные не станут доступными для считывания, поток выполнения может заняться чем-то другим. Тоже самое справедливо и для неблокирующего вывода. Поток выполнения может запросить запись в канал некоторых данных, но не дожидаться при этом пока они не будут полностью записаны. - В Java NIO имеются селекторы, которые позволяют одному потоку выполнения мониторить несколько каналов ввода. Т.е. существует возможность зарегистрировать несколько каналов с селектором, а потом использовать один поток выполнения для обслуживания каналов, имеющих доступные для обработки данные, или для выбора каналов, готовых для записи.
Какие особенности NIO вы знаете?	- Каналы и селекторы: NIO поддерживает различные типы каналов. Канал является абстракцией объектов более низкого уровня файловой системы (например, отображенные в памяти файлы и блокировки файлов), что позволяет передавать данные с более высокой скоростью. Каналы не блокируются и поэтому Java предоставляет еще такие инструменты, как селектор, который позволяет выбрать готовый канал для передачи данных, и сокет, который является инструментом для блокировки. - Буферы: имеет буферизация для всех классов-обёрток примитивов (кроме Boolean). Появился абстрактный класс Buffer, который предоставляет такие операции, как clear, flip, mark и т.д. Его подклассы предоставляют методы для получения и установки данных. - Кодировки: появились кодеры и декодеры для отображения байт и символов Unicode.
Что такое «каналы»?	Каналы (channels) - это логические (не физические) порталы, абстракции объектов более низкого уровня файловой системы (например, отображенные в памяти файлы и блокировки файлов), через которые осуществляется ввод/вывод данных, а буферы являются источниками или приёмниками этих переданных данных. При организации вывода, данные, которые необходимо отправить, помещаются в буфер, который затем передается в канал. При вводе, данные из канала помещаются в заранее предоставленный буфер. Каналы напоминают трубопроводы, по которым эффективно транспортируются данные между буферами байтов и сущностями по ту сторону каналов. Каналы - это шлюзы, которые позволяют получить доступ к сервисам ввода/вывода операционной системы с минимальными накладными расходами, а буферы - внутренние конечные точки этих шлюзов, используемые для передачи и приема данных.
Какие существуют виды потоков ввода/вывода?	Разделяют два вида потоков ввода/вывода: байтовые - java.io.InputStream, java.io.OutputStream; символьные - java.io.Reader, java.io.Writer.
В каких пакетах расположены классы потоков ввода/вывода?	java.io, java.nio. Для работы с потоками компрессированных данных используются классы из пакета java.util.zip
Какие подклассы класса InputStream вы знаете, для чего они предназначены?	InputStream - абстрактный класс, описывающий поток ввода; BufferedInputStream - буферизованный входной поток; ByteArrayInputStream позволяет использовать буфер в памяти (массив байтов) в качестве источника данных для входного потока; DataInputStream - входной поток для байтовых данных, включающий методы для чтения стандартных типов данных Java; FileInputStream - входной поток для чтения информации из файла; FilterInputStream - абстрактный класс, предоставляющий интерфейс для классов-надстроек, которые добавляют к существующим потокам полезные свойства; ObjectInputStream - входной поток для объектов; StringBufferInputStream превращает строку (String) во входной поток данных InputStream; PipedInputStream реализует понятие входного канала; PushbackInputStream - разновидность буферизации, обеспечивающая чтение байта с последующим его возвратом в поток, позволяет «заглянуть» во входной поток и увидеть, что оттуда поступит в следующий момент, не извлекая информации. SequenceInputStream используется для слияния двух или более потоков InputStream в единый.
Для чего используется PushbackInputStream?	Разновидность буферизации, обеспечивающая чтение байта с последующим его возвратом в поток. Класс PushbackInputStream представляет механизм «заглянуть» во входной поток и увидеть, что оттуда поступит в следующий момент, не извлекая информации. У класса есть дополнительный метод unread().
Для чего используется SequenceInputStream?	Класс SequenceInputStream позволяет сливать вместе несколько экземпляров класса InputStream. Конструктор принимает в качестве аргумента либо пару объектов класса InputStream, либо интерфейс Enumeration. Во время работы класс выполняет запросы на чтение из первого объекта класса InputStream и до конца, а затем переключается на второй. При использовании интерфейса работа продолжится по всем объектам класса InputStream. По достижении конца, связанный с ним поток закрывается. Закрытие потока, созданного объектом класса SequenceInputStream, приводит к закрытию всех открытых потоков.
Какой класс позволяет читать данные из входного байтового потока в формате примитивных типов данных?	Класс DataInputStream представляет поток ввода и предназначен для записи данных примитивных типов, таких, как int, double и т.д. Для каждого примитивного типа определен свой метод для считывания:  boolean readBoolean(): считывает из потока булевое однобайтовое значение byte readByte(): считывает из потока 1 байт char readChar(): считывает из потока значение char double readDouble(): считывает из потока 8-байтовое значение double float readFloat(): считывает из потока 4-байтовое значение float int readInt(): считывает из потока целочисленное значение int long readLong(): считывает из потока значение long short readShort(): считывает значение short String readUTF(): считывает из потока строку в кодировке UTF-8
Какие подклассы класса OutputStream вы знаете, для чего они предназначены?	OutputStream - это абстрактный класс, определяющий потоковый байтовый вывод; BufferedOutputStream - буферизированный выходной поток; ByteArrayOutputStream - все данные, посылаемые в этот поток, размещаются в предварительно созданном буфере; DataOutputStream - выходной поток байт, включающий методы для записи стандартных типов данных Java; FileOutputStream - запись данных в файл на физическом носителе; FilterOutputStream - абстрактный класс, предоставляющий интерфейс для классов-надстроек, которые добавляют к существующим потокам полезные свойства; PrintStream - выходной поток, включающий методы print() и println(); ObjectOutputStream - выходной поток для записи объектов; PipedOutputStream реализует понятие выходного канала.
Какие подклассы класса Reader вы знаете, для чего они предназначены?	Reader - абстрактный класс, описывающий символьный ввод; BufferedReader - буферизованный входной символьный поток; CharArrayReader - входной поток, который читает из символьного массива; FileReader - входной поток, читающий файл; FilterReader - абстрактный класс, предоставляющий интерфейс для классов-надстроек; InputStreamReader- входной поток, транслирующий байты в символы; LineNumberReader - входной поток, подсчитывающий строки; PipedReader - входной канал; PushbackReader - входной поток, позволяющий возвращать символы обратно в поток; StringReader - входной поток, читающий из строки.
Какие подклассы класса Writer вы знаете, для чего они предназначены?	Writer - абстрактный класс, описывающий символьный вывод; BufferedWriter - буферизованный выходной символьный поток; CharArrayWriter - выходной поток, который пишет в символьный массив; FileWriter - выходной поток, пишущий в файл; FilterWriter - абстрактный класс, предоставляющий интерфейс для классов-надстроек; OutputStreamWriter - выходной поток, транслирующий байты в символы; PipedWriter - выходной канал; PrintWriter - выходной поток символов, включающий методы print() и println(); StringWriter - выходной поток, пишущий в строку;
В чем отличие класса PrintWriter от PrintStream?	Прежде всего, в классе PrintWriter применен усовершенствованный способ работы с символами Unicode и другой механизм буферизации вывода: в классе PrintStream буфер вывода сбрасывался всякий раз, когда вызывался метод print() или println(), а при использовании класса PrintWriter существует возможность отказаться от автоматического сброса буферов, выполняя его явным образом при помощи метода flush(). Кроме того, методы класса PrintWriter никогда не создают исключений. Для проверки ошибок необходимо явно вызвать метод checkError().
Чем отличаются и что общего у InputStream, OutputStream, Reader, Writer?	InputStream и его наследники - совокупность для получения байтовых данных из различных источников; OutputStream и его наследники - набор классов, определяющих потоковый байтовый вывод; Reader и его наследники определяют потоковый ввод символов Unicode; Writer и его наследники определяют потоковый вывод символов Unicode.
Какие классы позволяют преобразовать байтовые потоки в символьные и обратно?	OutputStreamWriter — «мост» между классом OutputStream и классом Writer. Символы, записанные в поток, преобразовываются в байты. InputStreamReader — аналог для чтения. При помощи методов класса Reader читаются байты из потока InputStream и далее преобразуются в символы
Какие классы позволяют ускорить чтение/запись за счет использования буфера?	BufferedInputStream(InputStream in)/BufferedInputStream(InputStream in, int size), BufferedOutputStream(OutputStream out)/BufferedOutputStream(OutputStream out, int size), BufferedReader(Reader r)/BufferedReader(Reader in, int sz), BufferedWriter(Writer out)/BufferedWriter(Writer out, int sz)
Какой класс предназначен для работы с элементами файловой системы?	File работает непосредственно с файлами и каталогами. Данный класс позволяет создавать новые элементы и получать информацию существующих: размер, права доступа, время и дату создания, путь к родительскому каталогу.
Какие методы класса File вы знаете?	Наиболее используемые методы класса File: boolean createNewFile(): делает попытку создать новый файл; boolean delete(): делает попытку удалить каталог или файл; boolean mkdir(): делает попытку создать новый каталог; boolean renameTo(File dest): делает попытку переименовать файл или каталог; boolean exists(): проверяет, существует ли файл или каталог; String getAbsolutePath(): возвращает абсолютный путь для пути, переданного в конструктор объекта; String getName(): возвращает краткое имя файла или каталога; String getParent(): возвращает имя родительского каталога; boolean isDirectory(): возвращает значение true, если по указанному пути располагается каталог; boolean isFile(): возвращает значение true, если по указанному пути находится файл; boolean isHidden(): возвращает значение true, если каталог или файл являются скрытыми; long length(): возвращает размер файла в байтах; long lastModified(): возвращает время последнего изменения файла или каталога; String[] list(): возвращает массив файлов и подкаталогов, которые находятся в определенном каталоге; File[] listFiles(): возвращает массив файлов и подкаталогов, которые находятся в определенном каталоге.
Что вы знаете об интерфейсе FileFilter?	Интерфейс FileFilter применяется для проверки, попадает ли объект File под некоторое условие. Этот интерфейс содержит единственный метод boolean accept(File pathName). Этот метод необходимо переопределить и реализовать. Например:  public boolean accept(final File file) { return file.isExists() && file.isDirectory(); }
Как выбрать все элементы определенного каталога по критерию (например, с определенным расширением)?	Метод File.listFiles() возвращает массив объектов File, содержащихся в каталоге. Метод может принимать в качестве параметра объект класса, реализующего FileFilter. Это позволяет включить в список только те элементы, для которых метод accept возвращает true (критерием может быть длина имени файла или его расширение).
Что вы знаете о RandomAccessFile?	Класс java.io.RandomAccessFile обеспечивает чтение и запись данных в произвольном месте файла. Он не является частью иерархии InputStream или OutputStream. Это полностью отдельный класс, имеющий свои собственные (в большинстве своем native) методы. Объяснением этого может быть то, что RandomAccessFile имеет во многом отличающееся поведение по сравнению с остальными классами ввода/вывода так как позволяет, в пределах файла, перемещаться вперед и назад.  RandomAccessFile имеет такие специфические методы как: - getFilePointer() для определения текущего местоположения в файле; - seek() для перемещения на новую позицию в файле; - length() для выяснения размера файла; - setLength() для установки размера файла; - skipBytes() для того, чтобы попытаться пропустить определённое число байт; - getChannel() для работы с уникальным файловым каналом, ассоциированным с заданным файлом; - методы для выполнения обычного и форматированного вывода из файла (read(), readInt(), readLine(), readUTF() и т.п.); - методы для обычной или форматированной записи в файл с прямым доступом (write(), writeBoolean(), writeByte() и т.п.).  Так же следует отметить, что конструкторы RandomAccessFile требуют второй аргумент, указывающий необходимый режим доступа к файлу - только чтение ("r"), чтение и запись ("rw") или иную их разновидность.
Какие режимы доступа к файлу есть у RandomAccessFile?	"r" открывает файл только для чтения. Запуск любых методов записи данных приведет к выбросу исключения IOException. "rw" открывает файл для чтения и записи. Если файл еще не создан, то осуществляется попытка создать его. "rws" открывает файл для чтения и записи подобно "rw", но требует от системы при каждом изменении содержимого файла или метаданных синхронно записывать эти изменения на физический носитель. "rwd" открывает файл для чтения и записи подобно "rws", но требует от системы синхронно записывать изменения на физический носитель только при каждом изменении содержимого файла. Если изменяются метаданные, синхронная запись не требуется.
Какие классы поддерживают чтение и запись потоков в компрессированном формате?	DeflaterOutputStream - компрессия данных в формате deflate. Deflater - компрессия данных в формат ZLIB ZipOutputStream - потомок DeflaterOutputStream для компрессии данных в формат Zip. GZIPOutputStream - потомок DeflaterOutputStream для компрессии данных в формат GZIP. InflaterInputStream - декомпрессия данных в формате deflate. Inflater - декомпрессия данных в формате ZLIB ZipInputStream - потомок InflaterInputStream для декомпрессии данных в формате Zip. GZIPInputStream - потомок InflaterInputStream для декомпрессии данных в формате GZIP.
Существует ли возможность перенаправить потоки стандартного ввода/вывода?	Класс System позволяет вам перенаправлять стандартный ввод, вывод и поток вывода ошибок, используя простой вызов статического метода: setIn(InputStream) - для ввода; setOut(PrintStream) - для вывода; setErr(PrintStream) - для вывода ошибок.
Какой символ является разделителем при указании пути в файловой системе?	Для различных операционных систем символ разделителя различается. Для Windows это \, для Linux - /. В Java получить разделитель для текущей операционной системы можно через обращение к статическому полю File.separator.
Что такое «абсолютный путь» и «относительный путь»?	Абсолютный (полный) путь это путь, который указывает на одно и то же место в файловой системе, вне зависимости от текущей рабочей директории или других обстоятельств. Полный путь всегда начинается с корневого каталога. Относительный путь представляет собой путь по отношению к текущему рабочему каталогу пользователя или активного приложения.
Что такое «символьная ссылка»?	Символьная (символическая) ссылка (также «симлинк», Symbolic link) — специальный файл в файловой системе, в котором, вместо пользовательских данных, содержится путь к файлу, который должен быть открыт при попытке обратиться к данной ссылке (файлу). Целью ссылки может быть любой объект: например, другая ссылка, файл, каталог или даже несуществующий файл (в последнем случае, при попытке открыть его, должно выдаваться сообщение об отсутствии файла). Символьные ссылки используются для более удобной организации структуры файлов на компьютере, так как: - позволяют для одного файла или каталога иметь несколько имён и различных атрибутов; - свободны от некоторых ограничений, присущих жёстким ссылкам (последние действуют только в пределах одной файловой системы (одного раздела) и не могут ссылаться на каталоги).
Что такое «сериализация»?	Сериализация (Serialization) - процесс преобразования структуры данных в линейную последовательность байтов для дальнейшей передачи или сохранения. Сериализованные объекты можно затем восстановить (десериализовать). В Java, согласно спецификации Java Object Serialization существует два стандартных способа сериализации: стандартная сериализация, через использование интерфейса java.io.Serializable и «расширенная» сериализация - java.io.Externalizable.  Сериализация позволяет в определенных пределах изменять класс. Вот наиболее важные изменения, с которыми спецификация Java Object Serialization может справляться автоматически:  - добавление в класс новых полей; - изменение полей из статических в нестатические; - изменение полей из транзитных в нетранзитные.  Обратные изменения (из нестатических полей в статические и из нетранзитных в транзитные) или удаление полей требуют определенной дополнительной обработки в зависимости от того, какая степень обратной совместимости необходима.
Опишите процесс сериализации/десериализации с использованием Serializable.	При использовании Serializable применяется алгоритм сериализации, который с помощью рефлексии (Reflection API) выполняет: - запись в поток метаданных о классе, ассоциированном с объектом (имя класса, идентификатор SerialVersionUID, идентификаторы полей класса); - рекурсивную запись в поток описания суперклассов до класса java.lang.Object (не включительно); - запись примитивных значений полей сериализуемого экземпляра, начиная с полей самого верхнего суперкласса; - рекурсивную запись объектов, которые являются полями сериализуемого объекта.  При этом ранее сериализованные объекты повторно не сериализуются, что позволяет алгоритму корректно работать с циклическими ссылками. Для выполнения десериализации под объект выделяется память, после чего его поля заполняются значениями из потока. Конструктор объекта при этом не вызывается. Однако при десериализации будет вызван конструктор без параметров родительского несериализуемого класса, а его отсутствие повлечёт ошибку десериализации.
Как изменить стандартное поведение сериализации/десериализации?	Реализовать интерфейс java.io.Externalizable, который позволяет применение пользовательской логики сериализации. Способ сериализации и десериализации описывается в методах writeExternal() и readExternal(). Во время десериализации вызывается конструктор без параметров, а потом уже на созданном объекте вызывается метод readExternal.  Если у сериализуемого объекта реализован один из следующих методов, то механизм сериализации будет использовать его, а не метод по умолчанию : writeObject() - запись объекта в поток; readObject() - чтение объекта из потока; writeReplace() - позволяет заменить себя экземпляром другого класса перед записью; readResolve() - позволяет заменить на себя другой объект после чтения.
Как исключить поля из сериализации?	Для управления сериализацией при определении полей можно использовать ключевое слово transient, таким образом исключив поля из общего процесса сериализации.
Что обозначает ключевое слово transient?	Поля класса, помеченные модификатором transient, не сериализуются. Обычно в таких полях хранится промежуточное состояние объекта, которое, к примеру, проще вычислить. Другой пример такого поля - ссылка на экземпляр объекта, который не требует сериализации или не может быть сериализован.
Какое влияние оказывают на сериализуемость модификаторы полей static и final	При стандартной сериализации поля, имеющие модификатор static, не сериализуются. Соответственно, после десериализации это поле значения не меняет. При использовании реализации Externalizable сериализовать и десериализовать статическое поле можно, но не рекомендуется этого делать, т.к. это может сопровождаться трудноуловимыми ошибками. Поля с модификатором final сериализуются как и обычные. За одним исключением - их невозможно десериализовать при использовании Externalizable, поскольку final поля должны быть инициализированы в конструкторе, а после этого в readExternal() изменить значение этого поля будет невозможно. Соответственно, если необходимо сериализовать объект с final полем необходимо использовать только стандартную сериализацию.
Как не допустить сериализацию?	Чтобы не допустить автоматическую сериализацию можно переопределить private методы для создания исключительной ситуации NotSerializableException.  private void writeObject(ObjectOutputStream out) throws IOException { throw new NotSerializableException(); } private void readObject(ObjectInputStream in) throws IOException { throw new NotSerializableException(); }  Любая попытка записать или прочитать этот объект теперь приведет к возникновению исключительной ситуации.
Как создать собственный протокол сериализации?	Для создания собственного протокола сериализации достаточно реализовать интерфейс Externalizable, который содержит два метода: public void writeExternal(ObjectOutput out) throws IOException; public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException;
Какая роль поля serialVersionUID в сериализации?	serialVersionUID используется для указания версии сериализованных данных. Когда мы не объявляем serialVersionUID в нашем классе явно, среда выполнения Java делает это за нас, но этот процесс чувствителен ко многим метаданным класса включая количество полей, тип полей, модификаторы доступа полей, интерфейсов, которые реализованы в классе и пр. Рекомендуется явно объявлять serialVersionUID т.к. при добавлении, удалении атрибутов класса динамически сгенерированное значение может измениться и в момент выполнения будет выброшено исключение InvalidClassException. private static final long serialVersionUID = 20161013L;
Когда стоит изменять значение поля serialVersionUID?	serialVersionUID нужно изменять при внесении в класс несовместимых изменений, например при удалении какого-либо его атрибута. к оглавлению В чем проблема сериализации Singleton? Проблема в том что после десериализации мы получим другой объект. Таким образом, сериализация дает возможность создать Singleton еще раз, что недопустимо. Существует два способа избежать этого: явный запрет сериализации. определение метода с сигнатурой (default/public/private/protected/) Object readResolve() throws ObjectStreamException, назначением которого станет возврат замещающего объекта вместо объекта, на котором он вызван.
Какие существуют способы контроля за значениями десериализованного объекта	Если есть необходимость выполнения контроля за значениями десериализованного объекта, то можно использовать интерфейс ObjectInputValidation с переопределением метода validateObject().  Если вызвать метод validateObject() после десериализации объекта, то будет вызвано исключение InvalidObjectException при значении возраста за пределами 39...60.  public class Person implements java.io.Serializable, java.io.ObjectInputValidation { ... @Override public void validateObject() throws InvalidObjectException { if ((age < 39) || (age > 60)) throw new InvalidObjectException("Invalid age"); } }  Так же существуют способы подписывания и шифрования, позволяющие убедиться, что данные не были изменены: - с помощью описания логики в writeObject() и readObject(). - поместить в оберточный класс javax.crypto.SealedObject и/или java.security.SignedObject. Данные классы являются сериализуемыми, поэтому при оборачивании объекта в SealedObject создается подобие «подарочной упаковки» вокруг исходного объекта. Для шифрования необходимо создать симметричный ключ, управление которым должно осуществляться отдельно. Аналогично, для проверки данных можно использовать класс SignedObject, для работы с которым также нужен симметричный ключ, управляемый отдельно.
Расскажите о модели памяти Java?	Модель памяти Java (Java Memory Model, JMM) описывает поведение потоков в среде исполнения Java. Это часть семантики языка Java, набор правил, описывающий выполнение многопоточных программ и правил, по которым потоки могут взаимодействовать друг с другом посредством основной памяти. Формально модель памяти определяет набор действий межпоточного взаимодействия (эти действия включают в себя, в частности, чтение и запись переменной, захват и освобождений монитора, чтение и запись volatile переменной, запуск нового потока), а также модель памяти определяет отношение между этими действиями -happens-before - абстракции обозначающей, что если операция X связана отношением happens-before с операцией Y, то весь код следуемый за операцией Y, выполняемый в одном потоке, видит все изменения, сделанные другим потоком, до операции X. Существует несколько основных правил для отношения happens-before: В рамках одного потока любая операция happens-before любой операцией, следующей за ней в исходном коде; Освобождение монитора (unlock) happens-before захват того же монитора (lock); Выход из synchronized блока/метода happens-before вход в synchronized блок/метод на том же мониторе; Запись volatile поля happens-before чтение того же самого volatile поля; Завершение метода run() экземпляра класса Thread happens-before выход из метода join() или возвращение false методом isAlive() экземпляром того же потока; Вызов метода start() экземпляра класса Thread happens-before начало метода run() экземпляра того же потока; Завершение конструктора happens-before начало метода finalize() этого класса; Вызов метода interrupt() на потоке happens-before обнаружению потоком факта, что данный метод был вызван либо путем выбрасывания исключения InterruptedException, либо с помощью методов isInterrupted() или interrupted(). Связь happens-before транзитивна, т.е. если X happens-before Y, а Y happens-before Z, то X happens-before Z. Освобождение/захват монитора и запись/чтение в volatile переменную связаны отношением happens-before, только если операции проводятся над одним и тем же экземпляром объекта. В отношении happens-before участвуют только два потока, о поведении остальных потоков ничего сказать нельзя, пока в каждом из них не наступит отношение happens-before с другим потоком. Можно выделить несколько основных областей, имеющих отношение к модели памяти: Видимость (visibility). Один поток может в какой-то момент временно сохранить значение некоторых полей не в основную память, а в регистры или локальный кэш процессора, таким образом второй поток, выполняемый на другом процессоре, читая из основной памяти, может не увидеть последних изменений поля. И наоборот, если поток на протяжении какого-то времени работает с регистрами и локальными кэшами, читая данные оттуда, он может сразу не увидеть изменений, сделанных другим потоком в основную память. К вопросу видимости имеют отношение следующие ключевые слов языка Java: synchronized, volatile, final. С точки зрения Java все переменные (за исключением локальных переменных, объявленных внутри метода) хранятся в главной памяти, которая доступна всем потокам, кроме этого, каждый поток имеет локальную—рабочую—память, где он хранит копии переменных, с которыми он работает, и при выполнении программы поток работает только с этими копиями. Надо отметить, что это описание не требование к реализации, а всего лишь модель, которая объясняет поведение программы, так, в качестве локальной памяти не обязательно выступает кэш память, это могут быть регистры процессора или потоки могут вообще не иметь локальной памяти. При входе в synchronized метод или блок поток обновляет содержимое локальной памяти, а при выходе из synchronized метода или блока поток записывает изменения, сделанные в локальной памяти, в главную. Такое поведение synchronized методов и блоков следует из правил для отношения «происходит раньше»: так как все операции с памятью происходят раньше освобождения монитора и освобождение монитора происходит раньше захвата монитора, то все операции с памятью, которые были сделаны потоком до выхода из synchronized блока должны быть видны любому потоку, который входит в synchronized блок для того же самого монитора. Очень важно, что это правило работает только в том случае, если потоки синхронизируются, используя один и тот же монитор! Что касается volatile переменных, то запись таких переменных производится в основную память, минуя локальную. и чтение volatile переменной производится также из основной памяти, то есть значение переменной не может сохраняться в регистрах или локальной памяти потока и операция чтения этой переменной гарантированно вернёт последнее записанное в неё значение. Также модель памяти определяет дополнительную семантику ключевого слова final, имеющую отношение к видимости: после того как объект был корректно создан, любой поток может видеть значения его final полей без дополнительной синхронизации. «Корректно создан» означает, что ссылка на создающийся объект не должна использоваться до тех пор, пока не завершился конструктор объекта. Наличие такой семантики для ключевого слова final позволяет создание неизменяемых (immutable) объектов, содержащих только final поля, такие объекты могут свободно передаваться между потоками без обеспечения синхронизации при передаче. Есть одна проблема, связанная с final полями: реализация разрешает менять значения таких полей после создания объекта (это может быть сделано, например, с использованием механизма reflection). Если значение final поля—константа, чьё значение известно на момент компиляции, изменения такого поля могут не иметь эффекта, так-как обращения к этой переменной могли быть заменены компилятором на константу. Также спецификация разрешает другие оптимизации, связанные с final полями, например, операции чтения final переменной могут быть переупорядочены с операциями, которые потенциально могут изменить такую переменную. Так что рекомендуется изменять final поля объекта только внутри конструктора, в противном случае поведение не специфицировано. Reordering (переупорядочивание). Для увеличения производительности процессор/компилятор могут переставлять местами некоторые инструкции/операции. Вернее, с точки зрения потока, наблюдающего за выполнением операций в другом потоке, операции могут быть выполнены не в том порядке, в котором они идут в исходном коде. Тот же эффект может наблюдаться, когда один поток кладет результаты первой операции в регистр или локальный кэш, а результат второй операции попадает непосредственно в основную память. Тогда второй поток, обращаясь к основной памяти может сначала увидеть результат второй операции, и только потом первой, когда все регистры или кэши синхронизируются с основной памятью. Еще одна причина reordering, может заключаться в том, что процессор может решить поменять порядок выполнения операций, если, например, сочтет что такая последовательность выполнится быстрее. Вопрос reordering также регулируется набором правил для отношения «происходит раньше» и у этих правил есть следствие, касающееся порядка операций, используемое на практике: операции чтения и записи volatile переменных не могут быть переупорядочены с операциями чтения и записи других volatile и не-volatile переменных. Это следствие делает возможным использование volatile переменной как флага, сигнализирующем об окончании какого-либо действия. В остальном правила, касающиеся порядка выполнения операций, гарантируют упорядоченность операций для конкретного набора случаев (таких как, например, захват и освобождение монитора), во всех остальных случаях оставляя компилятору и процессору полную свободу для оптимизаций.
Что такое «потокобезопасность»?	Потокобезопасность - свойство объекта или кода, которое гарантирует, что при исполнении или использовании несколькими потоками, код будет вести себя, как предполагается. Например потокобезопасный счётчик не пропустит ни один счёт, даже если один и тот же экземпляр этого счётчика будет использоваться несколькими потоками.
В чём разница между «конкуренцией» и «параллелизмом»?	Конкуренция это способ одновременного решения множества задач. Признаки: Наличие нескольких потоков управления (например, Thread в Java, корутина в Kotlin), если поток управления один, то конкурентного выполнения быть не может Недетерминированный результат выполнения. Результат зависит от случайных событий, реализации и того, как была проведена синхронизация. Даже если каждый поток полностью детерминированный, итоговый результат будет недетерминированным  Параллелизм это способ выполнения разных частей одной задачи. Признаки: Необязательно имеет несколько потоков управления Может приводить к детерминированному результату, так, например, результат умножения каждого элемента массива на число, не изменится, если умножать его по частям параллельно.
Что такое «кооперативная многозадачность»? Какой тип многозадачности использует Java? Чем обусловлен этот выбор?	Кооперативная многозадачность - это способ деления процессорного времени между потоками, при котором каждый поток обязан отдавать управление следующему добровольно. Преимущества такого подхода - простота реализации, меньшие накладные расходы на переключение контекста. Недостатки - если один поток завис или ведет себя некорректно, то зависает целиком вся система и другие потоки никогда не получат управление. Java использует вытесняющую многозадачность, при которой решение о переключении между потоками процесса принимает операционная система. В отличие от кооперативной многозадачности управление операционной системе передаётся вне зависимости от состояния работающих приложений, благодаря чему, отдельные зависшие потоки процесса, как правило, не «подвешивают» всю систему целиком. За счёт регулярного переключения между задачами также улучшается отзывчивость приложения и повышается оперативность освобождения ресурсов, которые больше не используются. В реализации вытесняющая многозадачность отличается от кооперативной, в частности, тем, что требует обработки системного прерывания от аппаратного таймера.
Что такое ordering, as-if-serial semantics, sequential consistency, visibility, atomicity, happens-before, mutual exclusion, safe publication?	ordering механизм, который определяет, когда один поток может увидеть out-of-order (неверный) порядок исполнения инструкций другого потока. CPU для для повышения производительности может переупорядочивать процессорные инструкции и выполнять их в произвольном порядке до тех пор пока для потока внутри не будет видно никаких отличий. Гарантия, предоставляемая этим механизмом, называется as-if-serial semantics.  sequential consistency - то же что и as-if-serial semantics, гарантия того, что в рамках одного потока побочные эффекты от всех операций будут такие, как будто все операции выполняются последовательно. visibility определяет, когда действия в одном потоке становятся видны из другого потока.  happens-before - логическое ограничение на порядок выполнения инструкций программы. Если указывается, что запись в переменную и последующее ее чтение связаны через эту зависимость, то как бы при выполнении не переупорядочивались инструкции, в момент чтения все связанные с процессом записи результаты уже зафиксированы и видны.  atomicity — атомарность операций. Атомарная операция выглядит единой и неделимой командой процессора, которая может быть или уже выполненной или ещё невыполненной.  mutual exclusion (взаимоисключающая locking, семафор с одним состоянием) - механизм, гарантирующий потоку исключительный доступ к ресурсу. Используется для предотвращения одновременного доступа к общему ресурсу. В каждый момент времени таким ресурсом может владеть только один поток. Простейший пример:  synchronized(obj) { ... }. safe publication? - показ объектов другим потокам из текущего, не нарушая ограничений visibility. Способы такой публикации в Java: static{} инициализатор; volatile переменные; atomic переменные; сохранение в разделяемой переменной, корректно защищенной с использованием synchronized(), синхронизаторов или других конструкций, создающих read/write memory barrier; final переменные в разделяемом объекте, который был корректно проинициализирован.
Чем отличается процесс от потока?	Процесс — экземпляр программы во время выполнения, независимый объект, которому выделены системные ресурсы (например, процессорное время и память). Каждый процесс выполняется в отдельном адресном пространстве: один процесс не может получить доступ к переменным и структурам данных другого. Если процесс хочет получить доступ к чужим ресурсам, необходимо использовать межпроцессное взаимодействие. Это могут быть конвейеры, файлы, каналы связи между компьютерами и многое другое. Для каждого процесса ОС создает так называемое «виртуальное адресное пространство», к которому процесс имеет прямой доступ. Это пространство принадлежит процессу, содержит только его данные и находится в полном его распоряжении. Операционная система же отвечает за то, как виртуальное пространство процесса проецируется на физическую память. Поток(thread) — определенный способ выполнения процесса, определяющий последовательность исполнения кода в процессе. Потоки всегда создаются в контексте какого-либо процесса, и вся их жизнь проходит только в его границах. Потоки могут исполнять один и тот же код и манипулировать одними и теми же данными, а также совместно использовать описатели объектов ядра, поскольку таблица описателей создается не в отдельных потоках, а в процессах. Так как потоки расходуют существенно меньше ресурсов, чем процессы, в процессе выполнения работы выгоднее создавать дополнительные потоки и избегать создания новых процессов.
Что такое «зелёные потоки» и есть ли они в Java?	Зелёные (легковесные) потоки(green threads) - потоки эмулируемые виртуальной машиной или средой исполнения. Создание зелёного потока не подразумевает под собой создание реального потока ОС. Виртуальная машина Java берёт на себя заботу о переключении между разными green threads, а сама машина работает как один поток ОС. Это даёт несколько преимуществ. Потоки ОС относительно дороги в большинстве POSIX-систем. Кроме того, переключение между native threads гораздо медленнее, чем между green threads. Это всё означает, что в некоторых ситуациях green threads гораздо выгоднее, чем native threads. Система может поддерживать гораздо большее количество green threads, чем потоков OС. Например, гораздо практичнее запускать новый green thread для нового HTTP-соединения к веб-серверу, вместо создания нового native thread. Однако есть и недостатки. Самый большой заключается в том, что вы не можете исполнять два потока одновременно. Поскольку существует только один native thread, только он и вызывается планировщиком ОС. Даже если у вас несколько процессоров и несколько green threads, только один процессор может вызывать green thread. И всё потому, что с точки зрения планировщика заданий ОС всё это выглядит одним потоком. Начиная с версии 1.2 Java поддерживает native threads, и с тех пор они используются по умолчанию.
Каким образом можно создать поток?	Создать потомка класса Thread и переопределить его метод run();  Создать объект класса Thread, передав ему в конструкторе экземпляр класса, реализующего интерфейс Runnable. Эти интерфейс содержит метод run(), который будет выполняться в новом потоке. Поток закончит выполнение, когда завершится его метод run().  Вызвать метод submit() у экземпляра класса реализующего интерфейс ExecutorService, передав ему в качестве параметра экземпляр класса реализующего интерфейс Runnable или Callable (содержит метод call(), в котором описывается логика выполнения).
Чем различаются Thread и Runnable?	Thread - это класс, некоторая надстройка над физическим потоком. Runnable - это интерфейс, представляющий абстракцию над выполняемой задачей. Помимо того, что Runnable помогает разрешить проблему множественного наследования, несомненный плюс от его использования состоит в том, что он позволяет логически отделить логику выполнения задачи от непосредственного управления потоком.
В чём заключается разница между методами start() и run()?	Несмотря на то, что start() вызывает метод run() внутри себя, это не то же самое, что просто вызов run(). Если run() вызывается как обычный метод, то он вызывается в том же потоке и никакой новый поток не запускается, как это происходит, в случае, когда вы вызываете метод start().
Как принудительно запустить поток?	Никак. В Java не существует абсолютно никакого способа принудительного запуска потока. Это контролируется JVM и Java не предоставляет никакого API для управления этим процессом.
Что такое «монитор» в Java?	Монитор, мьютекс (mutex) - это средство обеспечения контроля за доступом к ресурсу. У монитора может быть максимум один владелец в каждый текущий момент времени. Следовательно, если кто-то использует ресурс и захватил монитор для обеспечения единоличного доступа, то другой, желающий использовать тот же ресурс, должен подождать освобождения монитора, захватить его и только потом начать использовать ресурс. Удобно представлять монитор как id захватившего его объекта. Если этот id равен 0 - ресурс свободен. Если не 0 - ресурс занят. Можно встать в очередь и ждать его освобождения. В Java у каждого экземпляра объекта есть монитор, который контролируется непосредственно виртуальной машиной. Используется он так: любой нестатический synchronized-метод при своем вызове прежде всего пытается захватить монитор того объекта, у которого он вызван (на который он может сослаться как на this). Если это удалось - метод исполняется. Если нет - поток останавливается и ждет, пока монитор будет отпущен.
Дайте определение понятию «синхронизация».	Синхронизация - это процесс, который позволяет выполнять потоки параллельно. В Java все объекты имеют одну блокировку, благодаря которой только один поток одновременно может получить доступ к критическому коду в объекте. Такая синхронизация помогает предотвратить повреждение состояния объекта. Если поток получил блокировку, ни один другой поток не может войти в синхронизированный код, пока locking не будет снята. Когда поток, владеющий блокировкой, выходит из синхронизированного кода, locking снимается. Теперь другой поток может получить блокировку объекта и выполнить синхронизированный код. Если поток пытается получить блокировку объекта, когда другой поток владеет блокировкой, поток переходит в состояние Блокировки до тех пор, пока locking не снимется.
Какие существуют способы синхронизации в Java?	Системная синхронизация с использованием wait()/notify(). Поток, который ждет выполнения каких-либо условий, вызывает у этого объекта метод wait(), предварительно захватив его монитор. На этом его работа приостанавливается. Другой поток может вызвать на этом же самом объекте метод notify() (опять же, предварительно захватив монитор объекта), в результате чего, ждущий на объекте поток «просыпается» и продолжает свое выполнение. В обоих случаях монитор надо захватывать в явном виде, через synchronized-блок, потому как методы wait()/notify() не синхронизированы!  Системная синхронизация с использованием join(). Метод join(), вызванный у экземпляра класса Thread, позволяет текущему потоку остановиться до того момента, как поток, связанный с этим экземпляром, закончит работу.  Использование классов из пакета java.util.concurrent, который предоставляет набор классов для организации межпоточного взаимодействия. Примеры таких классов - Lock, Semaphore и пр.. Концепция данного подхода заключается в использовании атомарных операций и переменных.
В каких состояниях может находиться поток?	Потоки могут находиться в одном из следующих состояний: Новый (New). После создания экземпляра потока, он находится в состоянии Новый до тех пор, пока не вызван метод start(). В этом состоянии поток не считается живым.  Работоспособный  (Runnable). Поток переходит в состояние Работоспособный, когда вызывается метод start(). Поток может перейти в это состояние также из состояния   Работающий или из состояния Блокирован. Когда поток находится в этом состоянии, он считается живым. Работающий (Running). Поток переходит из состояния Работоспособный в состояние Работающий, когда Планировщик потоков выбирает его как работающий в данный момент.  Живой, но не работоспособный (Alive, but not runnable). Поток может быть живым, но не работоспособным по нескольким причинам:Ожидание (Waiting). Поток переходит в состояние Ожидания, вызывая метод wait(). Вызов notify() или notifyAll() может перевести поток из состояния Ожидания в состояние Работоспособный.Сон (Sleeping). Метод sleep() переводит поток в состояние Сна на заданный промежуток времени в миллисекундах.Блокировка (Blocked). Поток может перейти в это состояние, в ожидании ресурса, такого как ввод/вывод или из-за блокировки другого объекта. В этом случае поток переходит в состояние Работоспособный, когда ресурс становится доступен.Мёртвый (Dead). Поток считается мёртвым, когда его метод run() полностью выполнен. Мёртвый поток не может перейти ни в какое другое состояние, даже если для него вызван метод start().
Можно ли создавать новые экземпляры класса, пока выполняется static synchronized метод?	Да, можно создавать новые экземпляры класса, так как статические поля не принадлежат к экземплярам класса.
Зачем может быть нужен private мьютекс?	Объект для синхронизации делается private, чтобы сторонний код не мог на него синхронизироваться и случайно получить взаимную блокировку.
Как работают методы wait() и notify()/notifyAll()?	Эти методы определены у класса Object и предназначены для взаимодействия потоков между собой при межпоточной синхронизации. wait(): освобождает монитор и переводит вызывающий поток в состояние ожидания до тех пор, пока другой поток не вызовет метод notify()/notifyAll(); notify(): продолжает работу потока, у которого ранее был вызван метод wait(); notifyAll(): возобновляет работу всех потоков, у которых ранее был вызван метод wait(). Когда вызван метод wait(), поток освобождает блокировку на объекте и переходит из состояния Работающий (Running) в состояние Ожидания (Waiting). Метод notify() подаёт сигнал одному из потоков, ожидающих на объекте, чтобы перейти в состояние Работоспособный (Runnable). При этом невозможно определить, какой из ожидающих потоков должен стать работоспособным. Метод notifyAll() заставляет все ожидающие потоки для объекта вернуться в состояние Работоспособный (Runnable). Если ни один поток не находится в ожидании на методе wait(), то при вызове notify() или notifyAll() ничего не происходит. Поток может вызвать методы wait() или notify() для определённого объекта, только если он в данный момент имеет блокировку на этот объект. wait(), notify() и notifyAll() должны вызываться только из синхронизированного кода.
В чем разница между notify() и notifyAll()?	Дело в том, что «висеть» на методе wait() одного монитора могут сразу несколько потоков. При вызове notify() только один из них выходит из wait() и пытается захватить монитор, а затем продолжает работу со следующего после wait() оператора. Какой из них выйдет - заранее неизвестно. А при вызове notifyAll(), все висящие на wait() потоки выходят из wait(), и все они пытаются захватить монитор. Понятно, что в любой момент времени монитор может быть захвачен только одним потоком, а остальные ждут своей очереди. Порядок очереди определяется планировщиком потоков Java.
Почему методы wait() и notify() вызываются только в синхронизированном блоке?	Монитор надо захватывать в явном виде (через synchronized-блок), потому что методы wait() и notify() не синхронизированы.
Чем отличается работа метода wait() с параметром и без параметра?	wait() без параметров освобождает монитор и переводит вызывающий поток в состояние ожидания до тех пор, пока другой поток не вызовет метод notify()/notifyAll(), с параметрами заставит поток ожидать заданное количество времени или вызова notify()/notifyAll().
Чем отличаются методы Thread.sleep() и Thread.yield()?	Метод yield() служит причиной того, что поток переходит из состояния работающий (running) в состояние работоспособный (runnable), давая возможность другим потокам активизироваться. Но следующий выбранный для запуска поток может и не быть другим. Метод sleep() вызывает засыпание текущего потока на заданное время, состояние изменяется с работающий (running) на ожидающий (waiting).
Как работает метод Thread.join()?	Когда поток вызывает join() для другого потока, текущий работающий поток будет ждать, пока другой поток, к которому он присоединяется, не будет завершён: void join()  void join(long millis) void join(long millis, int nanos)
Что такое deadlock?	Взаимная locking (deadlock) - явление, при котором все потоки находятся в режиме ожидания. Происходит, когда достигаются состояния: взаимного исключения: по крайней мере один ресурс занят в режиме неделимости и, следовательно, только один поток может использовать ресурс в любой данный момент времени. удержания и ожидания: поток удерживает как минимум один ресурс и запрашивает дополнительные ресурсов, которые удерживаются другими потоками. отсутствия предочистки: операционная система не переназначивает ресурсы: если они уже заняты, они должны отдаваться удерживающим потокам сразу же. цикличного ожидания: поток ждёт освобождения ресурса, другим потоком, который в свою очередь ждёт освобождения ресурса заблокированного первым потоком. Простейший способ избежать взаимной блокировки - не допускать цикличного ожидания. Этого можно достичь, получая мониторы разделяемых ресурсов в определённом порядке и освобождая их в обратном порядке.
Что такое livelock?	livelock - тип взаимной блокировки, при котором несколько потоков выполняют бесполезную работу, попадая в зацикленность при попытке получения каких-либо ресурсов. При этом их состояния постоянно изменяются в зависимости друг от друга. Фактической ошибки не возникает, но КПД системы падает до 0. Часто возникает в результате попыток предотвращения deadlock. Реальный пример livelock, - когда два человека встречаются в узком коридоре и каждый, пытаясь быть вежливым, отходит в сторону, и так они бесконечно двигаются из стороны в сторону, абсолютно не продвигаясь в нужном им направлении.
Как проверить, удерживает ли поток монитор определённого ресурса?	Метод Thread.holdsLock(lock) возвращает true, когда текущий поток удерживает монитор у определённого объекта.
На каком объекте происходит синхронизация при вызове static synchronized метода?	У синхронизированного статического метода нет доступа к this, но есть доступ к объекту класса Class, он присутствует в единственном экземпляре и именно он выступает в качестве монитора для синхронизации статических методов. Таким образом, следующая конструкция: public class SomeClass { public static synchronized void someMethod() { //code } } эквивалентна такой: public class SomeClass { public static void someMethod(){ synchronized(SomeClass.class){ //code } } }
Для чего используется ключевое слово volatile, synchronized, transient, native?	volatile - этот модификатор вынуждает потоки отключить оптимизацию доступа и использовать единственный экземпляр переменной. Если переменная примитивного типа - этого будет достаточно для обеспечения потокобезопасности. Если же переменная является ссылкой на объект - синхронизировано будет исключительно значение этой ссылки. Все же данные, содержащиеся в объекте, синхронизированы не будут! synchronized - это зарезервированное слово позволяет добиваться синхронизации в помеченных им методах или блоках кода. Ключевые слова transient и native к многопоточности никакого отношения не имеют, первое используется для указания полей класса, которые не нужно сериализовать, а второе - сигнализирует о том, что метод реализован в платформо-зависимом коде.
В чём различия между volatile и Atomic переменными?	volatile принуждает использовать единственный экземпляр переменной, но не гарантирует атомарность. Например, операция count++ не станет атомарной просто потому, что count объявлена volatile. C другой стороны class AtomicInteger предоставляет атомарный метод для выполнения таких комплексных операций атомарно, например getAndIncrement() - атомарная замена оператора инкремента, его можно использовать, чтобы атомарно увеличить текущее значение на один. Похожим образом сконструированы атомарные версии и для других типов данных.
В чём заключаются различия между java.util.concurrent.Atomic*.compareAndSwap() и java.util.concurrent.Atomic*.weakCompareAndSwap()	weakCompareAndSwap() не создает memory barrier и не дает гарантии happens-before; weakCompareAndSwap() сильно зависит от кэша/CPU, и может возвращать false без видимых причин; weakCompareAndSwap(), более легкая, но поддерживаемая далеко не всеми архитектурами и не всегда эффективная операция.
Что значит «приоритет потока»?	Приоритеты потоков используются планировщиком потоков для принятия решений о том, когда какому из потоков будет разрешено работать. Теоретически высокоприоритетные потоки получают больше времени процессора, чем низкоприоритетные. Практически объем времени процессора, который получает поток, часто зависит от нескольких факторов помимо его приоритета. Чтобы установить приоритет потока, используется метод класса Thread: final void setPriority(int level). Значение level изменяется в пределах от Thread.MIN_PRIORITY = 1 до Thread.MAX_PRIORITY = 10. Приоритет по умолчанию - Thread.NORM_PRlORITY = 5. Получить текущее значение приоритета потока можно вызвав метод: final int getPriority() у экземпляра класса Thread
Что такое «потоки-демоны»?	Потоки-демоны работают в фоновом режиме вместе с программой, но не являются неотъемлемой частью программы. Если какой-либо процесс может выполняться на фоне работы основных потоков выполнения и его деятельность заключается в обслуживании основных потоков приложения, то такой процесс может быть запущен как поток-демон с помощью метода setDaemon(boolean value), вызванного у потока до его запуска. Метод boolean isDaemon() позволяет определить, является ли указанный поток демоном или нет. Базовое свойство потоков-демонов заключается в возможности основного потока приложения завершить выполнение потока-демона (в отличие от обычных потоков) с окончанием кода метода main(), не обращая внимания на то, что поток-демон еще работает.
Можно ли сделать основной поток программы демоном?	Нет. Потоки-демоны позволяют описывать фоновые процессы, которые нужны только для обслуживания основных потоков выполнения и не могут существовать без них.
Что значит «усыпить» поток?	Это значит приостановить его на определенный промежуток времени, вызвав в ходе его выполнения статический метод Thread.sleep() передав в качестве параметра необходимое количество времени в миллисекундах. До истечения этого времени поток может быть выведен из состояния ожидания вызовом interrupt() с выбрасыванием InterruptedException.
Чем отличаются два интерфейса Runnable и Callable?	Интерфейс Runnable появился в Java 1.0, а интерфейс Callable был введен в Java 5.0 в составе библиотеки java.util.concurrent; Классы, реализующие интерфейс Runnable для выполнения задачи должны реализовывать метод run(). Классы, реализующие интерфейс Callable - метод call(); Метод Runnable.run() не возвращает никакого значения, Callable.call() возвращает объект Future, который может содержать результат вычислений; Метод run() не может выбрасывать проверяемые исключения, в то время как метод call() может.
Что такое FutureTask?	FutureTask представляет собой отменяемое асинхронное вычисление в параллельном Java приложении. Этот класс предоставляет базовую реализацию Future, с методами для запуска и остановки вычисления, методами для запроса состояния вычисления и извлечения результатов. Результат может быть получен только когда вычисление завершено, метод получения будет заблокирован, если вычисление ещё не завершено. Объекты FutureTask могут быть использованы для обёртки объектов Callable и Runnable. Так как FutureTask реализует Runnable, его можно передать в Executor на выполнение.
В чем заключаются различия между CyclicBarrier и CountDownLatch?	CountDownLatch (замок с обратным отсчетом) предоставляет возможность любому количеству потоков в блоке кода ожидать до тех пор, пока не завершится определенное количество операций, выполняющихся в других потоках, перед тем как они будут «отпущены», чтобы продолжить свою деятельность. В конструктор CountDownLatch(int count) обязательно передается количество операций, которое должно быть выполнено, чтобы замок «отпустил» заблокированные потоки. Примером CountDownLatch из жизни может служить сбор экскурсионной группы: пока не наберется определенное количество человек, экскурсия не начнется. CyclicBarrier реализует шаблон синхронизации «Барьер». Циклический барьер является точкой синхронизации, в которой указанное количество параллельных потоков встречается и блокируется. Как только все потоки прибыли, выполняется опционное действие (или не выполняется, если барьер был инициализирован без него), и, после того, как оно выполнено, барьер ломается и ожидающие потоки «освобождаются». В конструкторы барьера CyclicBarrier(int parties) и CyclicBarrier(int parties, Runnable barrierAction) обязательно передается количество сторон, которые должны «встретиться», и, опционально, действие, которое должно произойти, когда стороны встретились, но перед тем когда они будут «отпущены». CyclicBarrier является альтернативой метода join(), который «собирает» потоки только после того, как они выполнились. CyclicBarrier похож на CountDownLatch, но главное различие между ними в том, что использовать «замок» можно лишь единожды - после того, как его счётчик достигнет нуля, а «барьер» можно использовать неоднократно, даже после того, как он «сломается».
Как остановить поток?	На данный момент в Java принят уведомительный порядок остановки потока (хотя JDK 1.0 и имеет несколько управляющих выполнением потока методов, например stop(), suspend() и resume() - в следующих версиях JDK все они были помечены как deprecated из-за потенциальных угроз взаимной блокировки). Для корректной остановки потока можно использовать метод класса Thread - interrupt(). Этот метод выставляет некоторый внутренний флаг-статус прерывания. В дальнейшем состояние этого флага можно проверить с помощью метода isInterrupted() или Thread.interrupted() (для текущего потока). Метод interrupt() также способен вывести поток из состояния ожидания или спячки. Т.е. если у потока были вызваны методы sleep() или wait() - текущее состояние прервется и будет выброшено исключение InterruptedException. Флаг в этом случае не выставляется. Схема действия при этом получается следующей: Реализовать поток. В потоке периодически проводить проверку статуса прерывания через вызов isInterrupted(). Если состояние флага изменилось или было выброшено исключение во время ожидания/спячки, следовательно поток пытаются остановить извне. Принять решение - продолжить работу (если по каким-то причинам остановиться невозможно) или освободить заблокированные потоком ресурсы и закончить выполнение. Возможная проблема, которая присутствует в этом подходе - блокировки на потоковом вводе-выводе. Если поток заблокирован на чтении данных - вызов interrupt() из этого состояния его не выведет. Решения тут различаются в зависимости от типа источника данных. Если чтение идет из файла - долговременная locking крайне маловероятна и тогда можно просто дождаться выхода из метода read(). Если же чтение каким-то образом связано с сетью - стоит использовать неблокирующий ввод-вывод из Java NIO. Второй вариант реализации метода остановки (а также и приостановки) - сделать собственный аналог interrupt(). Т.е. объявить в классе потока флаги - на остановку и/или приостановку и выставлять их путем вызова заранее определённых методов извне. Методика действия при этом остаётся прежней - проверять установку флагов и принимать решения при их изменении. Недостатки такого подхода. Во-первых, потоки в состоянии ожидания таким способом не «оживить». Во-вторых, выставление флага одним потоком совсем не означает, что второй поток тут же его увидит. Для увеличения производительности виртуальная машина использует кеш данных потока, в результате чего обновление переменной у второго потока может произойти через неопределенный промежуток времени (хотя допустимым решением будет объявить переменную-флаг как volatile).
Почему не рекомендуется использовать метод Thread.stop()?	При принудительной остановке (приостановке) потока, stop() прерывает поток в недетерменированном месте выполнения, в результате становится совершенно непонятно, что делать с принадлежащими ему ресурсами. Поток может открыть сетевое соединение - что в таком случае делать с данными, которые еще не вычитаны? Где гарантия, что после дальнейшего запуска потока (в случае приостановки) он сможет их дочитать? Если поток блокировал разделяемый ресурс, то как снять эту блокировку и не переведёт ли принудительное снятие к нарушению консистентности системы? То же самое можно расширить и на случай соединения с базой данных: если поток остановят посередине транзакции, то кто ее будет закрывать? Кто и как будет разблокировать ресурсы?
Что происходит, когда в потоке выбрасывается исключение?	Если исключение не поймано - поток «умирает» (переходит в состяние мёртв (dead)). Если установлен обработчик непойманных исключений, то он возьмёт управление на себя. Thread.UncaughtExceptionHandler - интерфейс, определённый как вложенный интерфейс для других обработчиков, вызываемых, когда поток внезапно останавливается из-за непойманного исключения. В случае, если поток собирается остановиться из-за непойманного исключения, JVM проверяет его на наличие UncaughtExceptionHandler, используя Thread.getUncaughtExceptionHandler(), и если такой обработчик найдет, то вызовет у него метод uncaughtException(), передав этот поток и исключение в виде аргументов.
В чем разница между interrupted() и isInterrupted()?	Механизм прерывания работы потока в Java реализован с использованием внутреннего флага, известного как статус прерывания. Прерывание потока вызовом Thread.interrupt() устанавливает этот флаг. Методы Thread.interrupted() и isInterrupted() позволяют проверить, является ли поток прерванным. Когда прерванный поток проверяет статус прерывания, вызывая статический метод Thread.interrupted(), статус прерывания сбрасывается. Нестатический метод isInterrupted() используется одним потоком для проверки статуса прерывания у другого потока, не изменяя флаг прерывания.
Что такое «пул потоков»?	Создание потока является затратной по времени и ресурсам операцией. Количество потоков, которое может быть запущено в рамках одного процесса также ограниченно. Чтобы избежать этих проблем и в целом управлять множеством потоков более эффективно в Java был реализован механизм пула потоков (thread pool), который создаётся во время запуска приложения и в дальнейшем потоки для обработки запросов берутся и переиспользуются уже из него. Таким образом, появляется возможность не терять потоки, сбалансировать приложение по количеству потоков и частоте их создания.  Начиная с Java 1.5 Java API предоставляет фреймворк Executor, который позволяет создавать различные типы пула потоков:  Executor - упрощенный интерфейс пула, содержит один метод для передачи задачи на выполнение;  ExecutorService - расширенный интерфейс пула, с возможностью завершения всех потоков;  AbstractExecutorService - базовый класс пула, реализующий интерфейс ExecutorService;  Executors - фабрика объектов связанных с пулом потоков, в том числе позволяет создать основные типы пулов;  ThreadPoolExecutor - пул потоков с гибкой настройкой, может служить базовым классом для нестандартных пулов;  ForkJoinPool - пул для выполнения задач типа ForkJoinTask; ... и другие.  Методы Executors для создания пулов:  newCachedThreadPool() - если есть свободный поток, то задача выполняется в нем, иначе добавляется новый поток в пул. Потоки не используемые больше минуты завершаются и удалются и кэша. Размер пула неограничен. Предназначен для выполнения множество небольших асинхронных задач;  newCachedThreadPool(ThreadFactory threadFactory) - аналогично предыдущему, но с собственной фабрикой потоков;  newFixedThreadPool(int nThreads) - создает пул на указанное число потоков. Если новые задачи добавлены, когда все потоки активны, то они будут сохранены в очереди для выполнения позже. Если один из потоков завершился из-за ошибки, на его место будет запущен другой поток. Потоки живут до тех пор, пока пул не будет закрыт явно методом shutdown().  newFixedThreadPool(int nThreads, ThreadFactory threadFactory) - аналогично предыдущему, но с собственной фабрикой потоков;  newSingleThreadScheduledExecutor() - однопотоковый пул с возможностью выполнять задачу через указанное время или выполнять периодически. Если поток был завершен из-за каких-либо ошибок, то для выполнения следующей задачи будет создан новый поток.  newSingleThreadScheduledExecutor(ThreadFactory threadFactory) - аналогично предыдущему, но с собственной фабрикой потоков; newScheduledThreadPool(int corePoolSize) - пул для выполнения задач через указанное время или переодически;  newScheduledThreadPool(int corePoolSize, ThreadFactory threadFactory) - аналогично предыдущему, но с собственной фабрикой потоков;  unconfigurableExecutorService(ExecutorService executor) - обертка на пул, запрещающая изменять его конфигурацию;
Какого размера должен быть пул потоков?	Настраивая размер пула потоков, важно избежать двух ошибок: слишком мало потоков (очередь на выполнение будет расти, потребляя много памяти) или слишком много потоков (замедление работы всей систему из-за частых переключений контекста). Оптимальный размер пула потоков зависит от количества доступных процессоров и природы задач в рабочей очереди. На N-процессорной системе для рабочей очереди, которая будет выполнять исключительно задачи с ограничением по скорости вычислений, можно достигнуть максимального использования CPU с пулом потоков, в котором содержится N или N+1 поток. Для задач, которые могут ждать осуществления I/O (ввода - вывода) - например, задачи, считывающей HTTP-запрос из сокета - может понадобиться увеличение размера пула свыше количества доступных процессоров, потому, что не все потоки будут работать все время. Используя профилирование, можно оценить отношение времени ожидания (WT) ко времени обработки (ST) для типичного запроса. Если назвать это соотношение WT/ST, то для N-процессорной системе понадобится примерно N*(1 + WT/ST) потоков для полной загруженности процессоров. Использование процессора - не единственный фактор, важный при настройке размера пула потоков. По мере возрастания пула потоков, можно столкнуться с ограничениями планировщика, доступной памяти, или других системных ресурсов, таких, как количество сокетов, дескрипторы открытого файла, или каналы связи базы данных.
Что будет, если очередь пула потоков уже заполнена, но подаётся новая задача?	Если очередь пула потоков заполнилась, то поданная задача будет «отклонена». Например - метод submit() у ThreadPoolExecutor выкидывает RejectedExecutionException, после которого вызывается RejectedExecutionHandler.
В чём заключается различие между методами submit() и execute() у пула потоков?	Оба метода являются способами подачи задачи в пул потоков, но между ними есть небольшая разница. execute(Runnable command) определён в интерфейсе Executor и выполняет поданную задачу и ничего не возвращает. submit() - перегруженный метод, определённый в интерфейсе ExecutorService. Способен принимать задачи типов Runnable и Callable и возвращать объект Future, который можно использовать для контроля и управления процессом выполнения, получения его результата.
В чем заключаются различия между cтеком (stack) и кучей (heap) с точки зрения многопоточности?	Cтек - участок памяти, тесно связанный с потоками. У каждого потока есть свой стек, которые хранит локальные переменные, параметры методов и стек вызовов. Переменная, хранящаяся в стеке одного потока, не видна для другого. Куча - общий участок памяти, который делится между всеми потоками. Объекты, неважно локальные или любого другого уровня, создаются в куче. Для улучшения производительности, поток обычно кэширует значения из кучи в свой стек, в этом случае для того, чтобы указать потоку, что переменную следует читать из кучи используется ключевое слово volatile.
Как поделиться данными между двумя потоками?	Данными между потоками возможно делиться, используя общий объект или параллельные структуры данных, например BlockingQueue.
Какой параметр запуска JVM используется для контроля размера стека потока?	-Xss
Как получить дамп потока?	Среды исполнения Java на основе HotSpot генерируют только дамп в формате HPROF. В распоряжении разработчика имеется несколько интерактивных методов генерации дампов и один метод генерации дампов на основе событий. Интерактивные методы:  Использование Ctrl+Break: если для исполняющегося приложения установлена опция командной строки -XX:+HeapDumpOnCtrlBreak, то дамп формата HPROF генерируется вместе с дампом потока при наступлении события Ctrl+Break или SIGQUIT (обычно генерируется с помощью kill -3), которое инициируется посредством консоли. Эта опция может быть недоступна в некоторых версиях. В этом случае можно попытаться использовать следующую опцию: -Xrunhprof:format=b,file=heapdump.hprof  Использование инструмента jmap: утилита jmap, поставляемая в составе каталога /bin/ комплекта JDK, позволяет запрашивать дамп HPROF из исполняющегося процесса.  Использование операционной системы: Для создания файла ядра можно воспользоваться неразрушающей командой gcore или разрушающими командами kill -6 или kill -11. Затем извлечь дамп кучи из файла ядра с помощью утилиты jmap.  Использование инструмента JConsole. Операция dumpHeap предоставляется в JConsole как MBean-компонент HotSpotDiagnostic. Эта операция запрашивает генерацию дампа в формате HPROF.  Метод на основе событий:  Событие OutOfMemoryError: Если для исполняющегося приложения установлена опция командной строки -XX:+HeapDumpOnOutOfMemoryError, то при возникновении ошибки OutOfMemoryError генерируется дамп формата HPROF. Это идеальный метод для «production» систем, поскольку он практически обязателен для диагностирования проблем памяти и не сопровождается постоянными накладными расходами с точки зрения производительности. В старых выпусках сред исполнения Java на базе HotSpot для этого события не устанавливается предельное количество дампов кучи в пересчете на одну JVM; в более новых выпусках допускается не более одного дампа кучи для этого события на каждый запуск JVM.
Что такое ThreadLocal-переменная?	ThreadLocal - класс, позволяющий имея одну переменную, иметь различное её значение для каждого из потоков. У каждого потока - т.е. экземпляра класса Thread - есть ассоциированная с ним таблица ThreadLocal-переменных. Ключами таблицы являются cсылки на объекты класса ThreadLocal, а значениями - ссылки на объекты, «захваченные» ThreadLocal-переменными, т.е. ThreadLocal-переменные отличаются от обычных переменных тем, что у каждого потока свой собственный, индивидуально инициализируемый экземпляр переменной. Доступ к значению можно получить через методы get() или set(). Например, если мы объявим ThreadLocal-переменную: ThreadLocal<Object> locals = new ThreadLocal<Object>();. А затем, в потоке, сделаем locals.set(myObject), то ключом таблицы будет ссылка на объект locals, а значением - ссылка на объект myObject. При этом для другого потока существует возможность «положить» внутрь locals другое значение. Следует обратить внимание, что ThreadLocal изолирует именно ссылки на объекты, а не сами объекты. Если изолированные внутри потоков ссылки ведут на один и тот же объект, то возможны коллизии. Так же важно отметить, что т.к. ThreadLocal-переменные изолированы в потоках, то инициализация такой переменной должна происходить в том же потоке, в котором она будет использоваться. Ошибкой является инициализация такой переменной (вызов метода set()) в главном потоке приложения, потому как в данном случае значение, переданное в методе set(), будет «захвачено» для главного потока, и при вызове метода get() в целевом потоке будет возвращен null.
Назовите различия между synchronized и ReentrantLock?	В Java 5 появился интерфейс Lock предоставляющий возможности более эффективного и тонкого контроля блокировки ресурсов. ReentrantLock - распространённая реализация Lock, которая предоставляет Lock с таким же базовым поведением и семантикой, как у synchronized, но расширенными возможностями, такими как опрос о блокировании (lock polling), ожидание блокирования заданной длительности и прерываемое ожидание блокировки. Кроме того, он предлагает гораздо более высокую эффективность функционирования в условиях жесткой состязательности. Что понимается под блокировкой с повторным входом (reentrant)? Просто то, что есть подсчет сбора данных, связанный с блокировкой, и если поток, который удерживает блокировку, снова ее получает, данные отражают увеличение, и тогда для реального разблокирования нужно два раза снять блокировку. Это аналогично семантике synchronized; если поток входит в синхронный блок, защищенный монитором, который уже принадлежит потоку, потоку будет разрешено дальнейшее функционирование, и locking не будет снята, когда поток выйдет из второго (или последующего) блока synchronized, она будет снята только когда он выйдет из первого блока synchronized, в который он вошел под защитой монитора.Реализация ReentrantLock гораздо более масштабируема в условиях состязательности, чем реализация synchronized. Это значит, что когда много потоков соперничают за право получения блокировки, общая пропускная способность обычно лучше у ReentrantLock, чем у synchronized. JVM требуется меньше времени на установление очередности потоков и больше времени на непосредственно выполнение. У ReentrantLock (как и у других реализаций Lock) locking должна обязательно сниматься в finally блоке (иначе, если бы защищенный код выбросил исключение, locking не была бы снята). Используя синхронизацию, JVM гарантирует, что locking автоматически снимаются. Резюмируя, можно сказать, что когда состязания за блокировку нет либо оно очень мало, то synchronized возможно будет быстрее. Если присутствует заметное состязание за доступ к ресурсу, то скорее всего ReentrantLock даст некое преимущество.
Что такое ReadWriteLock?	ReadWriteLock - это интерфейс расширяющий базовый интерфейс Lock. Используется для улучшения производительности в многопоточном процессе и оперирует парой связанных блокировок (одна - для операций чтения, другая - для записи). Блокировка чтения может удерживаться одновременно несколькими читающими потоками, до тех пор, пока не появится записывающий. Блокировка записи является эксклюзивеной. Существует реализующий интерфейс ReadWriteLock класс ReentrantReadWriteLock, который поддерживает до 65535 блокировок записи и до стольки же блокировок чтения. 
Что такое «блокирующий метод»?	Блокирующий метод - метод, который блокируется, до тех пор, пока задание не выполнится, например метод accept() у ServerSocket блокируется в ожидании подключения клиента. Здесь блокирование означает, что контроль не вернётся к вызывающему методу до тех пор, пока не выполнится задание. Так же существуют асинхронные или неблокирующиеся методы, которые могут завершится до выполнения задачи.
то такое «фреймворк Fork/Join»?	Фреймворк Fork/Join, представленный в JDK 7, - это набор классов и интерфейсов позволяющих использовать преимущества многопроцессорной архитектуры современных компьютеров. Он разработан для выполнения задач, которые можно рекурсивно разбить на маленькие подзадачи, которые можно решать параллельно. Этап Fork: большая задача разделяется на несколько меньших подзадач, которые в свою очередь также разбиваются на меньшие. И так до тех пор, пока задача не становится тривиальной и решаемой последовательным способом. Этап Join: далее (опционально) идёт процесс «свёртки» - решения подзадач некоторым образом объединяются пока не получится решение всей задачи. Решение всех подзадач (в т.ч. и само разбиение на подзадачи) происходит параллельно. Для решения некоторых задач этап Join не требуется. Например, для параллельного QuickSort — массив рекурсивно делится на всё меньшие и меньшие диапазоны, пока не вырождается в тривиальный случай из 1 элемента. Хотя в некотором смысле Join будет необходим и тут, т.к. всё равно остаётся необходимость дождаться пока не закончится выполнение всех подзадач. Ещё одно замечательное преимущество этого фреймворка заключается в том, что он использует work-stealing алгоритм: потоки, которые завершили выполнение собственных подзадач, могут «украсть» подзадачи у других потоков, которые всё ещё заняты.
Что такое Semaphore?	Semaphore - это новый тип синхронизатора: семафор со счётчиком, реализующий шаблон синхронизации Семафор. Доступ управляется с помощью счётчика: изначальное значение счётчика задаётся в конструкторе при создании синхронизатора, когда поток заходит в заданный блок кода, то значение счётчика уменьшается на единицу, когда поток его покидает, то увеличивается. Если значение счётчика равно нулю, то текущий поток блокируется, пока кто-нибудь не выйдет из защищаемого блока. Semaphore используется для защиты дорогих ресурсов, которые доступны в ограниченном количестве, например подключение к базе данных в пуле.
Что такое double checked locking Singleton?	double checked locking Singleton - это один из способов создания потокобезопасного класса реализующего шаблон Одиночка. Данный метод пытается оптимизировать производительность, блокируясь только случае, когда экземпляр одиночки создаётся впервые.  class DoubleCheckedLockingSingleton { private static volatile DoubleCheckedLockingSingleton instance; static DoubleCheckedLockingSingleton getInstance() { DoubleCheckedLockingSingleton current = instance; if (current == null) { synchronized (DoubleCheckedLockingSingleton.class) { current = instance; if (current == null) { instance = current = new DoubleCheckedLockingSingleton(); } } } return current; } }  Следует заметить, что требование volatile обязательно. Проблема Double Checked Lock заключается в модели памяти Java, точнее в порядке создания объектов, когда возможна ситуация, при которой другой поток может получить и начать использовать (на основании условия, что указатель не нулевой) не полностью сконструированный объект. Хотя эта проблема была частично решена в JDK 1.5, однако рекомендация использовать volatile для Double Cheсked Lock остаётся в силе.
Чем полезны неизменяемые объекты?	Неизменяемость (immutability) помогает облегчить написание многопоточного кода. Неизменяемый объект может быть использован без какой-либо синхронизации. К сожалению, в Java нет аннотации @Immutable, которая делает объект неизменяемым, для этого разработчикам нужно самим создавать класс с необходимыми характеристиками. Для этого необходимо следовать некоторым общим принципам: инициализация всех полей только в конструкторе, отсутствие методов setX() вносящих изменения в поля класса, отсутствие утечек ссылки, организация отдельного хранилища копий изменяемых объектов и т.д.
Что такое busy spin?	busy spin - это техника, которую программисты используют, чтобы заставить поток ожидать при определённом условии. В отличие от традиционных методов wait(), sleep() или yield(), которые подразумевают уступку процессорного времени, этот метод вместо уступки выполняет пустой цикл. Это необходимо, для того, чтобы сохранить кэш процессора, т.к. в многоядерных системах, существует вероятность, что приостановленный поток продолжит своё выполнение уже на другом ядре, а это повлечет за собой перестройку состояния процессорного кэша, которая является достаточно затратной процедурой.
Перечислите принципы, которым вы следуете в многопоточном программировании?	При написании многопоточных программ следует придерживаться определённых правил, которые помогают обеспечить достойную производительность приложения в сочетании с удобной отладкой и простотой дальнейшей поддержки кода.  Всегда давайте значимые имена своим потокам. Процесс отладки, нахождения ошибок или отслеживание исключения в многопоточном коде - довольно сложная задача. OrderProcessor, QuoteProcessor или TradeProcessor намного информативнее, чем Thread1, Thread2 и Thread3. Имя должно отражать задачу, выполняемую данным потоком.  Избегайте блокировок или старайтесь уменьшить масштабы синхронизации. Блокировка затратна, а переключение контекста ещё более ресурсоёмко. Пытайтесь избегать синхронизации и блокировки насколько это возможно, и организуйте критическую секцию в минимально необходимом объёме. Поэтому синхронизированный блок всегда предпочительней синхронизированного метода, дополнительно наделяя возможностью абсолютного контроля над масштабом блокировки.  Обрабатывайте прерывание потока с особой тщательностью. Нет ничего хуже оставшегося заблокированным ресурса или системы в неконстистентном, по причине неподтверждённой транзакции, состоянии.  Помните об обработке исключений. Выброшенные InterruptedException должны быть адекватно обработаны, а не просто подавлены. Так же не стоит пренебрегать Thread.UncaughtExceptionHandler. При использовании пула потоков необходимо помнить, что он зачастую просто «проглатывает» исключения. Так, если вы отправили на выполнение Runnable нужно обязательно поместить код выполнения задачи внутрь блока try-catch. Если в очередь пула помещается Callable, необходимо удостоверится, что результат выполнения всегда изымается помощью блокирующего get(), чтобы в случае возникновения существовала возможнотсь заново выбросить произошедшее исключение.  Между синхронизаторами и wait() и notify() следует выбирать синхронизаторы. Во-первых, синхронизаторы, типа CountDownLatch, Semaphore, CyclicBarrier или Exchanger упрощают написание кода. Очень сложно реализовывать комплексный управляющий поток, используя wait() и notify(). Во-вторых, эти классы написаны и поддерживаются настоящими мастерами своего дела и есть шанс, что в последующих версиях JDK они будут оптимизированы изнутри или заменены более производительной внешней реализацией.  Почти всегда использование Concurrent сollection выгоднее использования Synchronized сollection, т.к. первые более современны (используют все доступные на момент их написания новшества языка) и масштабируемы, чем их синхронизированые аналоги.
Какое из следующих утверждений о потоках неверно?	 Если метод start() вызывается дважды для одного и того же объекта Thread, во время выполнения генерируется исключение.  2) Порядок, в котором запускались потоки, может не совпадать с порядком их фактического выполнения.  3) Если метод run() вызывается напрямую для объекта Thread, во время выполнения генерируется исключение.  4) Если метод sleep() вызывается для потока, во время выполнения синхронизированного кода, locking не снимается.  Правильный ответ: 3. Если метод run() вызывается напрямую для объекта Thread, во время выполнения исключение не генерируется. Однако, код, написанный в методе run() будет выполняться текущим, а не новым потоком. Таким образом, правильный способ запустить поток - это вызов метода start(), который приводит к выполнению метода run() новым потоком. Вызов метода start() дважды для одного и того же объекта Thread приведёт к генерированию исключения IllegalThreadStateException во время выполнения, следовательно, утверждение 1 верно. Утверждение 2 верно, так как порядок, в котором выполняются потоки, определяется Планировщиком потоков, независимо от того, какой поток запущен первым. Утверждение 4 верно, так как поток не освободит блокировки, которые он держит, когда он переходит в состояние Ожидания.
Даны 3 потока Т1, Т2 и Т3? Как реализовать выполнение в последовательности Т1, Т2, Т3?	Такой последовательности выполнения можно достичь многими способами, например просто воспользоваться методом join(), чтобы запустить поток в момент, когда другой уже закончит своё выполнение. Для реализации заданной последовательности, нужно запустить последний поток первым, и затем вызывать метод join() в обратном порядке, то есть Т3 вызывает Т2.join, а Т2 вызывает Т1.join, таким образом Т1 закончит выполнение первым, а Т3 последним.
Что такое race condition?	Состояние гонки (race condition) - ошибка проектирования многопоточной системы или приложения, при которой эта работа напрямую зависит от того, в каком порядке выполняются потоки. Состояние гонки возникает, когда поток, который должен исполнится в начале, проиграл гонку и первым исполняется другой поток: поведение кода изменяется, из-за чего возникают недетерменированные ошибки.
Существует ли способ решения проблемы race condition?	Существует ли способ решения проблемы race condition?
Что мы понимаем под операцией CAS?	CAS означает сравнение и замена и означает, что процессор предоставляет отдельную инструкцию, которая обновляет значение регистра, только если предоставленное значение равно текущему значению. Операции CAS можно использовать, чтобы избежать синхронизации, поскольку поток может попытаться обновить значение, предоставив его текущее значение и новое значение для операции CAS. Если другой поток тем временем обновил значение, значение потока не равно текущему значению, и операция обновления завершается неудачно. Затем поток читает новое значение и пытается снова. Таким образом, необходимая синхронизация сменяется оптимистическим ожиданием вращения.
Какие классы Java используют операцию CAS?	Классы SDK в пакете java.util.concurrent.atomic похожи AtomicIntege rили AtomicBoolean используют внутреннюю операцию CAS для реализации одновременного увеличения.  public class CounterAtomic { private AtomicLong counter = new AtomicLong(); public void increment() { counter.incrementAndGet(); } public long get() { return counter.get(); } }
С какими распространенными проблемами вы столкнулись в многопоточной среде?	Deadlock — два потока A и B, удерживайте lock_A и lock_B соответственно. Они оба хотят получить доступ к ресурсу R. Для безопасного доступа к R требуются и lock_A, и lock_B. Но поток A нуждается в lock_B, а поток B — в lock_A. Но оба они не готовы отказаться от замков, которые они держат. Следовательно, нет прогресса. Это тупик!  Условия гонки — Рассмотрим классический пример производителя-потребителя. Что если вы забудете заблокировать перед добавлением или удалением элемента из очереди? Представьте, что два потока A и B пытаются добавить элемент без блокировки. Поток A обращается к задней части очереди. Затем планировщик дает возможность запустить поток B, который успешно добавляет элемент и обновляет хвостовой указатель. Теперь указатель хвоста, прочитанный потоком A, устарел, но он думает, что это хвост, и добавляет элемент. Таким образом, пункт, добавленный B, потерян! Структура данных повреждена! Хуже того, это может также привести к утечке памяти во время очистки.  Гонка данных — представьте переменную флага, которую следует установить. Предположим, что вы установили замки, чтобы избежать условий гонки. Теперь разные потоки хотят устанавливать разные значения. Поскольку планировщик может планировать выполнение потока любым способом, вы не знаете, каково значение флага в конце.  Голодание это проблема, вызванная  планировщиком потоков. Некоторые потоки не имеют возможности запустить и завершить или не могут получить требуемые блокировки, потому что другим потокам предоставляется более высокий приоритет. Они «жаждут» циклов ЦП или других ресурсов. Инверсия приоритетов. Представьте себе два потока A и B. A имеет более высокий приоритет, чем B, и, следовательно, получает больше циклов ЦП, чем B. Но при доступе к общему ресурсу B удерживает блокировку, которая также требуется для A, и возвращает. Теперь A не может ничего сделать без блокировки, и много циклов ЦП тратится впустую, потому что B не получает достаточно циклов, но имеет блокировку.
Разница между зеленым потоком и собственным потоком в Java?	Зеленые потоки относятся к модели, в которой сама виртуальная машина Java создает, управляет и переключает контекст всех потоков Java в рамках одного процесса операционной системы. Библиотека потоков операционной системы не используется.  Под собственными потоками понимается объект, в котором виртуальная машина Java создает потоки Java и управляет ими с помощью библиотеки потоков операционной системы — с именем libthread в UnixWare — и каждый поток Java отображается в один поток библиотеки потоков.
Можно ли улучшить производительность приложения, используя многопоточность? Назовите несколько примеров.	Если у нас имеется более одного доступного ядра ЦП, производительность приложения можно повысить с помощью многопоточности, если возможно распараллелить вычисления на доступных ядрах ЦП. Примером может служить приложение, которое должно масштабировать все изображения, хранящиеся в структуре локального каталога. Вместо того, чтобы перебирать все изображения одно за другим, реализация производителя / потребителя может использовать один поток для сканирования структуры каталогов и группу рабочих потоков, которые выполняют фактическую операцию масштабирования. Другим примером может быть приложение, которое отображает некоторую веб-страницу. Вместо загрузки одной HTML-страницы за другой поток производителя может проанализировать первую HTML-страницу и выдать найденные ссылки в очередь. Рабочие потоки отслеживают очередь и загружают веб-страницы, найденные анализатором. Пока рабочие потоки ждут полной загрузки страницы, другие потоки могут использовать ЦП для анализа уже загруженных страниц и выдачи новых запросов.
Приведите пример, почему улучшения производительности для однопоточных приложений могут привести к снижению производительности многопоточных приложений.	Ярким примером такой оптимизации является реализация List , в которой количество элементов хранится в виде отдельной переменной. Это повышает производительность для однопоточных приложений, поскольку операция size() не должна повторяться по всем элементам, но может возвращать текущее количество элементов напрямую. В многопоточном приложении дополнительный счетчик должен защищаться блокировкой, поскольку несколько параллельных потоков могут вставлять элементы в список. Эта дополнительная locking может стоить производительности, когда в списке больше обновлений, чем вызовов операции size() .
Что такое ключевое слово volatile в Java и чем оно отличается от синхронизированного метода в Java?	Использование volatile заставляет поток читать и записывать переменные непосредственно из оперативной памяти. Поэтому, когда многие потоки используют одну и ту же переменную переменную, все они видят последнюю версию, которая присутствует в оперативной памяти, а не возможную старую копию в кэше. Когда поток входит в синхронизированный блок, он должен получить контроль над переменной монитора. Все остальные потоки ожидают выхода первого потока из синхронизированного блока. Чтобы все потоки могли видеть одинаковые изменения, все переменные, используемые в синхронизированном блоке, считываются и записываются непосредственно из памяти RAM, а не из копии кэша.
Может ли конструктор быть синхронизирован?	Нет, конструктор не может быть синхронизирован. Причина, по которой это приводит к синтаксической ошибке, заключается в том, что только конструирующий поток должен иметь доступ к создаваемому объекту.
Если два потока одновременно вызывают синхронизированный метод для разных экземпляров объекта, может ли один из этих потоков блокировать?	Оба метода блокируют один и тот же монитор. Следовательно, вы не можете одновременно выполнять их на одном и том же объекте из разных потоков (один из двух методов будет блокироваться, пока другой не будет завершен).
Future vs CompletableFuture - концепция и отличия	Future - интерфейс, который представляет пока еще недовычисленный результат. Когда породившая его асинхронная операция заканчивается, он заполняется значением. Метод get блокирует выполнение до получения результата, isDone проверяет его наличие. К примеру результат выполнения задач в ExecutorService, ForkJoinTask, реализует интерфейс Future.  CompletableFuture появился в Java 8. Это класс-реализация старого интерфейса Future, а значит всё сказанное выше справедливо и для него. Вдобавок к этому, CompletableFuture реализует работу с отложенными результатами посредством коллбэков. Метод thenApply регистрирует код обработки значения, который будет автоматически вызван позже, когда это значение появится. CompletableFutures были введены в Java 8 (2014). На самом деле они представляют собой эволюцию обычных Futures, вдохновленных Google Listenable Futures , частью библиотеки Guava . Это фьючерсы, которые также позволяют вам связывать задачи в цепочку. Вы можете использовать их, чтобы сказать некоторому рабочему потоку «иди и выполни задачу X, а когда закончишь, иди делай другую вещь, используя результат X». Используя CompletableFutures, вы можете что-то сделать с результатом операции, фактически не блокируя поток для ожидания результата.
Объект синхронизации Semaphore	Синхронизатор Semaphore реализует шаблон синхронизации Семафор. Чаще всего, семафоры необходимы, когда нужно ограничить доступ к некоторому общему ресурсу. В конструктор этого класса (Semaphore(int permits) или Semaphore(int permits, boolean fair)) обязательно передается количество потоков, которому семафор будет разрешать одновременно использовать заданный ресурс. Доступ управляется с помощью счётчика: изначально значение счётчика равно int permits, когда поток заходит в заданный блок кода, то значение счётчика уменьшается на единицу, когда поток его покидает, то увеличивается. Если значение счётчика равно нулю, то текущий поток блокируется, пока кто-нибудь не выйдет из блока (в качестве примера из жизни с permits = 1, можно привести очередь в кабинет в поликлинике: когда пациент покидает кабинет, мигает лампа, и заходит следующий пациент).
Объект синхронизации CountDownLatch	CountDownLatch (замок с обратным отсчетом) предоставляет возможность любому количеству потоков в блоке кода ожидать до тех пор, пока не завершится определенное количество операций, выполняющихся в других потоках, перед тем как они будут «отпущены», чтобы продолжить свою деятельность. В конструктор CountDownLatch (CountDownLatch(int count)) обязательно передается количество операций, которое должно быть выполнено, чтобы замок «отпустил» заблокированные потоки.Блокировка потоков снимается с помощью счётчика: любой действующий поток, при выполнении определенной операции уменьшает значение счётчика. Когда счётчик достигает 0, все ожидающие потоки разблокируются и продолжают выполняться (примером CountDownLatch из жизни может служить сбор экскурсионной группы: пока не наберется определенное количество человек, экскурсия не начнется).
Объект синхронизации CyclicBarrier	CyclicBarrier реализует шаблон синхронизации Барьер. Циклический барьер является точкой синхронизации, в которой указанное количество параллельных потоков встречается и блокируется. Как только все потоки прибыли, выполняется опционное действие (или не выполняется, если барьер был инициализирован без него), и, после того, как оно выполнено, барьер ломается и ожидающие потоки «освобождаются». В конструктор барьера (CyclicBarrier(int parties) и CyclicBarrier(int parties, Runnable barrierAction)) обязательно передается количество сторон, которые должны «встретиться», и, опционально, действие, которое должно произойти, когда стороны встретились, но перед тем когда они будут «отпущены».Барьер похож на CountDownLatch, но главное различие между ними в том, что вы не можете заново использовать «замок» после того, как его счётчик достигнет нуля, а барьер вы можете использовать снова, даже после того, как он сломается. CyclicBarrier является альтернативой метода join(), который «собирает» потоки только после того, как они выполнились.
Объект синхронизации Exchanger	Exchanger (обменник) может понадобиться, для того, чтобы обменяться данными между двумя потоками в определенной точки работы обоих потоков. Обменник — обобщенный класс, он параметризируется типом объекта для передачи.Обменник является точкой синхронизации пары потоков: поток, вызывающий у обменника метод exchange() блокируется и ждет другой поток. Когда другой поток вызовет тот же метод, произойдет обмен объектами: каждая из них получит аргумент другой в методе exchange(). Стоит отметить, что обменник поддерживает передачу null значения. Это дает возможность использовать его для передачи объекта в одну сторону, или, просто как точку синхронизации двух потоков.
Объект синхронизации Phaser	Phaser (фазер), как и CyclicBarrier, является реализацией шаблона синхронизации Барьер, но, в отличии от CyclicBarrier, предоставляет больше гибкости. Этот класс позволяет синхронизировать потоки, представляющие отдельную фазу или стадию выполнения общего действия. Как и CyclicBarrier, Phaser является точкой синхронизации, в которой встречаются потоки-участники. Когда все стороны прибыли, Phaser переходит к следующей фазе и снова ожидает ее завершения.Если сравнить Phaser и CyclicBarrier, то можно выделить следующие важные особенности Phaser: Каждая фаза (цикл синхронизации) имеет номер;  Количество сторон-участников жестко не задано и может меняться: поток может регистрироваться в качестве участника и отменять свое участие;  Участник не обязан ожидать, пока все остальные участники соберутся на барьере. Чтобы продолжить свою работу достаточно сообщить о своем прибытии;  Случайные свидетели могут следить за активностью в барьере;  Поток может и не быть стороной-участником барьера, чтобы ожидать его преодоления;  У фазера нет опционального действия.
Что такое Lock?	Lock — Базовый интерфейс из lock framework, предоставляющий более гибкий подход по ограничению доступа к ресурсам/блокам нежели при использовании synchronized. Так, при использовании нескольких локов, порядок их освобождения может быть произвольный. Плюс имеется возможность пойти по альтернативному сценарию, если лок уже кем то захвачен.
Что такое ReentrantLock?	ReentrantLock — Лок на вхождение. Только один поток может зайти в защищенный блок. Класс поддерживает «честную» (fair) и «нечестную» (non-fair) разблокировку потоков. При «честной» разблокировке соблюдается порядок освобождения потоков, вызывающих lock(). При «нечестной» разблокировке порядок освобождения потоков не гарантируется, но, как бонус, такая разlocking работает быстрее. По умолчанию, используется «нечестная» разlocking.
Как использовать ReadWriteLock?	Стандартный интерфейс ReadWriteLock предоставляет потокобезопасный разделенный доступ на чтение и на запись. Для этих целей в нём объявлены два метода: readLock() и writeLock(). Они возвращают объекты под интерфейсом Lock. Оба типа блокировок одного экземпляра ReadWriteLock связаны. Пока какой-то поток не заберет блокировку на запись, сколько угодно потоков могут читать не мешая друг другу. Блокировкой readLock закрывается часть кода с семантикой «только чтения» некоторого условного «ресурса». В критической секции кода writeLock осуществляется модификация ресурса. Свойства этих локов защищают программу от ситуаций конкурентной записи ресурса и чтения во время записи. Подобно copy-on-write коллекциям, этот подход становится выгодным, когда ресурс читают сильно чаще чем модифицируют.Интерфейс реализуется классом ReentrantReadWriteLock, который во многом похож на обычный ReentrantLock.
Когда используется StampedLock?	StampedLock - примитив синхронизации, добавленный в Java с версии 8. Общий принцип его работы точно такой же, как у ReadWriteLock: захват неэксклюзивной блокировки (на чтение), и эксклюзивной (на запись). Но есть у этих классов ряд различий в деталях.Во-первых, если locking ReadWriteLock возвращает объекты типа Lock, то StampedLock возвращает числа типа long, которые и называется «штампами». Штамп служит идентификатором лока, он передается параметром в методы по работе с ранее захваченной блокировкой чтения или записи. Специальный штамп 0 означает неудавшийся захват. StampedLock в отличие от ReentrantReadWriteLock - не реентрант. Это накладывает бóльшую ответственность на программиста: можно устроить дедлок на одном потоке.В StampedLock расширена функциональность. Новые методы с префиксом try* не висят в ожидании. Методы tryOptimistic* реализуют оптимистичную блокировку. Методы tryConvert* дают возможность изменять «уровень» заблокированности: можно попытаться превратить readLock во writeLock, и наоборот. Не смотря на похожесть, StampedLock не наследуется от ReadWriteLock. Но для совместимости в нём предусмотрены методы-адаптеры asReadWriteLock, asReadLock и asWriteLock. Итого, locking на штампах решает те же задачи, что ReadWriteLock, но дает больше возможностей и лучшую производительность.
Зачем выбирать ReentrantLock вместо synchronized?	Объект класса ReentrantLock решает те же задачи, что и блок synchronized. Поток висит на вызове метода lock() в ожидании своей очереди занять этот объект. Владеть локом, как и находиться внутри блока synchronized может только один поток одновременно. unlock(), подобно выходу из блока синхронизации, освобождает объект-монитор для других потоков.В отличие от блока синхронизации, ReentrantLock дает расширенный интерфейс для получения информации о состоянии блокировки. Методы лока позволяют еще до блокировки узнать, занят ли он сейчас, сколько потоков ждут его в очереди, сколько раз подряд текущий поток завладел им.Шире и возможные режимы блокировки. Кроме обычного ожидающего lock(), вариант tryLock() с параметром ожидает своей очереди только заданное время, а без параметра - вообще не ждет, а только захватывает свободный лок.Еще одно отличие - свойство fair. Лок с этим свойством обеспечивает «справедливость» очереди: пришедший раньше поток захватывает объект раньше. Блок synchronized не дает никаких гарантий порядка.
Что такое Executor?	Executor - интерфейс, который может выполнять подтвержденные задачи. Интерфейс предоставляет возможность избежать вникания в механику выполнения задачи и деталей использования выполняемого потока. Executor обычно используется для явного создания нитей
Что такое ExecutorService?	ExecutorService исполняет асинхронный код в одном или нескольких потоках. Создание инстанса ExecutorService'а делается либо вручную через конкретные имплементации (ScheduledThreadPoolExecutor или ThreadPoolExecutor), но проще будет использовать фабрики класса Executors. Например, если надо создать пул с 2мя потоками, то делается это так: 1 ExecutorService service = Executors.newFixedThreadPool(2); Если требуется использовать кэширующий пул потоков, который создает потоки по мере необходимости, но переиспользует неактивные потоки (и подчищает потоки, которые были неактивные некоторое время) Метод submit также возвращает объект Future, который содержит информацию о статусе исполнения переданного Runnable или Callable (который может возвращать значение). Из него можно узнать выполнился ли переданный код успешно, или он еще выполняется. Вызов метода get на объекте Future возвратит значение, который возвращает Callable (или null, если используется Runnable). Метод имеет 2 checked-исключения: InterruptedException, который бросается, когда выполнение прервано через метод interrupt(), или ExecutionException если код в Runnable или Callable бросил RuntimeException, что решает проблему поддержки исключений между потоками.
Что такое ThreadPoolExecutor и зачем он нужен?	ThreadPoolExecutor - реализация ExecutorService. Он выполняет переданную задачу (Callable или Runnable), используя одну из внутренних доступных нитей из пула. Пул потоков содержит в себе ThreadPoolExecutor, который может содержать изменяющееся число нитей. Число нитей в пуле задается с помощью corePoolSize и maximumPoolSize.
Зачем нужен ScheduledExecutorService?	Иногда требуется выполнение кода асихронно и периодически или требуется выполнить код через некоторое время, тогда на помощь приходит ScheduledExecutorService. Он позволяет поставить код выполняться в одном или нескольких потоках и сконфигурировать интервал или время, на которое выполненение будет отложено. Интервалом может быть время между двумя последовательными запусками или время между окончанием одного выполнения и началом другого. Методы ScheduledExecutorService возвращают ScheduledFuture, который также содержит значение отсрочки для выполнения ScheduledFuture.
Что такое ForkJoinPool?	ForkJoinPool - специальный вид ExecutorService (пулла потоков), который появился в Java с версии 7. Предназначен для выполнения рекурсивных задач.Задача для сервиса представляется экземпляром класса ForkJoinTask. В основном используются подклассы RecursiveTask и RecursiveAction, для задач с результатом и без соответственно. Аналогично интерфейсам Callable и Runnable обычного ExecutorService.Тело рекурсивной операции задается в реализации метода compute() задачи ForkJoinTask. Здесь же создаются новые подзадачи, и запускаются параллельно методом fork(). Чтобы дождаться завершения выполнения задачи, на каждой форкнутой подзадаче вызывается блокирующий метод join(), результат выполнения при необходимости агрегируется.С точки зрения использования метод ForkJoinTask.join() похож на аналогичный метод класса Thread. Но в случае fork-join поток может на самом деле не заснуть, а переключиться на выполнение другой задачи. Такая стратегия называется work stealing, и позволяет эффективнее использовать ограниченное количество потоков. Это похоже на переиспользование потоков корутинах Kotlin (green threads).
Что такое платформа Spring Model-View-Controller (MVC)?	Платформа Spring MVC предоставляет архитектуру контроллера представления модели и готовые компоненты, используемые для разработки слабо связанных веб-приложений. Используя MVC, вы можете разделить различные аспекты программы, такие как бизнес, логика ввода и пользовательский интерфейс, сохраняя при этом слабую связь между ними. Это обеспечивает большую гибкость в ваших веб-приложениях.
Как использовать JavaEE сервлет в Spring Framework?	Web-приложение на Spring MVC технически само по себе работает на сервлетах: всю обработку запросов берет на себя единый DispatcherServlet. С его помощью реализуется паттерн Front Controller. Если вам нужно определить в программе полностью независимый от Spring-контекста сервлет или фильтр, ничего особенного для этого делать не нужно. Как обычно в Servlet API, нужно объявить класс, добавить его в web.xml как сервлет, добавить для сервлета маппинг. Сервлет живет вне Spring-контекста, внедрение зависимостей в нём просто так не заработает. Чтобы использовать autowiring, на этапе инициализации сервлета вызывается статический SpringBeanAutowiringSupport.processInjectionBasedOnServletContext, с текущим сервлетом и его контекстом в аргументах. В этом же утилитарном классе есть ряд других средств для работы с контекстом извне. Если программа построена на Spring Boot, создание бина типа ServletRegistrationBean поможет добавить сервлеты в рантайме. А для декларативного добавления на этапе компиляции, к классу конфигурации применяется @ServletComponentScan. С этой аннотацией стартер приложения просканирует и добавит в контекст все web-компоненты в стиле Servlet 3.0: классы с аннотациями @WebFilter, @WebListener и @WebServlet.
Какая разница между аннотациями @Component, @Repository и @Service в Spring?	@Component - используется для указания класса в качестве компонента spring. При использовании поиска аннотаций, такой класс будет сконфигурирован как spring bean. @Controller - специальный тип класса, применяемый в MVC приложениях. Обрабатывает запросы и часто используется с аннотацией @RequestMapping. @Repository - указывает, что класс используется для работы с поиском, получением и хранением данных. может использоваться для реализации шаблона DAO. @Service - указывает, что класс является сервисом для реализации бизнес логики (на самом деле не отличается от Component, но просто помогает разработчику указать смысловую нагрузку класса). Для указания контейнеру на класс-бин можно использовать любую из этих аннотаций. Но различные имена позволяют различать назначение того или иного класса. Например, бины, получившиеся при помощи @Repository, дополнительно имеют обработку для JDBC Exception
Можем ли мы использовать @Component вместо @Service для бизнес логики?	Да. конечно. Если @Component является универсальным стереотипом для любого Spring компонента, то @Service в настоящее время является его псевдонимом. Однако, в официальной документации Spring рекомендуется использовать именно @Service для бизнес логики. Вполне возможно, что в будущих версиях фреймворка, для данного стереотипа добавится дополнительная семантика, и его бины станут обладать дополнительной логикой.
Расскажите, что вы знаете о DispatcherServlet и ContextLoaderListener.	DispatcherServlet - сервлет диспатчер. Этот сервлет анализирует запросы и направляет их соответствующему контроллеру для обработки. В Spring MVC класс DispatcherServlet является центральным сервлетом, который получает запросы и направляет их соответствующим контроллерам. В приложении Spring MVC может существовать произвольное количество экземпляров DispatcherServlet, предназначенных для разных целей (например, для обработки запросов пользовательского интерфейса, запросов веб-служб REST и т.д.). Каждый экземпляр DispatcherServlet имеет собственную конфигурацию WebApplicationContext, которая определяет характеристики уровня сервлета, такие как контроллеры, поддерживающие сервлет, отображение обработчиков, распознавание представлений, интернационализация, оформление темами, проверка достоверности, преобразование типов и форматирование и т.п. ContextLoaderListener - слушатель при старте и завершении корневого класса Spring WebApplicationContext. Основным назначением является связывание жизненного цикла ApplicationContext и ServletContext, а так же автоматического создания ApplicationContext. Можно использовать этот класс для доступа к бинам из различных контекстов спринг. Настраивается в web.xml:
Какой жизненный цикл у запроса?	Запрос приходит в DispatcherServlet  DispatcherServlet отправляет запрос на один из контроллеров, основываясь на URL из запроса  Контроллер обрабатывает запрос, делегирует выполнение бизнес-логике бизнес-слою (как правило это классы с аннотацией @Service), и создает модель с данными, которую и отправляет обратно в DispatcherServlet  DispatcherServlet отправляет модель на фронт для вью, основываясь на интерфейсе ViewResolver(подробнее об этом ниже)
DispatcherServlet Создан ли экземпляр в контексте приложения?	Нет, DispatcherServlet экземпляр создается сервлет-контейнерами, такими как Tomcat или Jetty. Вы должны определить DispatcherServlet в файл web.xml, как показано ниже. Вы можете видеть, что тег загрузки при запуске имеет значение 1, что означает, что DispatcherServlet он создается при развертывании приложения Spring MVC в Tomcat или любом другом контейнере сервлетов. Во время создания он ищет файл servlet-name-context.xml и затем инициализирует bean-компоненты, определенные в этом файле.
Что такое корневой контекст приложения в Spring MVC? Как это загружается?	В Spring MVC контекст, загружаемый с использованием ContextLoaderListener , называется «корневым» контекстом приложения, который принадлежит всему приложению, в то время как тот, который инициализирован с использованием DispatcherServlet , фактически специфичен для этого сервлета. Технически Spring MVC допускает множественное использование DispatcherServlet в веб-приложении Spring MVC, поэтому каждый контекст является специфическим для соответствующего сервлета. Но, имея тот же корневой контекст, может существовать.
Что такое ContextLoaderListener и для чего это нужно?	Это ContextLoaderListener слушатель, который помогает загрузить Spring MVC. Как следует из названия, он загружается и создает ApplicationContext, так что вам не нужно писать явный код для его создания. Контекст приложения это то, куда уходит Spring bean. Для веб-приложения существует подкласс WebAppliationContext. ContextLoaderListener Также связывает жизненный цикл ApplicationContext для жизненного цикла ServletContext. Вы можете получить ServletContext с WebApplicationContext помощью getServletContext() метода.
Что вы собираетесь делать в web.xml? Где вы это разместите?	Он ContextLoaderListener настроен в web.xml как слушатель, и вы помещаете его в тег, как показано ниже:  <listener>  <listener-class> org.springframework.web.context.ContextLoaderListener  </listener-class>  </listener>  При развертывании веб-приложения Spring MVC контейнер сервлетов создал экземпляр ContextLoaderListener класса, который загружает Spring WebApplicationContext. Вы также можете увидеть Spring MVC для начинающих, чтобы узнать больше об ContextLoaderListener и WebApplicationContext и их роли в Spring MVC.
Каковы части фреймворка Spring MVC?	Тремя основными частями MVC являются: · DispatcherServlet: Эта часть MVC управляет всеми HTTP-запросами и ответами, которые взаимодействуют с программой. DispatcherServlet сначала получает соответствующее сопоставление обработчика из файла конфигурации, а затем передает запрос контроллеру. DispatcherServlet является наиболее важной частью платформы Spring Web MVC. · WebApplicationContext: Это действует как расширение обычного ApplicationContext с дополнительными функциями, необходимыми для веб-приложений. Он может однозначно разрешать темы и автоматически определять, с каким сервлетом он связан. · Контроллеры: Это компоненты в DispatcherServlet, которые действуют как фильтры между вводом данных пользователем и ответом приложения. Контроллеры принимают ввод пользователя, решают, следует ли преобразовать его в Представление или Модель, и, наконец, возвращают преобразованный ввод в Распознаватель представлений для просмотра.
Как входящий запрос сопоставляется с контроллером и сопоставляется с методом?	Иногда также задают этот вопрос: как DispatcherServlet узнать, какой контроллер должен обработать запрос? Ну, ответ лежит в том, что называется отображением обработчика. Spring использует сопоставления обработчиков для связи контроллеров с запросами. Два из наиболее часто используемых отображений обработчиков это BeanNameUrlHandlerMapping и SimpleUrlHandlerMapping. Если BeanNameUrlHandlerMappingURL-адрес запроса совпадает с именем компонента, класс в определении компонента является контроллером, который будет обрабатывать запрос. С другой стороны SimpleUrlHandlerMapping, отображение более явное. Вы можете указать количество URL, и каждый URL может быть явно связан с контроллером. Если вы используете аннотации для настройки Spring MVC, что необходимо, тогда @RequestMapping аннотации используются для сопоставления входящего запроса с контроллером и методом-обработчиком. Вы также можете настроить @RequestMapping аннотацию по пути URI, параметрам запроса, HTTP-методам запроса и HTTP-заголовкам, присутствующим в запросе.
В чём разница между @Controller и @RestController?	Controller - это один из стереотипов Spring Framework. Компоненты такого типа обычно занимаются обработкой сетевых запросов. Контроллер состоит из набора методов-обработчиков, помеченных аннотацией @RequestMapping.Ответ на запрос можно сформировать разными способами: например просто вернуть из обработчика строку с именем jsp-файла, или же вернуть ResponseBodyEmitter, который будет асинхронно заполняться данными позже. Все возможные варианты перечислены в документации.Большинство современных API реализуется по архитектуре REST. В ней каждая сущность доступна под собственным URI. В методе-обработчике возвращается экземпляр класса этой сущности, который преобразуется в ответ сервера одним из HttpMessageConverter-ов. Например, в JSON его превратит MappingJackson2HttpMessageConverter. Чтобы использовать этот способ ответа, метод, или весь контроллер, должен иметь аннотацию @ResponseBody.@RestController - это просто сокращенная запись для @Controller + @ResponseBody.
Что такое ViewResolver в Spring?	ViewResolver - распознаватель представлений. Интерфейс ViewResolver в Spring MVC (из пакета org.springframework.web.servlet) поддерживает распознавание представлений на основе логического имени, возвращаемого контроллером. Для поддержки различных механизмов распознавания представлений предусмотрено множество классов реализации. Например, класс UrlBasedViewResolver поддерживает прямое преобразование логических имен в URL. Класс ContentNegotiatingViewResolver поддерживает динамическое распознавание представлений в зависимости от типа медиа, поддерживаемого клиентом (XML, PDF, JSON и т.д.). Существует также несколько реализаций для интеграции с различными технологиями представлений, такими как FreeMarker (FreeMarkerViewResolver), Velocity (VelocityViewResolver) и JasperReports (JasperReportsViewResolver). InternalResourceViewResolver - реализация ViewResolver, которая позволяет находить представления, которые возвращает контроллер для последующего перехода к нему. Ищет по заданному пути, префиксу, суффиксу и имени.
Что такое MultipartResolver и когда его использовать?	Интерфейс MultipartResolver используется для загрузки файлов. Существуют две реализации: CommonsMultipartResolver и StandardServletMultipartResolver, которые позволяют фреймворку загружать файлы. По умолчанию этот интерфейс не включается в приложении и необходимо указывать его в файле конфигурации. После настройки любой запрос о загрузке будет отправляться этому интерфейсу.
Для чего @RequestParam используется?	Это @RequestParam аннотация Spring MVC, которая используется для извлечения параметра запроса или параметров запроса из URL-адреса в методе обработчика контроллера, как показано ниже:  public String personDetail(@RequestParam("id") long id) {  .... return "personDetails"; }  @RequestParam Аннотаций также поддерживает преобразование типов данных, например , вы можете увидеть здесь строка преобразуется в автоматический вход в систему , но она также может привести к исключению , если параметр запроса нет , или в случае несоответствия типа. Вы также можете сделать параметр необязательным, используя требуемый = false, например @RequestParam (value = «id», required = false)
Каковы различия между @RequestParam и @PathVariable ?	Несмотря на то, что оба @RequestParam и @PathVariable аннотации используются для извлечения некоторых данных из URL, между ними есть ключевое различие. @RequestParam Используется для параметров экстракта запросов, например , что — нибудь после «?» в URL, в то время @PathVariable как используется для извлечения части самого URI. используется в веб-службах RESTful, поскольку их идентификатор обычно является частью пути URI или URL-адреса.
Расскажите про аннотацию @RequestMapping	Это аннотация в основном используется для указания URI для класс-контроллера. Раньше ее использовали методов класса, чтобы указать URI, http-метод, тип отправляемых данных, и т.п. В более новых версиях Spring ее заменили на аннотации @GetMapping, @PostMapping, и т.п. Теперь она используется только для указания URI до класса-контроллера.
Что за аннотации @GetMapping, @PostMapping, @DeleteMapping и прочие?	Это более узкие аннотации для маппинга http-методов. @GetMapping — Обрабатывает get-запросы @PostMapping — Обрабатывает post-запросы @DeleteMapping — Обрабатывает delete-запросы @PutMapping — Обрабатывает put-запросы @PatchMapping — Обрабатывает patch-запросы Все написанное ниже характерно также и для других аннотаций. @GetMapping это просто аннотация которая содержит @RequestMapping(method = RequestMethod.GET).Она также позволяет более глубоко настроить метод-обработчик.Ее параметры(они конвертируются в аналогичные параметры @RequestMapping): path — URI headers — заголовки name — имя обработчика params — параметры produces — тип возвращаемых данных(JSON, XML, текст). Используется в REST consumes — тип принимаемых данных. Используется в REST По умолчанию аннотация принимает путь до метода.@GetMapping("managers") = @GetMapping(path = "managers")
Что за аннотация @RequestBody?	Она используется для того чтобы указать что метод оперирует не моделями, а данными. То есть отправляет JSON, XML, текст, и т.п. Обычно она неявно используется в REST-сервисах.
Что такое View и какова идея поддержки различных типов View?	A View это интерфейс в приложении Spring MVC, реализации которого отвечают за отображение контекста и представление модели. Один вид предоставляет несколько атрибутов модели. Представления в Spring MVC могут быть бобами. Они могут быть созданы как бобы ViewResolver. Поскольку этот интерфейс не имеет состояния, реализации представлений должны быть поточно-ориентированными. При использовании ViewResolverлогическое имя представления может быть преобразовано в различные типы View реализации, например, JstlView для отображения JSP или других реализаций представления для FreeMarker и Velocity.
Как выбирается View в фазе рендеринга? Как отображается View?	DispatcherServlet содержит список специальных "отображателей" для view, которые основываясь на конфигурации сервлета будут содержать бины реализующие интерфейс ViewResolver. Процесс отображения view:  Контроллер возвращает имя view в DispactherServlet  Имя сопоставляется с именами во ViewResolver  Если находится подходящий ViewResolver, он возвращает View который должен использоваться при рендеринге.  DS передает модель с данными во View и отображает вывод(html-страницу)
Что такое Model?	Model является ссылкой для инкапсуляции данных или вывода для визуализации. Model всегда создается и передается в представление в Spring MVC. Если метод сопоставленного контроллера имеет Model в качестве параметра метода, model Spring Framework автоматически внедряет в этот метод экземпляр. Все атрибуты, установленные на внедренной модели, сохраняются и передаются в View. 
Почему у вас есть доступ к model вашему View? Откуда это взялось?	У вас должен быть доступ к model вашему представлению, чтобы отобразить вывод. Это тот, model который содержит данные для визуализации. Model Поставляется с контроллером, который обрабатывает их запрос клиента и инкапсулирует выход в Model объект.
Как загрузить файл в Spring MVC?	Внутри спринг предусмотрен интерфейс MultipartResolver для обеспечения загрузки файлов. Фактически нужно настроить файл конфигурации для указания обработчика загрузки файлов, а затем задать необходимый метод в контроллере spring.
Как обрабатывать исключения в Spring MVC Framework?	В Spring MVC интерфейс HandlerExceptionResolver (из пакета org.springframework.web.servlet) предназначен для работы с непредвиденными исключениями, возникающими во время выполнения обработчиков. По умолчанию DispatcherServlet регистрирует класс DefaultHandlerExceptionResolver (из пакета org.springframework.web.servlet.mvc.support). Этот распознаватель обрабатывает определенные стандартные исключения Spring MVC, устанавливая специальный код состояния ответа. Можно также реализовать собственный обработчик исключений, аннотировав метод контроллера с помощью аннотации @ExceptionHandler и передав ей в качестве атрибута тип исключения. В общем случае обработку исключений можно описать таким образом: Controller Based - указать методы для обработки исключения в классе контроллере. Для этого нужно пометить такие методы аннотацией @ExceptionHandler. Global Exception Handler - для обработки глобальных исключений spring предоставляет аннотацию @ControllerAdvice. HandlerExceptionResolver implementation - общие исключений большая часть времени обслуживают статические страницы. Spring Framework предоставляет интерфейс HandlerExceptionResolver, который позволяет задать глобального обработчика исключений. Реализацию этого интерфейса можно использовать для создания собственных глобальных обработчиков исключений в приложении.
Каковы минимальные настройки, чтобы создать приложение Spring MVC?	Для создания простого Spring MVC приложения необходимо пройти следующие шаги: Добавить зависимости spring-context и spring-webmvc в проект. Указать DispatcherServlet в web.xml для обработки запросов внутри приложения. Задать определение spring bean (аннотацией или в xml). Добавить определение view resolver для представлений. Настроить класс контроллер для обработки клиентских запросов.
Как бы вы связали Spring MVC Framework и архитектуру MVC?	Модель (Model) - выступает любой Java bean в Spring. Внутри класса могут быть заданы различные атрибуты и свойства для использования в представлении. Преставление (View) - JSP страница, HTML файл и т.п. служат для отображения необходимой информации пользователю. Представление передает обработку запросов к диспетчеру сервлетов (контроллеру). DispatcherServlet (Controller) - это главный контроллер в приложении Spring MVC, который обрабатывает все входящие запросы и передает их для обработки в различные методы в контроллеры.
Как добиться локализации в приложениях Spring MVC?	Spring MVC предоставляет очень простую и удобную возможность локализации приложения. Для этого необходимо сделать следующее: Создать файл resource bundle, в котором будут заданы различные варианты локализированной информации. Определить messageSource в конфигурации Spring используя классы ResourceBundleMessageSource или ResourceBundleMessageSource. Определить localceResolver класса CookieLocaleResolver для включения возможности переключения локали. С помощью элемента spring:message DispatcherServlet будет определять в каком месте необходимо подставлять локализированное сообщение в ответе.
Как мы можем использовать Spring для создания веб-службы RESTful, возвращающей JSON?	Spring Framework позволяет создавать Resful веб сервисы и возвращать данные в формате JSON. Spring обеспечивает интеграцию с Jackson JSON API для возможности отправки JSON ответов в resful web сервисе. Для отправки ответа в формате JSON из Spring MVC приложения необходимо произвести следующие настройки: Добавить зависимости Jackson JSON. С помощью maven это делается так:  Настроить бин RequestMappingHandlerAdapter в файле конфигурации Spring и задать свойство messageConverters на использование бина MappingJackson2HttpMessageConverter.  В контроллере указать с помощью аннотации @ResponseBody возвращение Object:
Как проверить (валидировать) данные формы в Spring Web MVC Framework?	Spring поддерживает аннотации валидации из JSR-303, а так же возможность создания своих реализаций классов валидаторов. Пример использования аннотаций:
Что вы знаете Spring MVC Interceptor и как он используется?	Перехватчики в Spring (Spring Interceptor) являются аналогом Servlet Filter и позволяют перехватывать запросы клиента и обрабатывать их. Перехватить запрос клиента можно в трех местах: preHandle, postHandle и afterCompletion. preHandle - метод используется для обработки запросов, которые еще не были переданы в метода обработчик контроллера. Должен вернуть true для передачи следующему перехватчику или в handler method. False укажет на обработку запроса самим обработчиком и отсутствию необходимости передавать его дальше. Метод имеет возможность выкидывать исключения и пересылать ошибки к представлению. postHandle - вызывается после handler method, но до обработки DispatcherServlet для передачи представлению. Может использоваться для добавления параметров в объект ModelAndView. afterCompletion - вызывается после отрисовки представления. Для создания обработчика необходимо расширить абстрактный класс HandlerInterceptorAdapter или реализовать интерфейс HandlerInterceptor. Так же нужно указать перехватчики в конфигурационном файле Spring.
В чем разница между Filters, Listeners and Interceptors?	Концептуально всё просто, фильтры сервлетов могут перехватывать только HTTPServlets. Listeners могут перехватывать специфические события. Как перехватить события которые относятся ни к тем не другим? Фильтры и перехватчики делают по сути одно и тоже: они перехватывают какое-то событие, и делают что-то до или после. Java EE использует термин Filter, Spring называет их Interceptors. Именно здесь AOP используется в полную силу, благодаря чему возможно перехватывание вызовов любых объектов
В чем разница между ModelMap и ModelAndView?	Model — интерфейс, ModelMap его реализация.. ModelAndView является контейнером для пары, как ModelMap и View. Обычно я люблю использовать ModelAndView. Однако есть так же способ когда мы задаем необходимые атрибуты в ModelMap, и возвращаем название View обычной строкой из метода контроллера.
В чем разница между model.put() и model.addAttribute()?	Метод addAttribute отделяет нас от работы с базовой структурой hashmap. По сути addAttribute это обертка над put, где делается дополнительная проверка на null. Метод addAttribute в отличии от put возвращает modelmap.model.addAttribute("attribute1","value1").addAttribute("attribute2","value2");
Что можете рассказать про Form Binding?	Нам это может понадобиться, если мы, например, захотим взять некоторое значение с HTML страницы и сохранить его в БД. Для этого нам надо это значение переместить в контроллер Спринга. Если мы будем использовать Spring MVC form tags, Spring автоматически свяжет переменные на HTML странице с Бином Спринга. Если мне придется с этим работать, я обязательно буду смотреть официальную документацию Spring MVC Form Tags.
Для чего был создан REST?	Чтобы понять концепцию REST, нужно разобрать акроним на его составляющие: Representational — ресурсы в REST могут быть представлены в любой форме — JSON, XML, текст, или даже HTML — зависит от того, какие данные больше подходят потребителю State — при работе с REST вы должны быть сконцентрированы на состоянии ресурса, а не на действиях с ресурсом Transfer — REST включает себя передачу ресурсных данных, в любой представленной форме, от одного приложения другому. REST это передача состояний ресурса между сервером и клиентом.
Что такое ресурс?	Ресурс в REST это все, что может быть передано между клиентом и сервером.Вот несколько примеров ресурсов: Новость Температура в Санкт-Петербурге в понедельник в 4 утра Зарплата сотрудника Выборка из базы данных Результат поиска
Что обозначает CRUD?	Действия в REST определяются http-методами.Get, Post, Put, Delete, Patch, и другие. Самые часто-используемые обозначаются аббревиатурой CRUD: Create — POST Read — GET Update — PUT Delete — DELETE
REST безопасен? Как вы можете защитить его?	По умолчанию REST не защищен. Вы можете настроить безопасность с помощью Basic Auth, JWT, OAuth2
Что такое save operations?	Это операции, которые не модифицируют ресурсы. Вот их список: GET HEAD OPTIONS
Что такое идемпотентая операция? Почему идемпотентность важна?	Идемпотентые методы это методы, при каждом вызове которых результат будет одинаковый. То есть, результат после 1 вызова такого метода будет такой же, как и результат после 10 вызовов этого метода. Это важно для отказоустойчевого API. Предположим, что клиент хочет обновить ресурс с помощью POST-запроса? Если POST не идемпотентный метод, то при многократном вызове возникнут непредвиденные обновления ресурса. Используя идемпотентные методы, вы ограждаете себя от многих ошибок.
REST хорошо масштабируется?	Да. REST хорошо масштабируется потому что он не хранит состояние. Это значит что он не хранит информацию о пользовательских сессиях на сервере. Информация о клиенте не должна хранится на стороне сервера, а должна передаваться каждый раз туда, где она нужна. Вот что значит ST в REST, State Transfer. Вы передаете состояние, а не храните его на сервере. REST также интероперабельный это значит, что на нем могут взаимодействовать разные программы написанные на разных языках. Это исходит из 2ух факторов: Интероперабельные HTTP-клиенты. Разные клиенты должны отправлять одинаковые http-запросы. Интероперабельность на уровне медиа-типов. Различные клиенты должны корректно отправлять и получать одни и те же ресурсы.
Что такое HttpMessageConverter?	HttpMessageConverter конвертирует запрос в объект и наоборот. Spring имеет несколько реализаций этого интерфейса, а вы можете создать свою. В этом случае DispatcherServlet не использует Model и View. В REST вообще не существует Model и View. Есть только данные, поставляемые контроллером, и представление ресурса, когда сообщение конвертируется из медиа-типа(json, xml...) в объект. Список конвертеров: BufferedImageHttpMessageConverter — конвертирует BufferedImage в(из) код изображения. Jaxb2RootElementHttpMessageConverter — конвертирует xml в(из) объект, помеченный jaxb2 аннотациями. Регистрируется, если jaxb2 находится в classpath. MappingJackson2HttpMessageConverter — конвертирует JSON в(из) объект. Регистрируется, если Jackson 2 находится в classpath. StringHttpMessageConverter — конвертирует все медиа-файлы в text/plain.
Зачем нужна @ResponseBody?	@ResponseBody ставится на методы, которые работают с данными, а не с моделями. Ее не требуется указывать явно, если используется @RestController. Обычные методы возвращают Model, а методы аннотированные @ResponseBody возвращают объекты, которые конвертируются в медиа-файлы с помощью HttpMessageConverter.
Зачем нужна аннотация @PathVariable?	Эта аннотация получает определенную часть из URI. URI: http://localhost:8080/getById/23 Следующий код поместит в переменную id значение 23.
Зачем нужна аннотация @ResponseStatus?	Она позволяет устанавливать код ответа. Обычно Spring сам устанавливает нужный код ответа, но бывают моменты, когда это нужно переопределить. @PostMapping @ResponseStatus(HttpStatus.CREATED) public void add(...) {...} Вместо использования аннотации можно возвращать ResponseEntity и вручную устанавливать код ответа. Не рекомендуется использовать ResponseEntity и @ReponseStatus вместе.
Что такое ResponseEntity?	Это специальный класс, который представляет http-ответ. Он содержит тело ответа, код состояния, заголовки. Мы можем использовать его для более тонкой настройки http-ответа. Он является универсальным типом, и можно использовать любой объект в качестве тела: @GetMapping("/hello") ResponseEntity hello() { return new ResponseEntity("Hello World!", HttpStatus.OK); }
Какие нововведения, появились в Java 8 и JDK 8?	Методы интерфейсов по умолчанию; Лямбда-выражения; Функциональные интерфейсы; Ссылки на методы и конструкторы; Повторяемые аннотации; Аннотации на типы данных; Рефлексия для параметров методов; Stream API для работы с коллекциями; Параллельная сортировка массивов; Новое API для работы с датами и временем; Новый движок JavaScript Nashorn; Добавлено несколько новых классов для потокобезопасной работы; Добавлен новый API для Calendar и Locale; Добавлена поддержка Unicode 6.2.0; Добавлен стандартный класс для работы с Base64; Добавлена поддержка беззнаковой арифметики; Улучшена производительность конструктора java.lang.String(byte[], *) и метода java.lang.String.getBytes(); Новая реализация AccessController.doPrivileged, позволяющая устанавливать подмножество привилегий без необходимости проверки всех остальных уровней доступа; Password-based алгоритмы стали более устойчивыми; Добавлена поддержка SSL/TLS Server Name Indication (NSI) в JSSE Server; Улучшено хранилище ключей (KeyStore); Добавлен алгоритм SHA-224; Удален мост JDBC - ODBC; Удален PermGen, изменен способ хранения мета-данных классов; Возможность создания профилей для платформы Java SE, которые включают в себя не всю платформу целиком, а некоторую ее часть; Инструментарий - Добавлена утилита jjs для использования JavaScript Nashorn; - Команда java может запускать JavaFX приложения; - Добавлена утилита jdeps для анализа .class-файлов.
Что такое «лямбда»? Какова структура и особенности использования лямбда-выражения?	Лямбда представляет собой набор инструкций, которые можно выделить в отдельную переменную и затем многократно вызвать в различных местах программы. Основу лямбда-выражения составляет лямбда-оператор, который представляет стрелку ->. Этот оператор разделяет лямбда-выражение на две части: левая часть содержит список параметров выражения, а правая, собственно, представляет тело лямбда-выражения, где выполняются все действия. Лямбда-выражение не выполняется само по себе, а образует реализацию метода, определенного в функциональном интерфейсе. При этом важно, что функциональный интерфейс должен содержать только один единственный метод без реализации.
К каким переменным есть доступ у лямбда-выражений?	Доступ к переменным внешней области действия из лямбда-выражения очень схож к доступу из анонимных объектов. Можно ссылаться на: - неизменяемые (effectively final - не обязательно помеченные как final) локальные переменные; - поля класса; - статические переменные. К методам по умолчанию реализуемого функционального интерфейса обращаться внутри лямбда-выражения запрещено.
Что такое «ссылка на метод»?	Если существующий в классе метод уже делает все, что необходимо, то можно воспользоваться механизмом method reference (ссылка на метод) для непосредственной передачи этого метода. Такая ссылка передается в виде: имя_класса::имя_статического_метода для статического метода; объект_класса::имя_метода для метода экземпляра; название_класса::new для конструктора. Результат будет в точности таким же, как в случае определения лямбда-выражения, которое вызывает этот метод
Какие виды ссылок на методы вы знаете?	на статический метод; на метод экземпляра; на конструкторе.
Объясните выражение System.out::println.	Данное выражение иллюстрирует механизм instance method reference: передачи ссылки на метод println() статического поля out класса System.
Что такое «функциональные интерфейсы»?	Функциональный интерфейс - это интерфейс, который определяет только один абстрактный метод. Чтобы точно определить интерфейс как функциональный, добавлена аннотация @FunctionalInterface, работающая по принципу @Override. Она обозначит замысел и не даст определить второй абстрактный метод в интерфейсе. Интерфейс может включать сколько угодно default методов и при этом оставаться функциональным, потому что default методы - не абстрактные.
Для чего нужны функциональные интерфейсы Function<T,R>, DoubleFunction<R>, IntFunction<R> и LongFunction<R>?	Function<T, R> - интерфейс, с помощью которого реализуется функция, получающая на вход экземпляр класса T и возвращающая на выходе экземпляр класса R. Методы по умолчанию могут использоваться для построения цепочек вызовов (compose, andThen).  Типичный пример метода в Stream c аргументом Function — метод map, который принимает элементы одного типа, что-то с ними делает и передает дальше, но это уже могут быть элементы другого типа.  
Для чего нужны функциональные интерфейсы UnaryOperator<T>, DoubleUnaryOperator, IntUnaryOperator и LongUnaryOperator?	UnaryOperator<T> (унарный оператор) принимает в качестве параметра объект типа T, выполняет над ними операции и возвращает результат операций в виде объекта типа T:  В качестве метода, использующего UnaryOperator как аргумент, возьмем метод класса Stream — iterate.  DoubleUnaryOperator - унарный оператор, получающий на вход Double; IntUnaryOperator - унарный оператор, получающий на вход Integer; LongUnaryOperator - унарный оператор, получающий на вход Long.
Для чего нужны функциональные интерфейсы BinaryOperator<T>, DoubleBinaryOperator, IntBinaryOperator и LongBinaryOperator?	BinaryOperator<T> (бинарный оператор) - интерфейс, с помощью которого реализуется функция, получающая на вход два экземпляра класса T и возвращающая на выходе экземпляр класса T.   DoubleBinaryOperator - бинарный оператор, получающий на вход Double; IntBinaryOperator - бинарный оператор, получающий на вход Integer; LongBinaryOperator - бинарный оператор, получающий на вход Long.
Для чего нужны функциональные интерфейсы Predicate<T>, DoublePredicate, IntPredicate и LongPredicate?	Predicate<T> (предикат) - интерфейс, с помощью которого реализуется функция, получающая на вход экземпляр класса T и возвращающая на выходе значение типа boolean. Интерфейс содержит различные методы по умолчанию, позволяющие строить сложные условия (and, or, negate).  Для примера возьмем метод класса Stream — filter, который в качестве аргумента принимает Predicate и возвращает Stream только с теми элементами, которые удовлетворяют условию Predicate. В контексте Stream-а это означает, что он пропускает только те элементы, которые возвращают true при использовании их в методе test интерфейса Predicate.  DoublePredicate - предикат, получающий на вход Double; 
Для чего нужны функциональные интерфейсы Consumer<T>, DoubleConsumer, IntConsumer и LongConsumer?	Consumer<T> (потребитель) - интерфейс, с помощью которого реализуется функция, которая получает на вход экземпляр класса T, производит с ним некоторое действие и ничего не возвращает.  Одним из методом в Stream, который использует функциональный интерфейс Consumer, является метод peek
Для чего нужны функциональные интерфейсы Supplier<T>, BooleanSupplier, DoubleSupplier, IntSupplier и LongSupplier?	Supplier<T> (поставщик) - интерфейс, с помощью которого реализуется функция, ничего не принимающая на вход, но возвращающая на выход результат класса T;  Примером метода в Stream, использующего функциональный интерфейс Supplier, является generate, который генерирует бесконечную последовательность на основе переданного ему функционального интерфейса.  Supplier<LocalDateTime> now = LocalDateTime::now; now.get();  DoubleSupplier - поставщик, возвращающий Double; IntSupplier - поставщик, возвращающий Integer; LongSupplier - поставщик, возвращающий Long.
Для чего нужен функциональный интерфейс BiConsumer<T,U>?	BiConsumer<T,U> представляет собой операцию, которая принимает два аргумента классов T и U производит с ними некоторое действие и ничего не возвращает.
Для чего нужен функциональный интерфейс BiFunction<T,U,R>?	BiFunction<T,U,R> представляет собой операцию, которая принимает два аргумента классов T и U и возвращающая результат класса R.
Для чего нужен функциональный интерфейс BiPredicate<T,U>?	BiPredicate<T,U> представляет собой операцию, которая принимает два аргумента классов T и U и возвращающая результат типа boolean.
Для чего нужны функциональные интерфейсы вида _To_Function?	DoubleToIntFunction - операция, принимающая аргумент класса Double и возвращающая результат типа Integer; DoubleToLongFunction - операция, принимающая аргумент класса Double и возвращающая результат типа Long; IntToDoubleFunction - операция, принимающая аргумент класса Integer и возвращающая результат типа Double; IntToLongFunction - операция, принимающая аргумент класса Integer и возвращающая результат типа Long; LongToDoubleFunction - операция, принимающая аргумент класса Long и возвращающая результат типа Double; LongToIntFunction - операция, принимающая аргумент класса Long и возвращающая результат типа Integer.
Для чего нужны функциональные интерфейсы ToDoubleBiFunction<T,U>, ToIntBiFunction<T,U> и ToLongBiFunction<T,U>?	ToDoubleBiFunction<T,U> - операция принимающая два аргумента классов T и U и возвращающая результат типа Double; ToLongBiFunction<T,U> - операция принимающая два аргумента классов T и U и возвращающая результат типа Long; ToIntBiFunction<T,U> - операция принимающая два аргумента классов T и U и возвращающая результат типа Integer.
Для чего нужны функциональные интерфейсы ToDoubleFunction<T>, ToIntFunction<T> и ToLongFunction<T>?	ToDoubleFunction<T> - операция, принимающая аргумент класса T и возвращающая результат типа Double; ToLongFunction<T> - операция, принимающая аргумент класса T и возвращающая результат типа Long; ToIntFunction<T> - операция, принимающая аргумент класса T и возвращающая результат типа Integer.
Для чего нужны функциональные интерфейсы ObjDoubleConsumer<T>, ObjIntConsumer<T> и ObjLongConsumer<T>?	ObjDoubleConsumer<T> - операция, которая принимает два аргумента классов T и Double, производит с ними некоторое действие и ничего не возвращает; ObjLongConsumer<T> - операция, которая принимает два аргумента классов T и Long, производит с ними некоторое действие и ничего не возвращает; ObjIntConsumer<T> - операция, которая принимает два аргумента классов T и Integer, производит с ними некоторое действие и ничего не возвращает.
Что такое StringJoiner?	Класс StringJoiner используется, чтобы создать последовательность строк, разделенных разделителем с возможностью присоединить к полученной строке префикс и суффикс
Что такое default методы интрефейса?	Java 8 позволяет добавлять неабстрактные реализации методов в интерфейс, используя ключевое слово default. Если класс реализует интерфейс, он может, но не обязан, реализовать методы по-умолчанию, уже реализованные в интерфейсе. Класс наследует реализацию по умолчанию. - Если некий класс реализует несколько интерфейсов, которые имеют одинаковый метод по умолчанию, то класс должен реализовать метод с совпадающей сигнатурой самостоятельно. Ситуация аналогична, если один интерфейс имеет метод по умолчанию, а в другом этот же метод является абстрактным - никакой реализации по умолчанию классом не наследуется. - Метод по умолчанию не может переопределить метод класса java.lang.Object. - Помогают реализовывать интерфейсы без страха нарушить работу других классов. - Позволяют избежать создания служебных классов, так как все необходимые методы могут быть представлены в самих интерфейсах. - Дают свободу классам выбрать метод, который нужно переопределить. - Одной из основных причин внедрения методов по умолчанию является возможность коллекций в Java 8 использовать лямбда-выражения.
Как вызывать default метод интерфейса в реализующем этот интерфейс классе?	Используя ключевое слово super вместе с именем интерфейса
Что такое static метод интерфейса?	Статические методы интерфейса похожи на методы по умолчанию, за исключением того, что для них отсутствует возможность переопределения в классах, реализующих интерфейс. - Статические методы в интерфейсе являются частью интерфейса без возможности использовать их для объектов класса реализации; - Методы класса java.lang.Object нельзя переопределить как статические; - Статические методы в интерфейсе используются для обеспечения вспомогательных методов, например, проверки на null, сортировки коллекций и т.д.
Что такое Optional?	Опциональное значение Optional это контейнер для объекта, который может содержать или не содержать значение null. Такая обёртка является удобным средством предотвращения NullPointerException, т.к. имеет некоторые функции высшего порядка, избавляющие от добавления повторяющихся 
Что такое Stream?	Stream - это новый функциональный интерфейс, введенный в Java 8, который представляет последовательность элементов и поддерживает различные операции для работы с этими элементами. Stream позволяет выполнять функциональные операции на элементах, такие как фильтрация, отображение, сортировка, агрегация и другие, с использованием функциональных стилистических подходов, таких как лямбда-выражения. Stream не хранит данные, а работает с элементами на лету при выполнении операций. Он обеспечивает более простой и удобный способ работы с коллекциями и другими источниками данных, позволяя писать более компактный и выразительный код. Stream поддерживает ленивую вычислительную модель, что означает, что операции выполняются только при необходимости, оптимизируя использование ресурсов. Stream может быть создан из коллекций, массивов, файлов и других источников данных. Он предоставляет разнообразные операции, такие как filter, map, reduce, collect и другие, которые позволяют манипулировать данными и получать нужный результат. Stream также поддерживает параллельную обработку элементов для повышения производительности при работе с большими наборами данных.
Промежуточный оператор filter(Predicate predicate)	фильтрует элементы потока, оставляя только те, которые удовлетворяют заданному предикату.
Промежуточный оператор map(Function mapper)	преобразует каждый элемент потока с помощью заданного маппера.
Промежуточный оператор flatMap(Function<T, Stream<R>> mapper)	преобразует каждый элемент потока в новый поток элементов и объединяет их в один поток.
Промежуточный оператор mapMulti(BiConsumer<T, Consumer<R>> mapper)	применяет заданный маппер к каждому элементу потока и может порождать несколько элементов для каждого входного элемента.
Промежуточный оператор limit(long maxSize)	ограничивает поток указанным максимальным количеством элементов.
Промежуточный оператор skip(long n)	пропускает указанное количество элементов в потоке.
Промежуточный оператор distinct()	удаляет дублирующиеся элементы из потока.
Промежуточный оператор peek(Consumer action)	выполняет заданное действие для каждого элемента потока без изменения самих элементов.
Промежуточный оператор takeWhile(Predicate predicate)	берет элементы из потока, пока они удовлетворяют заданному предикату.
Промежуточный оператор dropWhile(Predicate predicate)	пропускает элементы в потоке, пока они удовлетворяют заданному предикату.
Промежуточный оператор boxed()	преобразует элементы потока примитивов в соответствующие объектные типы.
Терминальный оператор void forEach(Consumer action)	выполняет заданное действие для каждого элемента потока.
Терминальный оператор long count()	возвращает количество элементов в потоке.
Терминальный оператор R collect(Collector collector)	выполняет агрегацию элементов потока с использованием заданного коллектора.
Терминальный оператор Object[] toArray()	преобразует элементы потока в массив объектов.
Терминальный оператор List<T> toList()	преобразует элементы потока в список.
Терминальный оператор T reduce(T identity, BinaryOperator<T> accumulator)	выполняет агрегацию элементов потока с использованием заданного аккумулятора и начального значения.
Терминальный оператор Optional min(Comparator comparator)	находит минимальный элемент в потоке с использованием заданного компаратора.
Терминальный оператор boolean anyMatch(Predicate predicate)	проверяет, удовлетворяет ли хотя бы один элемент потока заданному предикату.
Терминальный оператор boolean noneMatch(Predicate predicate)	проверяет, не удовлетворяет ли ни один элемент потока заданному предикату.
Терминальный оператор OptionalDouble average()	вычисляет среднее значение элементов потока (если применяется к потоку примитивов).
Терминальный оператор sum()	вычисляет сумму элементов потока (если применяется к потоку примитивов).
Терминальный оператор IntSummaryStatistics summaryStatistics()	вычисляет статистическую информацию (сумму, среднее значение, максимум, минимум и т.д.) для элементов потока (если применяется к потоку примитивов типа int).
Какие существуют способы создания стрима?	Из коллекции: Stream<String> fromCollection = Arrays.asList("x", "y", "z").stream(); Из набора значений: Stream<String> fromValues = Stream.of("x", "y", "z"); Из массива: Stream<String> fromArray = Arrays.stream(new String[]{"x", "y", "z"}); Из файла (каждая строка в файле будет отдельным элементом в стриме): Stream<String> fromFile = Files.lines(Paths.get("input.txt")); Из строки: IntStream fromString = "0123456789".chars(); С помощью Stream.builder(): Stream<String> fromBuilder = Stream.builder().add("z").add("y").add("z").build(); С помощью Stream.iterate() (бесконечный): Stream<Integer> fromIterate = Stream.iterate(1, n -> n + 1); С помощью Stream.generate() (бесконечный): Stream<String> fromGenerate = Stream.generate(() -> "0");
В чем разница между Collection и Stream?	Коллекции позволяют работать с элементами по-отдельности, тогда как стримы так делать не позволяют, но вместо этого предоставляют возможность выполнять функции над данными как над одним целым. Также стоит отметить важность самой концепции сущностей: Collection - это прежде всего воплощение Структуры Данных. Например, Set не просто хранит в себе элементы, он реализует идею множества с уникальными элементами, тогда как Stream, это прежде всего абстракция необходимая для реализации конвейера вычислений, собственно, поэтому, результатом работы конвейера являются те или иные Структуры Данных или же результаты проверок/поиска и т.п.
Для чего нужен метод collect() в стримах?	Метод collect() является конечной операцией, которая используется для представление результата в виде коллекции или какой-либо другой структуры данных. collect() принимает на вход Collector<Тип_источника, Тип_аккумулятора, Тип_результата>, который содержит четыре этапа: supplier - инициализация аккумулятора, accumulator - обработка каждого элемента, combiner - соединение двух аккумуляторов при параллельном выполнении, [finisher] - необязательный метод последней обработки аккумулятора. В Java 8 в классе Collectors реализовано несколько распространённых коллекторов: toList(), toCollection(), toSet() - представляют стрим в виде списка, коллекции или множества; toConcurrentMap(), toMap() - позволяют преобразовать стрим в Map; averagingInt(), averagingDouble(), averagingLong() - возвращают среднее значение; summingInt(), summingDouble(), summingLong() - возвращает сумму; summarizingInt(), summarizingDouble(), summarizingLong() - возвращают SummaryStatistics с разными агрегатными значениями; partitioningBy() - разделяет коллекцию на две части по соответствию условию и возвращает их как Map<Boolean, List>; groupingBy() - разделяет коллекцию на несколько частей и возвращает Map<N, List<T>>; mapping() - дополнительные преобразования значений для сложных Collector-ов. Так же существует возможность создания собственного коллектора через Collector.of():  Collector<String, List<String>, List<String>> toList = Collector.of( ArrayList::new, List::add, (l1, l2) -> { l1.addAll(l2); return l1; } );
Для чего в стримах применяются методы forEach() и forEachOrdered()?	forEach() применяет функцию к каждому объекту стрима, порядок при параллельном выполнении не гарантируется; forEachOrdered() применяет функцию к каждому объекту стрима с сохранением порядка элементов.
Для чего в стримах предназначены методы map() и mapToInt(), mapToDouble(), mapToLong()?	Метод map() является промежуточной операцией, которая заданным образом преобразует каждый элемент стрима. mapToInt(), mapToDouble(), mapToLong() - аналоги map(), возвращающие соответствующий числовой стрим (то есть стрим из числовых примитивов)
Какова цель метода filter() в стримах?	Метод filter() является промежуточной операцией принимающей предикат, который фильтрует все элементы, возвращая только те, что соответствуют условию.
Для чего в стримах предназначен метод limit()?	Метод limit() является промежуточной операцией, которая позволяет ограничить выборку определенным количеством первых элементов.
Для чего в стримах предназначен метод sorted()?	Метод sorted() является промежуточной операцией, которая позволяет сортировать значения либо в натуральном порядке, либо задавая Comparator. Порядок элементов в исходной коллекции остается нетронутым - sorted() всего лишь создает его отсортированное представление.
Для чего в стримах предназначены методы flatMap(), flatMapToInt(), flatMapToDouble(), flatMapToLong()?	Метод flatMap() похож на map, но может создавать из одного элемента несколько. Таким образом, каждый объект будет преобразован в ноль, один или несколько других объектов, поддерживаемых потоком. Наиболее очевидный способ применения этой операции — преобразование элементов контейнера при помощи функций, которые возвращают контейнеры.  Stream .of("H e l l o", "w o r l d !") .flatMap((p) -> Arrays.stream(p.split(" "))) .toArray(String[]::new);//["H", "e", "l", "l", "o", "w", "o", "r", "l", "d", "!"]  flatMapToInt(), flatMapToDouble(), flatMapToLong() - это аналоги flatMap(), возвращающие соответствующий числовой стрим.
Расскажите о параллельной обработке в Java 8.	Стримы могут быть последовательными и параллельными. Операции над последовательными стримами выполняются в одном потоке процессора, над параллельными — используя несколько потоков процессора. Параллельные стримы используют общий ForkJoinPool доступный через статический ForkJoinPool.commonPool() метод. При этом, если окружение не является многоядерным, то поток будет выполняться как последовательный. Фактически применение параллельных стримов сводится к тому, что данные в стримах будут разделены на части, каждая часть обрабатывается на отдельном ядре процессора, и в конце эти части соединяются, и над ними выполняются конечные операции. Для создания параллельного потока из коллекции можно также использовать метод parallelStream() интерфейса Collection. Чтобы сделать обычный последовательный стрим параллельным, надо вызвать у объекта Stream метод parallel(). Метод isParallel() позволяет узнать является ли стрим параллельным. С помощью, методов parallel() и sequential() можно определять какие операции могут быть параллельными, а какие только последовательными. Так же из любого последовательного стрима можно сделать параллельный и наоборот:  collection . stream()  .peek(...) операция последовательна  .parallel()  .map(...) элементы передаются в стрим в том же порядке, в котором они определены в источнике данных. При работе с параллельными стримами система сохраняет порядок следования элементов. Исключение составляет метод forEach(), который может выводить элементы в произвольном порядке. И чтобы сохранить порядок следования, необходимо применять метод forEachOrdered().  Критерии, которые могут повлиять на производительность в параллельных стримах: - Размер данных - чем больше данных, тем сложнее сначала разделять данные, а потом их соединять. - Количество ядер процессора. Теоретически, чем больше ядер в компьютере, тем быстрее программа будет работать. Если на машине одно ядро, нет смысла применять параллельные потоки. - Чем проще структура данных, с которой работает поток, тем быстрее будут происходить операции. Например, данные из ArrayList легко использовать, так как структура данной коллекции предполагает последовательность несвязанных данных. А вот коллекция типа LinkedList - не лучший вариант, так как в последовательном списке все элементы связаны с предыдущими/последующими. И такие данные трудно распараллелить. - Над данными примитивных типов операции будут производиться быстрее, чем над объектами классов. - Крайне не рекомендуется использовать параллельные стримы для скольких-нибудь долгих операций (например, сетевых соединений), так как все параллельные стримы работают c одним ForkJoinPool, то такие долгие операции могут остановить работу всех параллельных стримов в JVM из-за отсутствия доступных потоков в пуле, т.е. параллельные стримы стоит использовать лишь для коротких операций, где счет идет на миллисекунды, но не для тех где счет может идти на секунды и минуты; - Сохранение порядка в параллельных стримах увеличивает издержки при выполнении и если порядок не важен, то имеется возможность отключить его сохранение и тем самым увеличить производительность, использовав промежуточную  операцию unordered():  collection.parallelStream()  .sorted()  .unordered() .collect(Collectors.toList());
Какие конечные методы работы со стримами вы знаете?	findFirst() возвращает первый элемент; findAny() возвращает любой подходящий элемент; collect() представление результатов в виде коллекций и других структур данных; count() возвращает количество элементов; anyMatch() возвращает true, если условие выполняется хотя бы для одного элемента; noneMatch() возвращает true, если условие не выполняется ни для одного элемента; allMatch() возвращает true, если условие выполняется для всех элементов; min() возвращает минимальный элемент, используя в качестве условия Comparator; max() возвращает максимальный элемент, используя в качестве условия Comparator; forEach() применяет функцию к каждому объекту (порядок при параллельном выполнении не гарантируется); forEachOrdered() применяет функцию к каждому объекту с сохранением порядка элементов; toArray() возвращает массив значений; reduce()позволяет выполнять агрегатные функции и возвращать один результат. Для числовых стримов дополнительно доступны: sum() возвращает сумму всех чисел; average() возвращает среднее арифметическое всех чисел.
Какие промежуточные методы работы со стримами вы знаете?	filter() отфильтровывает записи, возвращая только записи, соответствующие условию; skip() позволяет пропустить определённое количество элементов в начале; distinct() возвращает стрим без дубликатов (для метода equals()); map() преобразует каждый элемент; peek() возвращает тот же стрим, применяя к каждому элементу функцию; limit() позволяет ограничить выборку определенным количеством первых элементов; sorted() позволяет сортировать значения либо в натуральном порядке, либо задавая Comparator; mapToInt(), mapToDouble(), mapToLong() - аналоги map() возвращающие стрим числовых примитивов; flatMap(), flatMapToInt(), flatMapToDouble(), flatMapToLong() - похожи на map(), но могут создавать из одного элемента несколько. Для числовых стримов дополнительно доступен метод mapToObj(), который преобразует числовой стрим обратно в объектный.
Какие дополнительные методы для работы с ассоциативными массивами (maps) появились в Java 8?	- putIfAbsent() добавляет пару «ключ-значение», только если ключ отсутствовал: map.putIfAbsent("a", "Aa"); - forEach() принимает функцию, которая производит операцию над каждым элементом
Что такое LocalDateTime?	LocalDateTime объединяет вместе LocaleDate и LocalTime, содержит дату и время в календарной системе ISO-8601 без привязки к часовому поясу. Время хранится с точностью до наносекунды. Содержит множество удобных методов, таких как plusMinutes, plusHours, isAfter, toSecondOfDay и т.д.
Что такое ZonedDateTime?	java.time.ZonedDateTime — аналог java.util.Calendar, класс с самым полным объемом информации о временном контексте в календарной системе ISO-8601. Включает временную зону, поэтому все операции с временными сдвигами этот класс проводит с её учётом.
Как получить текущую дату с использованием Date Time API из Java 8?	LocalDate.now();
Как добавить 1 неделю, 1 месяц, 1 год, 10 лет к текущей дате с использованием Date Time API?	LocalDate.now().plusWeeks(1); LocalDate.now().plusMonths(1); LocalDate.now().plusYears(1); LocalDate.now().plus(1, ChronoUnit.DECADES);
Как получить следующий вторник используя Date Time API?	LocalDate.now().with(TemporalAdjusters.next(DayOfWeek.TUESDAY));
Как получить текущее время с точностью до миллисекунд используя Date Time API	new Date().toInstant();
Как получить текущее время по местному времени с точностью до миллисекунд используя Date Time API?	LocalDateTime.ofInstant(new Date().toInstant(), ZoneId.systemDefault());
Как определить повторяемую аннотацию?	Чтобы определить повторяемую аннотацию, необходимо создать аннотацию-контейнер для списка повторяемых аннотаций и обозначить повторяемую мета-аннотацией @Repeatable:  @interface Schedulers { Scheduler[] value(); }   @Repeatable(Schedulers.class)   @interface Scheduler { String birthday() default "Jan 8 1935"; }
Что такое Nashorn?	Nashorn - это движок JavaScript, разрабатываемый на Java компанией Oracle. Призван дать возможность встраивать код JavaScript в приложения Java. В сравнении с Rhino, который поддерживается Mozilla Foundation, Nashorn обеспечивает от 2 до 10 раз более высокую производительность, так как он компилирует код и передает байт-код виртуальной машине Java непосредственно в памяти. Nashorn умеет компилировать код JavaScript и генерировать классы Java, которые загружаются специальным загрузчиком. Так же возможен вызов кода Java прямо из JavaScript.
Что такое jjs?	jjs это утилита командной строки, которая позволяет исполнять программы на языке JavaScript прямо в консоли.
Какой класс появился в Java 8 для кодирования/декодирования данных?	Base64 - потокобезопасный класс, который реализует кодировщик и декодировщик данных, используя схему кодирования base64 согласно RFC 4648 и RFC 2045. Base64 содержит 6 основных методов: getEncoder()/getDecoder() - возвращает кодировщик/декодировщик base64, соответствующий стандарту RFC 4648; getUrlEncoder()/getUrlDecoder() - возвращает URL-safe кодировщик/декодировщик base64, соответствующий стандарту RFC 4648; getMimeEncoder()/getMimeDecoder() - возвращает MIME кодировщик/декодировщик, соответствующий стандарту RFC 2045.
Как создать Base64 кодировщик и декодировщик?	 нужно использовать метод getEncoder() класса Base64, который возвращает экземпляр класса Base64.Encoder. Затем можно использовать этот экземпляр для кодирования данных с помощью метода encodeToString(byte[]), который принимает массив байтов и возвращает строку с закодированными данными. Для создания декодировщика можно использовать метод getDecoder() класса Base64, который возвращает экземпляр класса Base64.Decoder. Затем можно использовать этот экземпляр для декодирования строк с помощью метода decode(String), который принимает закодированную строку и возвращает массив байтов с декодированными данными.
empty()	Стрим, как и коллекция, может быть пустым, а значит всем последующем операторам нечего будет обрабатывать.
ofNullable(T t)	Появился в Java 9. Возвращает пустой стрим, если в качестве аргумента передан null, в противном случае, возвращает стрим из одного элемента.
generate(Supplier s)	Возвращает стрим с бесконечной последовательностью элементов, генерируемых функцией Supplier s.
builder()	Создаёт мутабельный объект для добавления элементов в стрим без использования какого-либо контейнера для этого.
Collector	Интерфейс java.util.stream.Collector служит для сбора элементов стрима в некоторый мутабельный контейнер. Он состоит из таких методов:  - Supplier<A> supplier() — функция, которая создаёт экземпляры контейнеров.  - BiConsumer<A,T> accumulator() — функция, которая кладёт новый элемент в контейнер.  - BinaryOperator<A> combiner() — функция, которая объединяет два контейнера в один. В параллельных стримах каждая часть может собираться в отдельный экземпляр контейнера и в итоге необходимо их объединять в один результирующий.  - Function<A,R> finisher() — функция, которая преобразовывает весь контейнер в конечный результат. Например, можно обернуть List в Collections.unmodifiableList.  - Set<Characteristics> characteristics() — возвращает характеристики коллектора, чтобы внутренняя реализация знала, с чем имеет дело. Например, можно указать, что коллектор поддерживает многопоточность. Характеристики: - CONCURRENT — коллектор поддерживает многопоточность, а значит отдельные части стрима могут быть успешно положены в контейнер из другого потока. - UNORDERED — коллектор не зависит от порядка поступаемых элементов. - IDENTITY_FINISH — функция finish() имеет стандартную реализацию (Function.identity()), а значит её можно не вызывать.
Spliterator	Основное использование Java Spliterator - разделение ввода на разные части, а затем параллельная обработка каждой части отдельно. Полезно обрабатывать большие объемы данных с помощью параллельного программирования.  Методы интерфейса:  - trySplit — как следует из названия, пытается разделить элементы на две части. Если это сделать не получается, либо элементов недостаточно для разделения, то вернёт null. В остальных случаях возвращает ещё один Spliterator с частью данных.  - tryAdvance(Consumer action) — если имеются элементы, для которых можно применить действие, то оно применяется и возвращает true, в противном случае возвращается false, но действие не выполняется.  - estimateSize() — возвращает примерное количество элементов, оставшихся для обработки, либо Long.MAX_VALUE, если стрим бесконечный или посчитать количество невозможно.  - characteristics() — возвращает характеристики сплитератора.
Что такое функциональное программирование?	Функциональное программирование - способ организации вычислений без состояния. Строго говоря, состояние у такой программы конечно есть, это - совокупность контекстов всех её функций. Но: главная проблема, стоящая за сложностями состояния, идентичности и изменения, состоит в том, что, введя присваивание, мы вынуждены внести в свои вычислительные модели понятие времени (time). До того, как появилось присваивание, наши программы от времени не зависели — в том смысле, что всякое выражение, обладающее значением, всегда имело одно и то же значение.
TCP/IP vs UDP	Протокол TCP (Transmission Control Protocol) - это сетевой протокол, который «заточен» под соединение. Иными словами, прежде, чем начать обмен данными, данному протоколу требуется установить соединение между двумя хостами. Данный протокол имеет высокую надежность, поскольку позволяет не терять данные при передаче, запрашивает подтверждения о получении от принимающей стороны и в случае необходимости отправляет данные повторно. При этом отправляемые пакеты данных сохраняют порядок отправки, то есть можно сказать, что передача данных упорядочена. Минусом данного протокола является относительно низкая скорость передачи данных, за счет того что выполнение надежной и упорядоченной передачи занимает больше времени, чем в альтернативном протоколе UDP.  Протокол UDP (User Datagram Protocol), в свою очередь, более прост. Для передачи данных ему не обязательно устанавливать соединение между отправителем и получателем. Информация передается без предварительной проверки готовности принимающей стороны. Это делает протокол менее надежным - при передаче некоторые фрагменты данных могут теряться. Кроме того, упорядоченность данных не соблюдается - возможен непоследовательный прием данных получателем. Зато скорость передачи данных по данному транспортному протоколу будет более высокой.  Надежность: в этом случае предпочтительнее будет протокол TCP, за счет подтверждения получения данных, повторной отправки в случае необходимости, а также использованию такого инструмента как тайм-аут. Протокол UDP такого инструментария не имеет, а потому при получении отправленные данные могут приходить не полностью;  Упорядоченность: опять будет предпочтительнее TCP, поскольку этот протокол гарантирует передачу пакетов данных именно в том порядке, в котором они были отправлены. В случае с UDP такой порядок не соблюдается;  Скорость: здесь уже лидировать будет UDP, так как более тяжеловесному TCP-протоколу будет требоваться больше времени для установки соединения, подтверждения получения, повторной отправки данных и т.д. ;  Метод передачи данных: в случае с TCP данные передаются потоково, границы фрагментов данных не имеют обозначения. В случае с UDP данные передаются в виде датаграмм - проверка пакетов на целостность осуществляется принимающей стороной только в случае получения сообщения. Также пакеты данных имеют определенные обозначения границ;
Что такое «коллекция»?	«Коллекция» - это структура данных, набор каких-либо объектов. Данными (объектами в наборе) могут быть числа, строки, объекты пользовательских классов и т.п.
Назовите основные интерфейсы JCF и их реализации.	На вершине иерархии в Java Collection Framework располагаются 2 интерфейса: Collection и Map. Эти интерфейсы разделяют все коллекции, входящие во фреймворк на две части по типу хранения данных: простые последовательные наборы элементов и наборы пар «ключ — значение» соответственно.  Интерфейс Collection расширяют интерфейсы: - List (список) представляет собой коллекцию, в которой допустимы дублирующие значения. Элементы такой коллекции пронумерованы, начиная от нуля, к ним можно обратиться по индексу. Реализации: -- ArrayList - инкапсулирует в себе обычный массив, длина которого автоматически увеличивается при добавлении новых элементов. -- LinkedList (двунаправленный связный список) - состоит из узлов, каждый из которых содержит как собственно данные, так и две ссылки на следующий и предыдущий узел. -- Vector — реализация динамического массива объектов, методы которой синхронизированы. -- Stack — реализация стека LIFO (last-in-first-out). - Set (сет) описывает неупорядоченную коллекцию, не содержащую повторяющихся элементов. Реализации: -- HashSet - использует HashMap для хранения данных. В качестве ключа и значения используется добавляемый элемент. Из-за особенностей реализации порядок элементов не гарантируется при добавлении. -- LinkedHashSet — гарантирует, что порядок элементов при обходе коллекции будет идентичен порядку добавления элементов. -- TreeSet — предоставляет возможность управлять порядком элементов в коллекции при помощи объекта Comparator, либо сохраняет элементы с использованием «natural ordering». - Queue (очередь) предназначена для хранения элементов с предопределённым способом вставки и извлечения FIFO (first-in-first-out): -- PriorityQueue — предоставляет возможность управлять порядком элементов в коллекции при помощи объекта Comparator, либо сохраняет элементы с использованием «natural ordering». -- ArrayDeque — реализация интерфейса Deque, который расширяет интерфейс Queue методами, позволяющими реализовать конструкцию вида LIFO (last-in-first-out).  Интерфейс Map реализован классами: - Hashtable — хэш-таблица, методы которой синхронизированы. Не позволяет использовать null в качестве значения или ключа и не является упорядоченной. - HashMap — хэш-таблица. Позволяет использовать null в качестве значения или ключа и не является упорядоченной. - LinkedHashMap — упорядоченная реализация хэш-таблицы. - TreeMap — реализация, основанная на красно-чёрных деревьях. Является упорядоченной и предоставляет возможность управлять порядком элементов в коллекции при помощи объекта Comparator, либо сохраняет элементы с использованием «natural ordering». - WeakHashMap — реализация хэш-таблицы, которая организована с использованием weak references для ключей (сборщик мусора автоматически удалит элемент из коллекции при следующей сборке мусора, если на ключ этого элемента нет жёстких ссылок).
Расположите в виде иерархии следующие интерфейсы: List, Set, Map, SortedSet, SortedMap, Collection, Iterable, Iterator, NavigableSet, NavigableMap.	Iterable - Collection -- List -- Set --- SortedSet ---- NavigableSet Map - SortedMap -- NavigableMap Iterator
Почему Map это не Collection, в то время как List и Set являются Collection?	Collection представляет собой совокупность некоторых элементов. Map - это совокупность пар «ключ-значение».
В чем разница между классами java.util.Collection и java.util.Collections?	java.util.Collections - набор статических методов для работы с коллекциями.  java.util.Collection - один из основных интерфейсов Java Collections Framework.
Что такое «fail-fast поведение»?	fail-fast поведение означает, что при возникновении ошибки или состояния, которое может привести к ошибке, система немедленно прекращает дальнейшую работу и уведомляет об этом. Использование fail-fast подхода позволяет избежать недетерминированного поведения программы в течение времени. В Java Collections API некоторые итераторы ведут себя как fail-fast и выбрасывают ConcurrentModificationException, если после его создания была произведена модификация коллекции, т.е. добавлен или удален элемент напрямую из коллекции, а не используя методы итератора. Реализация такого поведения осуществляется за счет подсчета количества модификаций коллекции (modification count): - при изменении коллекции счетчик модификаций так же изменяется; - при создании итератора ему передается текущее значение счетчика; - при каждом обращении к итератору сохраненное значение счетчика сравнивается с текущим, и, если они не совпадают, возникает исключение.
Какая разница между fail-fast и fail-safe?	В противоположность fail-fast, итераторы fail-safe не вызывают никаких исключений при изменении структуры, потому что они работают с клоном коллекции вместо оригинала.
Приведите примеры итераторов, реализующих поведение fail-safe	Итератор коллекции CopyOnWriteArrayList и итератор представления keySet коллекции ConcurrentHashMap являются примерами итераторов fail-safe.
Чем различаются Enumeration и Iterator.	Хотя оба интерфейса и предназначены для обхода коллекций между ними имеются существенные различия: - с помощью Enumeration нельзя добавлять/удалять элементы; - в Iterator исправлены имена методов для повышения читаемости кода (Enumeration.hasMoreElements() соответствует Iterator.hasNext(), Enumeration.nextElement() соответствует Iterator.next() и т.д); - Enumeration присутствуют в устаревших классах, таких как Vector/Stack, тогда как Iterator есть во всех современных классах-коллекциях.
Как между собой связаны Iterable и Iterator?	Интерфейс Iterable имеет только один метод - iterator(), который возвращает Iterator.
Как между собой связаны Iterable, Iterator и «for-each»?	Классы, реализующие интерфейс Iterable, могут применяться в конструкции for-each, которая использует Iterator.
Сравните Iterator и ListIterator.	- ListIterator расширяет интерфейс Iterator - ListIterator может быть использован только для перебора элементов коллекции List; - Iterator позволяет перебирать элементы только в одном направлении, при помощи метода next(). Тогда как ListIterator позволяет перебирать список в обоих направлениях, при помощи методов next() и previous(); - ListIterator не указывает на конкретный элемент: его текущая позиция располагается между элементами, которые возвращают методы previous() и next(). - При помощи ListIterator вы можете модифицировать список, добавляя/удаляя элементы с помощью методов add() и remove(). Iterator не поддерживает данного функционала.
Что произойдет при вызове Iterator.next() без предварительного вызова Iterator.hasNext()?	Если итератор указывает на последний элемент коллекции, то возникнет исключение NoSuchElementException, иначе будет возвращен следующий элемент.
Сколько элементов будет пропущено, если Iterator.next() будет вызван после 10-ти вызовов Iterator.hasNext()?	Нисколько - hasNext() осуществляет только проверку наличия следующего элемента.
Как поведёт себя коллекция, если вызвать iterator.remove()?	Если вызову iterator.remove() предшествовал вызов iterator.next(), то iterator.remove() удалит элемент коллекции, на который указывает итератор, в противном случае будет выброшено IllegalStateException().
Как поведёт себя уже инстанциированный итератор для collection, если вызвать collection.remove()?	При следующем вызове методов итератора будет выброшено ConcurrentModificationException.
Как избежать ConcurrentModificationException во время перебора коллекции?	- Попробовать подобрать или реализовать самостоятельно другой итератор, работающий по принципу fail-safe. - Использовать ConcurrentHashMap и CopyOnWriteArrayList. - Преобразовать список в массив и перебирать массив. - Блокировать изменения списка на время перебора с помощью блока synchronized.  Отрицательная сторона последних двух вариантов - ухудшение производительности.
Какая коллекция реализует дисциплину обслуживания FIFO?	FIFO, First-In-First-Out («первым пришел-первым ушел») - по этому принципу построена коллекция Queue.
Какая коллекция реализует дисциплину обслуживания FILO?	FILO, First-In-Last-Out («первым пришел, последним ушел») - по этому принципу построена коллекция Stack.
Чем отличается ArrayList от Vector?	- Методы класса Vector синхронизированы, а ArrayList - нет; - По умолчанию, Vector удваивает свой размер, когда заканчивается выделенная под элементы память. ArrayList же увеличивает свой размер только на половину.  Vector это устаревший класс и его использование не рекомендовано.
Чем отличается ArrayList от LinkedList? В каких случаях лучше использовать первый, а в каких второй?	ArrayList это список, реализованный на основе массива, а LinkedList это классический двусвязный список, основанный на объектах с ссылками между ними. ArrayList: - доступ к произвольному элементу по индексу за константное время O(1); - доступ к элементам по значению за линейное время O(N); - вставка в конец в среднем производится за константное время O(1); - удаление произвольного элемента из списка занимает значительное время т.к. при этом все элементы, находящиеся «правее» смещаются на одну ячейку влево (реальный размер массива (capacity) не изменяется); - вставка элемента в произвольное место списка занимает значительное время т.к. при этом все элементы, находящиеся «правее» смещаются на одну ячейку вправо; - минимум накладных расходов при хранении. LinkedList: - на получение элемента по индексу или значению потребуется линейное время O(N); - на добавление и удаление в начало или конец списка потребуется константное O(1); - вставка или удаление в/из произвольного место константное O(1); - требует больше памяти для хранения такого же количества элементов, потому что кроме самого элемента хранятся еще указатели на следующий и предыдущий элементы списка.  В целом, LinkedList в абсолютных величинах проигрывает ArrayList и по потребляемой памяти, и по скорости выполнения операций. LinkedList предпочтительно применять, когда нужны частые операции вставки/удаления или в случаях, когда необходимо гарантированное время добавления элемента в список.
Что работает быстрее ArrayList или LinkedList?	Смотря какие действия будут выполняться над структурой.
Какое худшее время работы метода contains() для элемента, который есть в LinkedList?	O(N). Время поиска элемента линейно пропорционально количеству элементов в списке.
Какое худшее время работы метода contains() для элемента, который есть в ArrayList?	O(N). Время поиска элемента линейно пропорционально количеству элементов с списке.
Какое худшее время работы метода add() для LinkedList?	O(N). Добавление в начало/конец списка осуществляется за время O(1).
Какое худшее время работы метода add() для ArrayList?	O(N). Вставка элемента в конец списка осуществляется за время O(1), но если вместимость массива недостаточна, то происходит создание нового массива с увеличенным размером и копирование всех элементов из старого массива в новый.
Необходимо добавить 1 млн. элементов, какую структуру вы используете?	Однозначный ответ можно дать только исходя из информации о том в какую часть списка происходит добавление элементов, что потом будет происходить с элементами списка, существуют ли какие-то ограничения по памяти или скорости выполнения.
Как происходит удаление элементов из ArrayList? Как меняется в этом случае размер ArrayList?	При удалении произвольного элемента из списка, все элементы, находящиеся «правее» смещаются на одну ячейку влево и реальный размер массива (его емкость, capacity) не изменяется никак. Механизм автоматического «расширения» массива существует, а вот автоматического «сжатия» нет, можно только явно выполнить «сжатие» командой trimToSize().
Предложите эффективный алгоритм удаления нескольких рядом стоящих элементов из середины списка, реализуемого ArrayList	Допустим нужно удалить n элементов с позиции m в списке. Вместо выполнения удаления одного элемента n раз (каждый раз смещая на 1 позицию элементы, стоящие «правее» в списке), нужно выполнить смещение всех элементов, стоящих «правее» n + m позиции на n элементов «левее» к началу списка. Таким образом, вместо выполнения n итераций перемещения элементов списка, все выполняется за 1 проход. Но если говорить об общей эффективности - то самый быстрый способ будет с использованием System.arraycopy(), и получить к нему доступ можно через метод - subList(int fromIndex, int toIndex)
Сколько необходимо дополнительной памяти при вызове ArrayList.add()?	Если в массиве достаточно места для размещения нового элемента, то дополнительной памяти не требуется. Иначе происходит создание нового массива размером в 1,5 раза превышающим существующий (это верно для JDK выше 1.7, в более ранних версиях размер увеличения иной).
Сколько выделяется дополнительно памяти при вызове LinkedList.add()?	Создается один новый экземпляр вложенного класса Node.
Оцените количество памяти на хранение одного примитива типа byte в LinkedList?	Каждый элемент LinkedList хранит ссылку на предыдущий элемент, следующий элемент и ссылку на данные.  private static class Node<E> { E item;  Node<E> next;  Node<E> prev;  //...  }  Для 32-битных систем каждая ссылка занимает 32 бита (4 байта). Сам объект (заголовок) вложенного класса Node занимает 8 байт. 4 + 4 + 4 + 8 = 20 байт, а т.к. размер каждого объекта в Java кратен 8, соответственно получаем 24 байта. Примитив типа byte занимает 1 байт памяти, но в JCF примитивы упаковываются: объект типа Byte занимает в памяти 16 байт (8 байт на заголовок объекта, 1 байт на поле типа byte и 7 байт для кратности 8). Также напомню, что значения от -128 до 127 кэшируются и для них новые объекты каждый раз не создаются. Таким образом, в x32 JVM 24 байта тратятся на хранение одного элемента в списке и 16 байт - на хранение упакованного объекта типа Byte. Итого 40 байт. Для 64-битной JVM каждая ссылка занимает 64 бита (8 байт), размер заголовка каждого объекта составляет 16 байт (два машинных слова). Вычисления аналогичны: 8 + 8 + 8 + 16 = 40байт и 24 байта. Итого 64 байта
Оцените количество памяти на хранение одного примитива типа byte в ArrayList?	ArrayList основан на массиве, для примитивных типов данных осуществляется автоматическая упаковка значения, поэтому 16 байт тратится на хранение упакованного объекта и 4 байта (8 для x64) - на хранение ссылки на этот объект в самой структуре данных. Таким образом, в x32 JVM 4 байта используются на хранение одного элемента и 16 байт - на хранение упакованного объекта типа Byte. Для x64 - 8 байт и 24 байта соответственно.
Для ArrayList или для LinkedList операция добавления элемента в середину (list.add(list.size()/2, newElement)) медленнее?	Для ArrayList: - проверка массива на вместимость. Если вместимости недостаточно, то увеличение размера массива и копирование всех элементов в новый массив (O(N)); - копирование всех элементов, расположенных правее от позиции вставки, на одну позицию вправо (O(N)); - вставка элемента (O(1)). Для LinkedList: - поиск позиции вставки (O(N)); - вставка элемента (O(1)).  В худшем случае вставка в середину списка эффективнее для LinkedList. В остальных - скорее всего, для ArrayList, поскольку копирование элементов осуществляется за счет вызова быстрого системного метода System.arraycopy().
В реализации класса ArrayList есть следующие поля: Object[] elementData, int size. Объясните, зачем хранить отдельно size, если всегда можно взять elementData.length?	Размер массива elementData представляет собой вместимость (capacity) ArrayList, которая всегда больше переменной size - реального количества хранимых элементов. При необходимости вместимость автоматически возрастает.
Кто кого расширяет: Queue расширяет Deque, или Deque расширяет Queue?	Queue - это очередь, которая обычно (но необязательно) строится по принципу FIFO (First-In-First-Out) - соответственно извлечение элемента осуществляется с начала очереди, вставка элемента - в конец очереди. Хотя этот принцип нарушает, к примеру, PriorityQueue, использующая «natural ordering» или переданный Comparator при вставке нового элемента. Deque (Double Ended Queue) расширяет Queue и согласно документации, это линейная коллекция, поддерживающая вставку/извлечение элементов с обоих концов. Помимо этого, реализации интерфейса Deque могут строится по принципу FIFO, либо LIFO. Реализации и Deque, и Queue обычно не переопределяют методы equals() и hashCode(), вместо этого используются унаследованные методы класса Object, основанные на сравнении ссылок.
Почему LinkedList реализует и List, и Deque?	LinkedList позволяет добавлять элементы в начало и конец списка за константное время, что хорошо согласуется с поведением интерфейса Deque.
LinkedList это односвязный, двусвязный или четырехсвязный список?	Двусвязный: каждый элемент LinkedList хранит ссылку на предыдущий и следующий элементы.
Как перебрать элементы LinkedList в обратном порядке, не используя медленный get(index)?	Для этого в LinkedList есть обратный итератор, который можно получить вызва метод descendingIterator().
Что позволяет сделать PriorityQueue?	Особенностью PriorityQueue является возможность управления порядком элементов. По-умолчанию, элементы сортируются с использованием «natural ordering», но это поведение может быть переопределено при помощи объекта Comparator, который задаётся при создании очереди. Данная коллекция не поддерживает null в качестве элементов. Используя PriorityQueue, можно, например, реализовать алгоритм Дейкстры для поиска кратчайшего пути от одной вершины графа к другой. Либо для хранения объектов согласно определённого свойства.
Stack считается «устаревшим». Чем его рекомендуют заменять? Почему?	Stack был добавлен в Java 1.0 как реализация стека LIFO (last-in-first-out) и является расширением коллекции Vector, хотя это несколько нарушает понятие стека (например, класс Vector предоставляет возможность обращаться к любому элементу по индексу). Является частично синхронизированной коллекцией (кроме метода добавления push()) с вытекающими отсюда последствиями в виде негативного воздействия на производительность. После добавления в Java 1.6 интерфейса Deque, рекомендуется использовать реализации именно этого интерфейса, например, ArrayDeque.
Зачем нужен HashMap, если есть Hashtable?	- Методы класса Hashtable синхронизированы, что приводит к снижению производительности, а HashMap - нет; - HashTable не может содержать элементы null, тогда как HashMap может содержать один ключ null и любое количество значений null; - Iterator у HashMap, в отличие от Enumeration у HashTable, работает по принципу «fail-fast» (выдает исключение при любой несогласованности данных).  Hashtable это устаревший класс и его использование не рекомендовано.
В чем разница между HashMap и IdentityHashMap? Для чего нужна IdentityHashMap?	IdentityHashMap - это структура данных, так же реализующая интерфейс Map и использующая при сравнении ключей (значений) сравнение ссылок, а не вызов метода equals(). Другими словами, в IdentityHashMap два ключа k1 и k2 будут считаться равными, если они указывают на один объект, т.е. выполняется условие k1 == k2. IdentityHashMap не использует метод hashCode(), вместо которого применяется метод System.identityHashCode(), по этой причине IdentityHashMap по сравнению с HashMap имеет более высокую производительность, особенно если последний хранит объекты с дорогостоящими методами equals() и hashCode(). Одним из основных требований к использованию HashMap является неизменяемость ключа, а, т.к. IdentityHashMap не использует методы equals() и hashCode(), то это правило на него не распространяется. IdentityHashMap может применяться для реализации сериализации/клонирования. При выполнении подобных алгоритмов программе необходимо обслуживать хэш-таблицу со всеми ссылками на объекты, которые уже были обработаны. Такая структура не должна рассматривать уникальные объекты как равные, даже если метод equals() возвращает true.
В чем разница между HashMap и WeakHashMap? Для чего используется WeakHashMap?	В Java существует 4 типа ссылок: сильные (strong reference), мягкие (SoftReference), слабые (WeakReference) и фантомные (PhantomReference). Особенности каждого типа ссылок связаны с работой Garbage Collector. Если объект можно достичь только с помощью цепочки WeakReference (то есть на него отсутствуют сильные и мягкие ссылки), то данный объект будет помечен на удаление. WeakHashMap - это структура данных, реализующая интерфейс Map и основанная на использовании WeakReference для хранения ключей. Таким образом, пара «ключ-значение» будет удалена из WeakHashMap, если на объект-ключ более не имеется сильных ссылок. В качестве примера использования такой структуры данных можно привести следующую ситуацию: допустим имеются объекты, которые необходимо расширить дополнительной информацией, при этом изменение класса этих объектов нежелательно либо невозможно. В этом случае добавляем каждый объект в WeakHashMap в качестве ключа, а в качестве значения - нужную информацию. Таким образом, пока на объект имеется сильная ссылка (либо мягкая), можно проверять хэш-таблицу и извлекать информацию. Как только объект будет удален, то WeakReference для этого ключа будет помещен в ReferenceQueue и затем соответствующая запись для этой слабой ссылки будет удалена из WeakHashMap.
В WeakHashMap используются WeakReferences. А почему бы не создать SoftHashMap на SoftReferences?	SoftHashMap представлена в сторонних библиотеках, например, в Apache Commons.
В WeakHashMap используются WeakReferences. А почему бы не создать PhantomHashMap на PhantomReferences?	PhantomReference при вызове метода get() возвращает всегда null, поэтому тяжело представить назначение такой структуры данных.
LinkedHashMap - что в нем от LinkedList, а что от HashMap?	Реализация LinkedHashMap отличается от HashMap поддержкой двухсвязанного списка, определяющего порядок итерации по элементам структуры данных. По умолчанию элементы списка упорядочены согласно их порядку добавления в LinkedHashMap (insertion-order). Однако порядок итерации можно изменить, установив параметр конструктора accessOrder в значение true. В этом случае доступ осуществляется по порядку последнего обращения к элементу (access-order). Это означает, что при вызове методов get() или put() элемент, к которому обращаемся, перемещается в конец списка. При добавлении элемента, который уже присутствует в LinkedHashMap (т.е. с одинаковым ключом), порядок итерации по элементам не изменяется.
В чем проявляется «сортированность» SortedMap, кроме того, что toString() выводит все элементы по порядку?	Так же оно проявляется при итерации по коллекции.
Как устроен HashMap?	HashMap состоит из «корзин» (bucket). С технической точки зрения «корзины» это элементы массива, которые хранят ссылки на списки элементов. При добавлении новой пары «ключ-значение», вычисляет хэш-код ключа, на основании которого вычисляется номер корзины (номер ячейки массива), в которую попадет новый элемент. Если корзина пустая, то в нее сохраняется ссылка на вновь добавляемый элемент, если же там уже есть элемент, то происходит последовательный переход по ссылкам между элементами в цепочке, в поисках последнего элемента, от которого и ставится ссылка на вновь добавленный элемент. Если в списке был найден элемент с таким же ключом, то он заменяется.
Согласно Кнуту и Кормену существует две основных реализации хэш-таблицы: на основе открытой адресации и на основе метода цепочек. Как реализована HashMap? Почему, по вашему мнению, была выбрана именно эта реализация? В чем плюсы и минусы каждого подхода?	HashMap реализован с использованием метода цепочек, т.е. каждой ячейке массива (корзине) соответствует свой связный список и при возникновении коллизии осуществляется добавление нового элемента в этот список. Для метода цепочек коэффициент заполнения может быть больше 1 и с увеличением числа элементов производительность убывает линейно. Такие таблицы удобно использовать, если заранее неизвестно количество хранимых элементов, либо их может быть достаточно много, что приводит к большим значениям коэффициента заполнения. Среди методов открытой реализации различают: - линейное пробирование; - квадратичное пробирование; - двойное хэширование. Недостатки структур с методом открытой адресации: - Количество элементов в хэш-таблице не может превышать размера массива. По мере увеличения числа элементов и повышения коэффициента заполнения производительность структуры резко падает, поэтому необходимо проводить перехэширование. - Сложно организовать удаление элемента. - Первые два метода открытой адресации приводят к проблеме первичной и вторичной группировок. Преимущества хэш-таблицы с открытой адресацией: - отсутствие затрат на создание и хранение объектов списка; - простота организации сериализации/десериализации объекта.
Как работает HashMap при попытке сохранить в него два элемента по ключам с одинаковым hashCode(), но для которых equals() == false?	По значению hashCode() вычисляется индекс ячейки массива, в список которой этот элемент будет добавлен. Перед добавлением осуществляется проверка на наличие элементов в этой ячейке. Если элементы с таким hashCode() уже присутствует, но их equals() методы не равны, то элемент будет добавлен в конец списка.
Какое начальное количество корзин в HashMap?	В конструкторе по умолчанию - 16, используя конструкторы с параметрами можно задавать произвольное начальное количество корзин.
Какова оценка временной сложности операций над элементами из HashMap? Гарантирует ли HashMap указанную сложность выборки элемента?	В общем случае операции добавления, поиска и удаления элементов занимают константное время. Данная сложность не гарантируется, т.к. если хэш-функция распределяет элементы по корзинам равномерно, временная сложность станет не хуже Логарифмического времени O(log(N)), а в случае, когда хэш-функция постоянно возвращает одно и то же значение, HashMap превратится в связный список со сложностью О(n).
Возможна ли ситуация, когда HashMap выродится в список даже с ключами имеющими разные hashCode()?	Это возможно в случае, если метод, определяющий номер корзины будет возвращать одинаковые значения.
В каком случае может быть потерян элемент в HashMap?	Допустим, в качестве ключа используется не примитив, а объект с несколькими полями. После добавления элемента в HashMap у объекта, который выступает в качестве ключа, изменяют одно поле, которое участвует в вычислении хэш-кода. В результате при попытке найти данный элемент по исходному ключу, будет происходить обращение к правильной корзине, а вот equals уже не найдет указанный ключ в списке элементов. Тем не менее, даже если equals реализован таким образом, что изменение данного поля объекта не влияет на результат, то после увеличения размера корзин и пересчета хэш-кодов элементов, указанный элемент, с измененным значением поля, с большой долей вероятности попадет в совершенно другую корзину и тогда уже потеряется совсем.
Почему нельзя использовать byte[] в качестве ключа в HashMap?	Хэш-код массива не зависит от хранимых в нем элементов, а присваивается при создании массива (метод вычисления хэш-кода массива не переопределен и вычисляется по стандартному Object.hashCode() на основании адреса массива). Так же у массивов не переопределен equals и выполняется сравнение указателей. Это приводит к тому, что обратиться к сохраненному с ключом-массивом элементу не получится при использовании другого массива такого же размера и с такими же элементами, доступ можно осуществить лишь в одном случае — при использовании той же самой ссылки на массив, что использовалась для сохранения элемента.
Какова роль equals() и hashCode() в HashMap?	hashCode позволяет определить корзину для поиска элемента, а equals используется для сравнения ключей элементов в списке корзины и искомого ключа.
Каково максимальное число значений hashCode()?	Число значений следует из сигнатуры int hashCode() и равно диапазону типа int — 2^32.
Какое худшее время работы метода get(key) для ключа, которого нет в HashMap?	O(N). Худший случай - это поиск ключа в HashMap, вырожденного в список по причине совпадения ключей по hashCode() и для выяснения хранится ли элемент с определённым ключом может потребоваться перебор всего списка.
Сколько переходов происходит в момент вызова HashMap.get(key) по ключу, который есть в таблице?	- ключ равен null: 1 - выполняется единственный метод getForNullKey(). - любой ключ отличный от null: 4 - вычисление хэш-кода ключа; определение номера корзины; поиск значения; возврат значения.
Сколько создается новых объектов, когда вы добавляете новый элемент в HashMap?	Один новый объект статического вложенного класса Entry<K,V>.
Как и когда происходит увеличение количества корзин в HashMap?	Помимо capacity у HashMap есть еще поле loadFactor, на основании которого, вычисляется предельное количество занятых корзин capacity * loadFactor. По умолчанию loadFactor = 0.75. По достижению предельного значения, число корзин увеличивается в 2 раза и для всех хранимых элементов вычисляется новое «местоположение» с учетом нового числа корзин.
Объясните смысл параметров в конструкторе HashMap(int initialCapacity, float loadFactor).	- initialCapacity - исходный размер HashMap, количество корзин в хэш-таблице в момент её создания. - loadFactor - коэффициент заполнения HashMap, при превышении которого происходит увеличение количества корзин и автоматическое перехэширование. Равен отношению числа уже хранимых элементов в таблице к её размеру.
Будет ли работать HashMap, если все добавляемые ключи будут иметь одинаковый hashCode()?	Да, будет, но в этом случае HashMap вырождается в связный список и теряет свои преимущества.
Как перебрать все ключи Map?	Использовать метод keySet(), который возвращает множество Set<K> ключей.
Как перебрать все значения Map?	Использовать метод values(), который возвращает коллекцию Collection<V> значений.
Как перебрать все пары «ключ-значение» в Map?	Использовать метод entrySet(), который возвращает множество Set<Map.Entry<K, V> пар «ключ-значение».
В чем отличия TreeSet и HashSet?	Начнем с того, что Set это множество (так же называют «набором»). Set не допускает хранение двух одинаковых элементов. Формально говоря, термин «множество» и так обозначает совокупность различных элементов, очень важно, что именно различных элементов, так как это главное свойство Set. С учетом такого определения, пояснение про хранение одинаковых элементом не требуется, но в обиходе, понятие «множество» потеряло свой строгий смысл касательно уникальности элементов, входящих в него, поэтому все же уточняйте отдельно данное свойство множества.  TreeSet обеспечивает упорядоченно хранение элементов в виде красно-черного дерева. Сложность выполнения основных операций не хуже O(log(N)) (Логарифмическое время). HashSet использует для хранения элементов такой же подход, что и HashMap, за тем отличием, что в HashSet в качестве ключа и значения выступает сам элемент, кроме того, HashSet не поддерживает упорядоченное хранение элементов и обеспечивает временную сложность выполнения операций аналогично HashMap.
Что будет, если добавлять элементы в TreeSet по возрастанию?	В основе TreeSet лежит красно-черное дерево, которое умеет само себя балансировать. В итоге, TreeSet все равно в каком порядке вы добавляете в него элементы, преимущества этой структуры данных будут сохраняться.
Чем LinkedHashSet отличается от HashSet?	LinkedHashSet отличается от HashSet только тем, что в его основе лежит LinkedHashMap вместо HashMap. Благодаря этому порядок элементов при обходе коллекции является идентичным порядку добавления элементов (insertion-order). При добавлении элемента, который уже присутствует в LinkedHashSet (т.е. с одинаковым ключом), порядок обхода элементов не изменяется.
Для Enum есть специальный класс java.util.EnumSet. Зачем? Чем авторов не устраивал HashSet или TreeSet?	EnumSet - это реализация интерфейса Set для использования с перечислениями (Enum). В структуре данных хранятся объекты только одного типа Enum, указываемого при создании. Для хранения значений EnumSet использует массив битов (bit vector), - это позволяет получить высокую компактность и эффективность. Проход по EnumSet осуществляется согласно порядку объявления элементов перечисления. Все основные операции выполняются за O(1) и обычно (но негарантированно) быстрей аналогов из HashSet, а пакетные операции (bulk operations), такие как containsAll() и retainAll() выполняются даже горазда быстрей. Помимо всего EnumSet предоставляет множество статических методов инициализации для упрощенного и удобного создания экземпляров.
Каким образом можно получить синхронизированные объекты стандартных коллекций?	С помощью статических методов synchronizedMap() и synchronizedList() класса Collections. Данные методы возвращают синхронизированный декоратор переданной коллекции. При этом все равно в случае обхода по коллекции требуется ручная синхронизация. Map m = Collections.synchronizedMap(new HashMap()); List l = Collections.synchronizedList(new ArrayList()); Начиная с Java 6 JCF был расширен специальными коллекциями, поддерживающими многопоточный доступ, такими как CopyOnWriteArrayList и ConcurrentHashMap.
Как получить коллекцию только для чтения?	При помощи: Collections.unmodifiableList(list); Collections.unmodifiableSet(set); Collections.unmodifiableMap(map). Эти методы принимают коллекцию в качестве параметра, и возвращают коллекцию только для чтения с теми же элементами внутри.
ConcurrentModificationException.	ConcurrentModificationException` выбрасывается, когда коллекция изменяется во время итерации. Это исключение обычно возникает, когда несколько потоков одновременно изменяют коллекцию без надлежащей синхронизации. Чтобы избежать этого исключения, рекомендуется использовать параллельные коллекции или правильно синхронизировать доступ к коллекции, если в ней участвует несколько потоков.
Приведите пример, когда какая-либо коллекция выбрасывает UnsupportedOperationException.	Исключение UnsupportedOperationException выбрасывается, когда операция не поддерживается или не реализуется объектом или коллекцией. Это исключение обычно возникает при попытке выполнить операцию, которая не поддерживается текущей реализацией, или при работе с неизменяемыми коллекциями, не допускающими модификации. Чтобы избежать этого исключения, убедитесь, что вы используете методы и операции, которые поддерживаются объектом или коллекцией, с которой вы работаете.
Как, используя LinkedHashMap, сделать кэш c «invalidation policy»?	Необходимо использовать LRU-алгоритм (Least Recently Used algorithm) и LinkedHashMap с access-order. В этом случае при обращении к элементу он будет перемещаться в конец списка, а наименее используемые элементы будут постепенно группироваться в начале списка. Так же в стандартной реализации LinkedHashMap есть метод removeEldestEntries(), который возвращает true, если текущий объект LinkedHashMap должен удалить наименее используемый элемент из коллекции при использовании методов put() и putAll().  public class LRUCache<K, V> extends LinkedHashMap<K, V> {  private static final int MAX_ENTRIES = 10;  public LRUCache(int initialCapacity) {  super(initialCapacity, 0.85f, true);  }  @Override  protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {  return size() > MAX_ENTRIES;  } }  Стоит заметить, что LinkedHashMap не позволяет полностью реализовать LRU-алгоритм, поскольку при вставке уже имеющегося в коллекции элемента порядок итерации по элементам не меняется.
Как одной строчкой скопировать элементы любой collection в массив?	Object[] array = collection.toArray();
Как одним вызовом из List получить List со всеми элементами, кроме первых и последних 3-х?	List<Integer> subList = list.subList(3, list.size() - 3);
Как одной строчкой преобразовать HashSet в ArrayList?	ArrayList<Integer> list = new ArrayList<>(new HashSet<>());
Как одной строчкой преобразовать ArrayList в HashSet?	HashSet<Integer> set = new HashSet<>(new ArrayList<>());
Сделайте HashSet из ключей HashMap.	HashSet<Object> set = new HashSet<>(map.keySet());
Сделайте HashMap из HashSet<Map.Entry<K, V>>.	HashMap<K, V> map = new HashMap<>(set.size());  for (Map.Entry<K, V> entry : set) {  map.put(entry.getKey(), entry.getValue());  }
Чем отличается ArrayList от HashSet?	Если ArrayList и LinkedList можно было сравнить по операциям — где кто лучше — то с ArrayList с HashSet сравнить уже не так просто, ведь это совершенно разные коллекции. Можно сравнить одно сладкое блюдо с другим, но с мясным уже получится — больно уж они разные. Тем не менее, я попробую привести их некоторые различия:  ArrayList реализует интерфейс List, в то время как HashSet реализует интерфейс Set;  В ArrayList возможен доступ по индексу элемента: операция get имеет алгоритмическую сложность O(1), а в HashSet необходимый элемент можно получить лишь путём перебора, а это у нас от O(1) до O(n);  ArrayList допускает присутствие дубликатов элементов. В HashSet все элементы уникальны: добавить в HashSet элемент, аналог которого уже присутствует в коллекции, не получится (проверка дубликатов ведется по hashcode, отсюда и название этой коллекции);  ArrayList реализован с помощью внутреннего массива, а HashSet реализован с помощью внутренней HashMap;  ArrayList поддерживает порядок вставки элементов, в то время как HashSet это неупорядоченное множество и не поддерживает порядок элементов;  ArrayList допускает любое количество пустых значений (null), в HashSet можно вставить лишь одно значение null (как-никак, уникальность элементов).
Зачем в Java такое разнообразие имплементации динамического массива?	Ну, это скорее философский вопрос. Ну а зачем придумывают такое количество новых разнообразных технологий? Для удобства. Собственно, так же и с большим количеством имплементаций динамического массива. Ни одну из них нельзя назвать лучшей или идеальной. У каждой есть преимущество в какой-то конкретной ситуации. И наша задача — знать их различия, их сильные/слабые стороны: чтобы суметь в нужной ситуации использовать самую подходящую из них.
Как отсортировать коллекцию элементов?	Первое, что нужно сказать, — класс элемента коллекции должен имплементировать интерфейс Comparable и его метод compareTo. Или же нужен класс, который имплементирует Comaprator с его методом comparator.  Оба способа указывают, каким образом нужно сравнивать объекты данного типа. При сортировке это критически важно, ведь нужно понимать принцип, по которому элементы можно сравнить. В основном используется способ через имплементацию Comparable, реализуемый непосредственно в классе, который вы хотите сортировать. В то же время применение Comparator-а более редко. Скажем, вы используете класс с какой-то библиотеки, у которого нет реализации Comparable, но вам как-то нужно будет его сортировать. Не имея возможности изменить код данного класса (кроме как расширить его), вы можете написать реализацию Comparator-а, в котором укажете, по какому принципу нужно сравнивать объекты данного класса. И еще один пример. Допустим, вам нужны разные принципы сортировки объектов одного и того же типа, поэтому вы пишете несколько Comparator-ов которые используете в разных ситуациях. Как правило, многие классы из коробки уже реализуют интерфейс Comparable — тот же String. Собственно, при их использовании вам не нужно париться, как их сравнить. Вы просто берете и используете их.   Первый и самый очевидный способ — использовать коллекцию типа TreeSet или TreeMap, которые хранят элементы в ужеотсортированном порядке, согласно компаратору класса элементов. Не забывайте, что TreeMap сортирует ключи, но не значения. Если вы используете имплементацию Comparator вместо Comparable, вам нужно будет передать его объект в конструктор коллекции при создании:  TreeSet treeSet = new TreeSet(customComparator);  А что если у вас коллекция другого типа? Как её отсортировать?  В этом случае подходит второй способ утилитного класса Collections — метод sort(). Он статический, поэтому всё, что вам нужно — имя класса и метод, в который передается необходимый список. Например:  Collections.sort(someList);  Если вы используете не Comparable, а реализацию Comparator, его нужно передать вторым параметром:  Collections.sort(someList, customComparator);  В итоге внутренний порядок элементов переданного списка изменится: он будет отсортирован согласно компаратору элементов. Отмечу, что передаваемый список элементов должен быть мутабельным, т.е. изменяемым, иначе метод не сработает и будет выброшено UnsupportedOperationException.  В качестве третьего способа можно использовать Stream операцию sort, которая сортирует элементы коллекции, если используется имплементация Comparable:  someList = someList.stream().sorted().collect(Collectors.toList());  если Comparator:  someList = someList.stream().sorted(customComparator).collect(Collectors.toList());  Подробнее о Stream можно почитать в этой статье.   Четвертый способ — ручная реализация сортировки, например, сортировки пузырьком или сортировки слиянием.
Какое внутреннее строение LinkedList?	Если ArrayList содержит элементы во внутреннем массиве, то LinkedList — в виде двусвязного списка. Это значит, что каждый элемент содержит ссылку на предыдущий элемент (previous) и на следующий (next). У первого элемента нет ссылки на предыдущий (он ведь первый), при этом он считается главой списка, и в LinkedList есть ссылка непосредственно на него. У последнего элемента, собственно, нет следующего элемента, он является хвостом списка, и поэтому прямая ссылка на него есть в самом LinkedList. Поэтому логарифмическая сложность при доступе к главе или хвосту списка — O(1). В ArrayList при увеличении списка увеличивался внутренний массив, тут же все происходит проще — при добавлении элемента просто меняются пару ссылок. Давайте рассмотрим некоторые наиболее используемые методы LinkedlList-а:  1. add(<Elelement>) — происходит добавление в конце списка, т.е. после последнего элемента (5) добавится ссылка на новый элемент как next. Новому элементу добавится ссылка на последний (5) как previous элемент. Логарифмическая сложность такой операции будет O(1), так как необходима всего лишь ссылка на последний элемент, а как вы помните, на хвост есть прямая ссылка с LinkedList и логарифмическая сложность доступа к нему минимальная. 2. add(<Index>,<Elelement>) — добавление элемента по индексу. При добавлении элемента, например, в середину списка, сперва перебираются элементы с головы и хвоста (с обеих сторон), пока не будет найдено нужное место. Если мы хотим вставить элемент между третьим и четвертым (на рисунке выше), то при поиске нужного места ссылка next третьего элемента будет уже указывать на новый. У нового же ссылка previous будет указывать на третий. Соответственно, ссылка четвертого элемента — previous — будет указывать уже на новый элемент, а у нового элемента ссылка next будет указывать на четвертый элемент: Логарифмическая сложность данного метода будет зависеть от индекса, задаваемого новому элементу:  если он будет близок к голове или хвосту, то будет приближаться к O(1), поскольку перебирать элементы фактически будет не нужно; если же близко к середине, то O(N/2) — будет происходить переборка элементов с головы и хвоста одновременно, пока не будет найден нужный элемент. 3. set(<Index>,<Elelement>) — записывает элемент в указанную позицию в списке. Логарифмическая сложность данной операции будет колебаться от O(1) до O(N/2), опять же в зависимости от того, насколько близок элемент к голове, хвосту или середине. 4. remove(<index>) — удаляет элемент из списка, по сути делая так, чтобы элемент, который находится перед удаляемым (previous), ссылался на элемент, который идёт после удаляемого (next). И наоборот: чтобы элемент, который идет после удаляемого, ссылался на тот, который идёт перед удаляемым: Получился процесс, обратный добавлению по индексу (add(<Index>,<Elelement>)).
Каково внутреннее строение ArrayList?	ArrayList это аналог массива, но со способностью динамически расширяться. Что это значит? Дело в том, что ArrayList работает на основе обычного массива, а именно он хранит элементы во внутреннем массиве (его размер по умолчанию — 10 ячеек). Когда внутренний массив заполняется, создается новый массив, размер которого определяется по формуле:  <размерТекущегоМассива> * 3 / 2 + 1  То есть если размер нашего массива 10, размер нового будет: 10 * 3 / 2 + 1 = 16. Далее в него копируются все значения из первого (старого) массива c помощью нативного метода System.arraycopy(), и первый массив удаляется. Собственно, так и реализуется динамическая расширяемость ArrayList. Рассмотрим самые используемые методы ArrayList:   1. add(<Elelement>) — добавляет элемент в конец массива (в последнюю пустую ячейку), при этом сперва проверяется, есть ли место в данном массиве. Если его нет, создается новый массив, в который копируются элементы. Логарифмическая сложность данной операции — O(1). Есть аналогичный метод — add(<Index>,<Elelement>). Он добавляет элемент не в конец списка (массива), а в определенную ячейку с индексом, который пришёл в качестве аргумента. В таком случае логарифмическая сложность будет отличаться в зависимости от места добавления: если это было примерно начало списка, логарифмическая сложность будет близка к O(N), ведь придется все элементы, расположенные справа от нового, двигать на одну ячейку вправо; если элемент вставляется в середину — O(N/2) т.к. нам нужно сдвинуть на одну ячейку вправо только половину элементов списка. То есть логарифмическая сложность данного метода колеблется от O(N) до O(1) в зависимости от места вставки элемента.  2. set(<Index>,<Elelement>) — записывает элемент в указанную позицию в списке. Если в той позиции уже присутствует элемент, перезаписывает его. Логарифмическая сложность данной операции — O(1), ведь там никаких сдвигов нет: только поиск по индексу в массиве, что, как мы помним, имеет сложность O(1), и запись элемента.   3. remove(<index>) — удаление элемента по его индексу во внутреннем массиве. При удалении элемента, который расположен не в конце списка, необходимо сдвинуть все элементы справа от него на одну ячейку влево, чтобы закрыть образовавшуюся брешь после удаления элемента. Поэтому логарифмическая сложность будет такой же, как и у add(<Index>,<Elelement>), если элемент был в середине — O(N/2), — ведь нужно половину элементов сдвинуть на один влево. Соответственно, если он был в начале —- O(N). Ну и если в конце — O(1), ведь и двигать ничего не нужно.
HashMap one optimization?	Когда TREEIFY_THRESHOLD = 8 (Количество объектов в односвязном списке) становится слишком большой (в настоящее время: TREEIFY_THRESHOLD = 8 ), HashMap динамически заменяет ее специальной реализацией древовидной карты. Таким образом, вместо пессимистического O (n) мы получаем намного лучше O (logn). Как это работает? Что ж, ранее записи с конфликтующими ключами просто добавлялись в связанный список, который позже нужно было просмотреть. Теперь HashMap преобразует список в двоичное дерево, используя хеш-код в качестве переменной ветвления. Если два хэша различны, но попали в одно и то же ведро, один считается больше и идет вправо. Если хэши равны (как в нашем случае), HashMap надеется, что ключи Comparable , чтобы он мог установить некоторый порядок. Это не требование ключей HashMap , но, видимо, хорошая практика. Если ключи несопоставимы, не ожидайте каких-либо улучшений производительности в случае сильных коллизий хешей.
Расскажите про реализации деревьев.	TreeMap - Упорядоченная по ключам. Основана на красно-черных деревьях. Может использовать компаратов в конструкторе. Красно-черные деревья это самобалансирующееся дерево которое гарантирует логарифмический рост высоты дерева от числа узлов. TreeSet - основан на сбалансированном двоичном дереве, в результате элементы упорядочены по возрастанию hashCode()'ов. Можно управлять порядком при помощи компаратора.
Что такое красно-черное дерево	Красно-черные деревья относятся к сбалансированным бинарным деревьям поиска. Как бинарное дерево, красно-черное обладает свойствами:  Оба поддерева являются бинарными деревьями поиска.  Для каждого узла с ключом K выполняется критерий упорядочения: ключи всех левых потомков <= K < ключи всех правых потомков  (в других определениях дубликаты должны располагаться с правой стороны либо вообще отсутствовать). Это неравенство должно быть истинным для всех потомков узла, а не только его дочерних узлов.  Свойства красно-черных деревьев:  Каждый узел окрашен либо в красный, либо в черный цвет (в структуре данных узла появляется дополнительное поле - бит цвета).  Корень окрашен в черный цвет.  Листья(так называемые NULL-узлы) окрашены в черный цвет.  Каждый красный узел должен иметь два черных дочерних узла. Нужно отметить, что у черного узла могут быть черные дочерние узлы. Красные узлы в качестве дочерних могут иметь только черные.  Пути от узла к его листьям должны содержать одинаковое количество черных узлов(это черная высота).
Удаление элемента из дерева	Если у удаляемого элемента нет потомков или один потомок, то удаленить просто. Если у удаляемого элемента есть два потомка, то удаляемый узел надо заменить на приемника. Т.к. используется сложный алгоритм для поиска приемника, то часто вместо удаления используют флаг isDeleted. В остальных методах проверяют значение этого флага.
Какие существуют алгоритмы обхода дерева	Какие существуют алгоритмы обхода дерева В зависимости от траекторий выделяют два типа обхода: горизонтальный (в ширину) вертикальный (в глубину).  Горизонтальный обход подразумевает обход дерева по уровням (level-ordered) - вначале обрабатываются все узлы текущего уровня, после чего осуществляется переход на нижний уровень.  static void contLevelOrder(Node top){  Queue<Node> queue=new LinkedList<> (); do{  top.treatment(); if (top.left!=null) queue.add(top.left); if (top.right!=null) queue.add(top.right);  if (!queue.isEmpty()) top=queue.poll();  }while (!queue.isEmpty());  }  Вертикальный бывает 3 видов:  прямой (preorder) Посещение узла. Вызов самого себя для обхода левого поддерева узла. Вызов самого себя для обхода правого поддерева узла  симметричный (inorder).  При симметричном обходе двоичного дерева все узлы перебираются в порядке возрастания ключей. Простейший способ обхода основан на использовании рекурсии. Метод должен выполнить только три операции:  Вызов самого себя для обхода левого поддерева узла. Посещение узла. Вызов самого себя для обхода правого поддерева узла.  private void inOrder(node localRoot) { if(localRoot != null) { inOrder(localRoot.leftChild); console.log(node.value);  inOrder(localRoot.rightChild);  }  } обратный (postorder) Вызов самого себя для обхода левого поддерева узла. Вызов самого себя для обхода правого поддерева узла. Посещение узла.
Что такое Spring Boot?	pring Boot - это подпроект в рамках организации с открытым исходным кодом Spring. Это универсальное решение для компонентов Spring. Оно в основном упрощает использование Spring, сохраняет тяжелую конфигурацию и предоставляет различные стартовые средства, чтобы разработчики могли быстро приступить к работе. В чем преимущества Spring Boot? Spring Boot имеет следующие преимущества:  Простота использования, повышение эффективности разработки и обеспечение более быстрого и обширного начального опыта разработки Spring.  Из коробки, вдали от громоздкой конфигурации.  Предоставляет ряд некоммерческих функций, общих для крупномасштабных проектов, таких как встроенный сервер, управление безопасностью, мониторинг рабочих данных, проверка рабочего состояния, внешняя настройка и т. Д.  Нет генерации кода и конфигурации XML.  Избегайте большого количества операций импорта Maven и различных конфликтов версий.
Какова основная аннотация Spring Boot? Из каких аннотаций в основном состоят?	Аннотации к классу запуска - @SpringBootApplication, которая также является основной аннотацией Spring Boot. Основная комбинация включает следующие три аннотации: Аннотации к классу запуска - @SpringBootApplication, которая также является основной аннотацией Spring Boot. Основная комбинация включает следующие три аннотации: @SpringBootConfiguration: объединяет аннотации @Configuration для реализации функции файлов конфигурации. @EnableAutoConfiguration: включите функцию автоматической настройки или вы можете отключить параметр автоматической настройки, например отключение функции автоматической настройки источника данных: @SpringBootApplication (исключить {DataSourceAutoConfiguration.class}) @ComponentScan: сканирование компонентов Spring.  Вот другие основные аннотации: @EnableConfigurationProperties — позволяет использовать бины с аннотацией @ConfigurationProperties @ConfigurationProperties — позволяет связывать проперти из файлов с бинами @WebMvcTest — используется для тестов Spring MVC @SpringBootTest — используется, когда нужны функции Spring Boot в тестах @DataJpaTest — используется для теста компонентов JPA
Как он работает? Как он понимает что и как нужно сконфигурировать?	Он предполагает что вам надо, основываясь на зависимостях в classpath. "Соглашение над конфигурацией" — он автоконфигурирует Spring специально подобранными настройками, которые потом можно переопределить. Для этого есть несколько аннотаций, @ConditionalOnClass, @ConditionalOnBean, @ConditionalOnMissingBean и @ConditionalOnMissingClass, которые позволяют применять условия к @Configuration-классам и @Bean-методам в этих классах. Например: Бин будет создан только если определенная зависимость есть в classpath. Используйте @ConditionalOnClass, установив туда имя класса из classpath. Бин будет создан только если в контейнере нет бина такого типа или с таким именем. Используйте @ConditionalOnMissingBean, установив туда имя или тип бина для проверки.
Что влияет на настройку Spring Boot?	Существует список аннотаций-условий, каждая из которых используется для управления созданием бинов. Вот список таких аннотаций(на самом деле их больше): @ConditionalOnClass Пристутствие класса в classpath @ConditionalOnMissingClass Отсутствие класса в classpath @ConditionalOnBean Присутствие бина или его типа(класс бина) @ConditionalOnMissingBean Отсутствие бина или его типа @ConditionalOnProperty Присутствие Spring-свойства @ConditionalOnResource Присутствие файла-ресурса @ConditionalOnWebApplication Если это веб-приложение, будет использоваться WebApplicationContext @ConditionalOnNotWebApplicationЕсли это не веб-приложение
Что такое JavaConfig?	Spring JavaConfig является продуктом сообщества Spring и предоставляет чистый Java-метод для настройки контейнера Spring IoC. Так что это помогает избежать использования конфигурации XML. Преимущества использования JavaConfig: (1) Объектно-ориентированная конфигурация. Поскольку конфигурация определяется как класс в JavaConfig, пользователи могут в полной мере использовать объектно-ориентированные функции Java. Один класс конфигурации может наследовать другой, переопределять его метод @Bean и т. Д. (2) Уменьшите или исключите конфигурацию XML. Доказаны преимущества внешней конфигурации, основанной на принципе внедрения зависимостей. Однако многие разработчики не хотят переключаться между XML и Java. JavaConfig предоставляет разработчикам чистый метод Java для настройки контейнера Spring, аналогичный по концепции конфигурации XML. С технической точки зрения можно использовать только класс конфигурации JavaConfig для настройки контейнера, но на самом деле многие люди думают, что смешивание и сопоставление JavaConfig и XML является идеальным. (3) Безопасность типов и удобство рефакторинга. JavaConfig предоставляет безопасный способ настройки контейнера Spring. Благодаря поддержке универсальных шаблонов в Java 5.0 компоненты теперь можно получать по типу, а не по имени, без приведения типов или поиска на основе строк.
Делает ли Spring Boot сканирование компонентов? Где он их ищет по умолчанию?	Да, делает, если стоит аннотация @SpringBootApplication, которая содержит аннотацию @ComponentScanning. По умолчанию Spring ищет бины в том же package, что и класс с аннотацией. Это можно переопределить, указав классы(или package) в параметрах scanBasePackageClasses или scanBasePackage.
Что такое Spring Boot Starter POM? Чем он может быть полезен?	Стартеры предоставляют набор удобных дескрипторов зависимостей, которые можно включить в ваше приложение. Вы получаете один источник для spring и связанных с ним технологий без необходимости искать и копипастить дескрипторы развертывания.Например, если вы хотите начать работать с Spring JPA, всего лишь добавьте зависимость spring-boot-starter-data-jpa в ваш проект. Стартеры содержат большинство зависимостей, нужных вам для запуска проекта, работают быстро и согласованно, и поддерживают наборы транзитивных зависимостей.
Каков принцип автоматической настройки Spring Boot?	Аннотации @EnableAutoConfiguration, @Configuration, @ConditionalOnClass - это ядро ​​автоматической настройки, @EnableAutoConfiguration импортирует класс автоматической конфигурации, определенный в META-INF / spring.factories, в контейнер. Отфильтруйте допустимые классы автоконфигурации. Каждый класс автоматической конфигурации объединяет соответствующий xxxProperties.java для чтения файла конфигурации для функции автоматической настройки.
Как определяются property? Где находится дефолтный PropertySource в Spring Boot?	Spring Boot использует особый порядок PropertySource'ов для того чтобы позволить переопределять значения свойств. Вот порядок источников для получения свойств приложения: Общие настройки из директории ~/spring-boot devtools.properties Настройки из аннотации @TestPropertySource из тестов Атрибуты @SpringBootTest#properties Аргументы командной строки Свойства из SPRING_APPLICATION_JSON Параметры для инициализации ServletConfig Параметры для инициализации ServletContext JNDI-атрибуты из java:comp/env Java System Properties(System.getProperties()) Переменные ОС RandomValueProperySource Проперти для профилей, например YAML или application-{profile}.properties application.properties и YAML не из вашего jar application.properties и YAML из вашего jar @PropertySource на @Configuration-классе Проперти по умолчанию(устанавливаются через SpringApplication.setDefaultProperties()) Также добавлю, что property.yml всегда переопределяют property.properties.
Как вы понимаете последовательность загрузки конфигурации Spring Boot?	В Spring Boot есть несколько способов загрузить конфигурацию.Файл свойств; 2) файл YAML; 3) переменные системного окружения; 4) Параметры командной строки; и многое другое ......
Что такое ЯМЛ?	YAML - это удобочитаемый язык сериализации данных. Обычно используется для файлов конфигурации. По сравнению с файлами свойств, если мы хотим добавить сложные свойства в файл конфигурации, файл YAML будет более структурированным и менее запутанным. Видно, что YAML имеет иерархические данные конфигурации.
В чем преимущества конфигурации YAML?	YAML теперь можно рассматривать как очень популярный формат файла конфигурации, независимо от того, является ли он внешним или внутренним, вы можете увидеть конфигурацию YAML. Итак, каковы преимущества конфигурации YAML по сравнению с традиционной конфигурацией свойств?  Упорядоченная конфигурация, в некоторых особых случаях упорядоченная конфигурация очень важна  Поддержка массивов, элементы в массиве могут быть базовыми типами данных или объектами.  краткий  По сравнению с файлом конфигурации свойств, YAML имеет недостаток, заключающийся в том, что он не поддерживает аннотацию @PropertySource для импорта пользовательской конфигурации YAML.
Может ли Spring Boot использовать конфигурацию XML?	Spring Boot рекомендует использовать конфигурацию Java вместо конфигурации XML, но конфигурацию XML также можно использовать в Spring Boot.Конфигурация XML может быть представлена ​​с помощью аннотации @ImportResource.
Что такое файл конфигурации ядра загрузки Spring? В чем разница между bootstrap.properties и application.properties?	При простой разработке Spring Boot может быть нелегко встретить файл конфигурации bootstrap.properties, но в сочетании с Spring Cloud эта конфигурация будет часто встречаться, особенно когда вам нужно загрузить некоторые файлы удаленной конфигурации. Два файла конфигурации ядра загрузки Spring: bootstrap (. yml или. properties): boostrap загружается родительским ApplicationContext, который загружается до приложения. Конфигурация вступает в силу на этапе загрузки контекста приложения. Вообще говоря, мы будем использовать его в Spring Cloud Config или Nacos. И атрибуты в Boostrap не могут быть перезаписаны; application (.yml или. properties): загружается ApplicatonContext для автоматической настройки проектов весенней загрузки.
Что такое Spring Profiles?	Spring Profiles позволяет пользователям регистрировать bean-компоненты на основе файлов конфигурации (dev, test, prod и т. Д.). Следовательно, когда приложение работает в стадии разработки, могут быть загружены только определенные bean-компоненты, в то время как в PRODUCTION могут быть загружены некоторые другие bean-компоненты. Предположим, наше требование состоит в том, что документ Swagger применим только к среде контроля качества, а все остальные документы отключены. Это можно сделать с помощью файлов конфигурации. Spring Boot позволяет очень легко использовать файлы конфигурации.
Как запускать приложения Spring Boot на пользовательских портах?	Чтобы запустить приложение Spring Boot на настраиваемом порту, вы можете указать порт в application.properties. server.port = 8090
Как реализовать безопасность приложения Spring Boot?	Чтобы обеспечить безопасность Spring Boot, мы используем зависимость spring-boot-starter-security и должны добавить конфигурацию безопасности. Для этого требуется очень мало кода. Класс конфигурации должен будет расширить WebSecurityConfigurerAdapter и переопределить его методы.
Сравните преимущества и недостатки Spring Security и Shiro?	Поскольку Spring Boot официально предоставляет большое количество очень удобных готовых стартеров, включая Starter Spring Security, он упрощает использование Spring Security в Spring Boot, и даже нужно только добавить зависимость для защиты всех интерфейсов. Поэтому, если это проект Spring Boot, обычно выбирается Spring Security. Конечно, это всего лишь предложенная комбинация, с чисто технической точки зрения, какой бы ни была комбинация, проблем нет. По сравнению с Spring Security, Shiro имеет следующие характеристики:  Spring Security - это тяжелая структура управления безопасностью; Shiro - легкая структура управления безопасностью.  Spring Security имеет сложные концепции и громоздкую конфигурацию; у Широ простые концепции и простая конфигурация.  Spring Security мощен; Широ прост
Как решить междоменные проблемы в Spring Boot?	Междоменный доступ может быть решен через JSONP в интерфейсе пользователя, но JSONP может отправлять только запросы GET и не может отправлять запросы других типов. В приложениях в стиле RESTful это очень безвкусно, поэтому мы рекомендуем передать (CORS, Cross-origin совместное использование ресурсов) для решения междоменных проблем. Это решение не является уникальным для Spring Boot. В традиционной среде SSM CORS можно использовать для решения междоменных проблем, но до того, как мы настроили CORS в XML-файле, теперь мы можем реализовать интерфейс WebMvcConfigurer, а затем переопределить метод addCorsMappings Решайте междоменные проблемы. @Configuration public class CorsConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) {  registry.addMapping("/**")  .allowedOrigins("*")  .allowCredentials(true)  .allowedMethods("GET", "POST", "PUT", "DELETE", "OPTIONS")  .maxAge(3600);  } } Передняя и задняя части проекта развертываются отдельно, поэтому необходимо решить междоменные проблемы. Мы используем файлы cookie для хранения информации для входа в систему и выполняем контроль разрешений в перехватчике spring. Если разрешения не совпадают, мы напрямую возвращаем пользователю фиксированный результат json. После входа пользователя в систему он используется нормально; когда пользователь выходит из системы или срок действия токена истекает из-за проблемы перехватчика и междоменной последовательности, возникает междоменное явление. Мы знаем, что http-запрос должен сначала пройти через фильтр, а затем быть обработан перехватчиком после того, как он достигнет сервлета.Если мы поместим cors в фильтр, он может быть выполнен до перехватчика разрешений.  @Configuration public class CorsConfig {      @Bean  public CorsFilter corsFilter() {  CorsConfiguration corsConfiguration = new CorsConfiguration();  corsConfiguration.addAllowedOrigin("*");  corsConfiguration.addAllowedHeader("*");  corsConfiguration.addAllowedMethod("*");  corsConfiguration.setAllowCredentials(true);  UrlBasedCorsConfigurationSource urlBasedCorsConfigurationSource = new UrlBasedCorsConfigurationSource();  urlBasedCorsConfigurationSource.registerCorsConfiguration("/**", corsConfiguration);  return new CorsFilter(urlBasedCorsConfigurationSource);  }     }
Что такое CSRF-атака?	CSRF означает подделку межсайтовых запросов. Это атака, которая заставляет конечного пользователя выполнять нежелательные действия в веб-приложении, прошедшем проверку подлинности. Атаки CSRF нацелены на запросы на изменение состояния, а не на кражу данных, поскольку злоумышленники не могут просматривать ответы на поддельные запросы.
Что такое монитор в Spring Boot?	Привод пружинного чехла - одна из важных функций в каркасе пружинного чехла. Монитор загрузки Spring помогает вам получить доступ к текущему состоянию работающего приложения в производственной среде. Некоторые индикаторы необходимо проверять и контролировать в производственной среде. Даже некоторые внешние приложения могут использовать эти службы для отправки предупреждающих сообщений соответствующему персоналу. Модуль монитора предоставляет набор конечных точек REST, к которым можно получить прямой доступ как URL-адреса HTTP для проверки статуса.
Как отключить безопасность конечных точек Actuator в Spring Boot?	По умолчанию все конфиденциальные конечные точки HTTP защищены, и только пользователи с ролью ACTUATOR могут получить к ним доступ. Безопасность реализуется с помощью стандартного метода HttpServletRequest.isUserInRole. Мы можем использовать для отключения безопасности. Отключать безопасность рекомендуется только в том случае, если доступ к конечной точке привода осуществляется через брандмауэр.
Как мы отслеживаем все микроконтроллеры Spring Bootслужба?	Spring Boot предоставляет конечные точки монитора для отслеживания показателей каждой микросервиса. Эти конечные точки полезны для получения информации о приложениях (например, о том, запущены ли они) и о том, нормально ли работают их компоненты (например, базы данных и т. Д.). Однако одним из основных недостатков или трудностей использования монитора является то, что мы должны открывать точки знаний приложения отдельно, чтобы понять его статус или работоспособность. Представьте себе микросервис, в котором задействовано 50 приложений, и администратору придется задействовать терминалы выполнения всех 50 приложений. Чтобы помочь нам разобраться в этой ситуации, мы будем использовать проект с открытым исходным кодом, расположенный по адресу. Он построен на Spring Boot Actuator, который предоставляет веб-интерфейс, который позволяет нам визуализировать показатели нескольких приложений.
Что такое WebSockets?	WebSocket - это протокол связи с компьютером, который обеспечивает полнодуплексный канал связи через одно TCP-соединение. 1. WebSocket - это двунаправленный клиент или сервер WebSocket для инициирования отправки сообщений. 2. WebSocket является полнодуплексным, взаимодействие клиента и сервера не зависит друг от друга. 3. Одиночное TCP-соединение - начальное соединение использует HTTP, а затем это соединение обновляется до соединения на основе сокетов. Затем это единственное соединение используется для всех будущих коммуникаций. 4. Легкость - по сравнению с http, обмен данными сообщениями через WebSocket намного легче.
Что такое данные Spring?	Spring Data - это подпроект Spring. Используется для упрощения доступа к базе данных, поддерживает NoSQL и реляционное хранилище данных. Основная цель - сделать доступ к базе данных удобным и быстрым. Spring Data имеет следующие характеристики: Проект SpringData поддерживает хранилище NoSQL: 1 MongoDB (база данных документов) 2 Neo4j (база данных графиков) 3 Redis (хранилище ключей / значений) 4 Hbase (база данных семейства столбцов) Технологии реляционного хранения данных, поддерживаемые проектом SpringData: 1 JDBC 2 JPA Spring Data Jpa стремится сократить объем разработки уровня доступа к данным (DAO). Единственное, что нужно сделать разработчикам, - это объявить интерфейс уровня сохраняемости, а Spring Data JPA сделает все остальное за вас! Spring Data JPA определяет, какую логику должен реализовать метод, в соответствии с именем стандартного метода в соответствии с именем стандарта.
Что такое Spring Batch?	Spring Boot Batch предоставляет функции многократного использования, которые очень важны при обработке большого количества записей, включая журнал / трассировку, управление транзакциями, статистику обработки заданий, перезапуск задания, пропуск и управление ресурсами. Он также предоставляет более продвинутые технические услуги и функции.С помощью технологии оптимизации и разделения можно реализовать чрезвычайно высокие пакетные и высокопроизводительные задания пакетной обработки. Простые и сложные задания пакетной обработки могут использовать платформу для обработки важных и больших объемов информации с высокой степенью масштабируемости.
Что такое шаблон FreeMarker?	FreeMarker - это шаблонизатор на основе Java, изначально ориентированный на использование программной архитектуры MVC для создания динамических веб-страниц. Основным преимуществом использования Freemarker является полное разделение уровня представления и бизнес-уровня. Программисты могут обрабатывать код приложения, а дизайнеры могут заниматься дизайном HTML-страниц. Наконец, используйте freemarker, чтобы объединить их, чтобы получить окончательную страницу вывода.
Как интегрировать Spring Boot и ActiveMQ?	Для интеграции Spring Boot и ActiveMQ мы используем зависимости. Это требует очень небольшой настройки и никакого шаблонного кода.
Что такое Apache Kafka?	Apache Kafka - это распределенная система обмена сообщениями "публикация-подписка". Это масштабируемая, отказоустойчивая система обмена сообщениями "публикация-подписка", которая позволяет нам создавать распределенные приложения. Это проект верхнего уровня Apache. Kafka подходит для использования сообщений офлайн и онлайн.
Что такое Swagger? Вы реализовали это с помощью Spring Boot?	Swagger широко используется для визуализации API-интерфейсов с использованием пользовательского интерфейса Swagger для предоставления онлайн-песочниц для интерфейсных разработчиков. Swagger - это инструмент для создания визуальных представлений RESTful Web-сервисов, спецификации и полной реализации инфраструктуры. Он позволяет обновлять документы с той же скоростью, что и сервер. При правильном определении с помощью Swagger потребители могут использовать минимум логики реализации для понимания удаленных служб и взаимодействия с ними. Поэтому Swagger исключает догадки при вызове сервисов.
Передняя и задняя части разделены, как поддерживать документы интерфейса?	Front-end и back-end разработка становится все более популярной. В большинстве случаев мы используем Spring Boot для выполнения front-end и back-end разработки. Должны быть документы интерфейса для разделения front-end и back-end. Глупый способ - использовать word или md для поддержки документов интерфейса, но эффективность слишком мала.Когда интерфейс меняется, документы в руках каждого должны измениться. В Spring Boot обычным решением этой проблемы является Swagger. Используя Swagger, мы можем быстро создать веб-сайт документации интерфейса. После изменения интерфейса документация будет автоматически обновляться. Все инженеры-разработчики могут получить доступ к этому онлайн-веб-сайту, чтобы получить последнюю версию Документация по интерфейсу очень удобна.
Как перезагрузить изменения в Spring Boot без перезапуска сервера? Как выполнить горячее развертывание проекта Spring Boot?	Этого можно добиться с помощью инструмента DEV. С помощью этой зависимости вы можете сохранить любые изменения, и встроенный tomcat перезапустится. Spring Boot имеет модуль инструментов разработки (DevTools), который помогает повысить продуктивность разработчиков. Одна из основных проблем, с которыми сталкиваются разработчики Java, - это автоматическое развертывание изменений файлов на сервере и автоматический перезапуск сервера. Разработчики могут перезагрузить изменения в Spring Boot без перезапуска сервера. Это избавит от необходимости каждый раз вручную развертывать изменения. Spring Boot не имел этой функции, когда выпустил свою первую версию. Это функция, которая больше всего нужна разработчикам. Модуль DevTools полностью удовлетворяет потребности разработчиков. Этот модуль будет отключен в производственной среде. Он также предоставляет консоль базы данных H2 для лучшего тестирования приложений.
Какие начальные зависимости maven вы использовали?	Используются некоторые из следующих зависимостей spring-boot-starter-activemq spring-boot-starter-security Это помогает уменьшить количество зависимостей и уменьшить конфликты версий.
Что такое стартер в Spring Boot?Это?	Прежде всего, этот Starter не является новой технической точкой и в основном реализован на основе существующих функций Spring. Прежде всего, он предоставляет автоматизированный класс конфигурации, обычно называемый XXXAutoConfiguration. В этом классе конфигурации условные аннотации используются для определения того, вступает ли конфигурация в силу (условные аннотации присущи Spring), а затем он также предоставляет серию конфигураций по умолчанию. , Разработчикам также разрешено настраивать соответствующую конфигурацию в соответствии с реальной ситуацией, а затем вводить эти атрибуты конфигурации с помощью безопасного внедрения атрибутов. Вновь введенные атрибуты заменят атрибуты по умолчанию. Из-за этого многие сторонние фреймворки можно использовать напрямую, вводя зависимости. Конечно, разработчики также могут настроить Starter
Какая польза от spring-boot-starter-parent?	Все мы знаем, что недавно созданный проект Spring Boot по умолчанию имеет родителя. Этот родительский элемент - spring-boot-starter-parent. Spring-boot-starter-parent имеет следующие функции: 1 Скомпилированная версия Java определена как 1.8. 2 Используйте кодировку формата UTF-8. 3 Унаследованный от spring-boot-dependencies, он определяет версию зависимости. Именно потому, что эта зависимость наследуется, нам не нужно записывать номер версии при написании зависимости. 4 Конфигурация для выполнения упаковочных операций. 5 Автоматическая фильтрация ресурсов. 6 Автоматическая настройка плагинов. 7 Фильтрация ресурсов для application.properties и application.yml включает файлы конфигурации различных сред, определенных профилем, таких как application-dev.properties и application-dev.yml.
В чем разница между банкой Spring Boot и обычной банкой?	В конечном итоге jar-файл, упакованный в проект Spring Boot, является исполняемым jar-файлом. Этот jar-файл можно запустить напрямую с помощью команды java -jar xxx.jar. Этот jar-файл нельзя использовать в качестве обычного jar-файла в других проектах. Даже если это зависит, его нельзя использовать. тип. На Spring Boot jar нельзя полагаться в других проектах, главным образом потому, что его структура отличается от обычных jar-файлов. Обычный пакет jar, имя пакета находится сразу после распаковки, и наш код находится в пакете. После распаковки исполняемый jar, упакованный Spring Boot, является нашим кодом в каталоге \ BOOT-INF \ classes, поэтому он не может быть напрямую Справка. Если вам нужно обратиться к нему, вы можете добавить конфигурацию в файл pom.xml и упаковать проект Spring Boot в два jar-файла, один исполняемый файл и один ссылочный.
Как реализовать задачи синхронизации в Spring Boot?	Задачи по времени также являются обычным требованием.Поддержка задач по времени в Spring Boot в основном происходит из среды Spring. В Spring Boot есть два разных способа использования синхронизированных задач: один - использовать аннотацию @Scheduled в Spring, а другой - использовать стороннюю структуру Quartz. Способ использования @Scheduled в Spring в основном реализуется с помощью аннотации @Scheduled
Верно или ложно следующее утверждение: «Каждое приложение Spring Boot - это веб-приложение, работающее во встроенном Apache Tomcat». Обоснуйте свой ответ	Утверждение ложное. Когда дело доходит до веб-приложений, Spring Boot работает с множеством контейнеров сервлетов. По умолчанию используется Apache Tomcat , но вы также можете использовать веб-приложение с Jetty, Undertow или вообще без встроенного контейнера сервлетов. Более того, Spring Boot не привязан только к веб-приложениям, хотя такое впечатление можно получить, используя зависимость spring-boot-starter-web и, следовательно, автоконфигурацию Spring Boot для веб-сайтов. С помощью Spring Boot вы можете писать все виды сервисов, от пакетных заданий и утилит командной строки до серверных модулей обмена сообщениями и реактивных веб-приложений.
В чем разница между Spring Boot и Spring MVC? Или между Spring Boot и Spring Framework? Можете ли вы использовать их вместе в одном проекте?	Spring Boot построен поверх Spring Framework. Пример: Spring Framework предлагает вам возможность читать файлы свойств .properties из различных мест, например, с помощью аннотаций @PropertySource. Он также предлагает вам возможность писать JSON REST контроллеры с помощью инфраструктуры Web MVC. Проблема в том, что вы должны указать Spring откуда читать свойства приложения и правильно настроить веб-фреймворк, например, для поддержки JSON. Spring Boot, с другой стороны, берет эти отдельные части и предварительно настраивает их для вас. Например: Он всегда автоматически ищет файлы application.properties в различных заранее определенных местах и ​​считывает их. Он всегда загружает встроенный Tomcat, поэтому вы можете сразу увидеть результаты написания ваших @RestControllers и начать писать веб-приложения. Он автоматически настраивает все для отправки / получения JSON, не беспокоясь о конкретных зависимостях Maven / Gradle. Все, путем запуска основного метода в классе Java, который аннотируется аннотацией @SpringBootApplication. Если это объяснение по-прежнему оставляет у вас вопросы, ознакомьтесь с этим обширным руководством по Spring Framework, которое более подробно освещает эту тему.
Назовите два способа создать новый проект Spring Boot с нуля? Кроме того, как узнать, какие Spring Boot стартеры нужны вашему проекту?	Вы можете создавать новые проекты Spring Boot с помощью веб-приложения Spring Initializr или Spring Boot CLI. Интересно, что Spring Initializr - это не просто веб-сайт, на котором вы можете создавать .zip файлы скелета проекта. Это также API, который можно вызывать программно. Все основные IDE (Spring Tool Suite, IntelliJ IDEA Ultimate, Netbeans и VSCode) напрямую интегрируются с ним, так что вы можете создавать новые проекты Spring Boot прямо из вашей IDE. Что касается стартеров, вам нужно прочитать документацию и иметь немного опыта. Если вы работаете с веб-приложением, вы начнете с spring-boot-starter-web, а затем добавите соответствующий стартер из документации, как только вы захотите включить определенную технологию. Через некоторое время вы получите хорошее представление о том, какие стартеры вам нужны для вашей технологии.
Почему вам не нужно указывать версии зависимостей в файле pom.xml при включении сторонних библиотек? Верно ли это для всех сторонних библиотек или только для некоторых? Как узнать, какие библиотеки поддерживает Spring Boot?	Это потому, что Spring Boot выполняет за вас некоторое управление зависимостями. На верхнем уровне стартеры Spring Boot закачивают родительский файл pom.xml (или файл build.gradle), в котором определены все зависимости и соответствующие версии, которые поддерживает конкретная версия Spring Boot - так называемый BOM (Bill Of Materials). Затем вы можете просто использовать эти предопределенные версии или переопределить номера версий в своих собственных сценариях сборки. Вы можете найти список всех поддерживаемых в настоящее время сторонних библиотек и версий в проекте spring-boot-dependencies.
Вы хотите сделать свое приложение настраиваемым, скажем, указать разное соединение с базой данных для среды разработки и рабочей среды. Какие у вас есть варианты?	По умолчанию Spring Boot извлекает свойства почти из 20 мест, от переменных среды и аргументов командной строки до файлов конфигурации (application.properties).Эти местоположения также упорядочены, так что местоположения, расположенные ниже в списке, имеют приоритет над более ранними. Вы можете, например, поместить файл application.properties по умолчанию в свой развертываемый файл .jar, тогда как ваши коллеги по эксплуатации переопределят только некоторые из них, предоставив свой собственный файл application.properties на машине развертывания. Важно понимать эти местоположения и поведение по умолчанию, чтобы повторно не реализовывать функциональность свойств Spring Boot с настраиваемым PropertySourceProvider или использовать более тяжелые параметры, такие как сервер конфигурации Spring-Cloud. Вам также необходимо убедиться, что вы понимаете концепцию нечёткой привязки свойств Spring (Relaxed properties binding), поскольку вы можете связывать свойства из этих мест со свойствами компонента конфигурации без явного совпадения имен.
Верно или неверно следующее утверждение: «Каждый проект Spring Boot должен использовать Thymeleaf в качестве механизма создания шаблонов HTML». Какие у вас есть возможности для рендеринга HTML?	Утверждение ложное. Spring Boot работает с различными механизмами шаблонов HTML, и хотя Thymeleaf является популярным выбором и полностью интегрирован со Spring, вы также можете использовать многие другие, такие как Freemarker, Velocity или даже JSP (хотя это и не строго шаблонный движок). Обычно рекомендуется выбрать вариант, который вам наиболее удобен / который используется в вашей компании по умолчанию.
Как можно реализовать доступ к реляционной базе данных с помощью Spring Boot? Какие у вас есть варианты?	Spring Boot интегрируется с множеством библиотек доступа к базам данных Java ( см. Полный список здесь ). Большинство пользователей, вероятно, будут использовать spring-boot-starter-jpa, spring-boot-starter-jdbc или один из соответствующих проектов spring-data. Существуют также более легкие альтернативы, такие как jOOQ или myBatis. Наконец, вы всегда можете использовать опции NoSQL, такие как MongoDB и т. д.
Вам необходимо настроить ведение журнала в своем приложении, но вы хотите различать уровни журнала на вашем компьютере и уровни журнала в разных средах (qa, test, prod). Какие у вас есть варианты?	Во-первых, всегда полезно правильно понять экосистему ведения журналов Java, а затем прочитать соответствующую главу Spring Boot документации о ведении журнала. Когда дело доходит до настройки вывода, существуют различные варианты: Непосредственно в файле application.properties (который, конечно, может и должен отличаться в средах DEV и PRD). В зависимости от используемой структуры ведения журнала, указание настраиваемого файла конфигурации (например, logback-spring.xml). Или даже через JMX во время выполнения. Две популярные современные библиотеки ведения журнала, Logback и Log4j2, также поддерживают горячую перезагрузку конфигурации ведения журнала без необходимости перезагрузки вашего приложения.
Как проще всего развернуть приложение Spring Boot в рабочей среде? Какие еще есть варианты?	Самый простой способ развернуть приложение Spring Boot это поместить .jar файл со встроенным контейнером сервлетов на любой сервер или платформу, на которой установлена ​​JRE.По организационным и историческим причинам вы также можете развернуть приложение Spring Boot как файл .war в существующем контейнере сервлетов или сервере приложений. И последнее, но не менее важное: вы, конечно, также можете поместить свой .jar файл в образ Docker и даже развернуть его с помощью Kubernetes.
Вам сказали включить «Spring Security» в вашем приложении. Что происходит, когда вы добавляете стартер Spring Security в свое приложение?	Это вопрос с подвохом. При добавлении Spring Security Starter в ваше приложение вы будете неожиданно запрашивать логин каждый раз, когда вы пытаетесь получить доступ к вашему приложению. Кроме того, отправка форм / конечные точки REST будут работать иначе или полностью заблокированы. Суть в том, что вы «не просто включаете» безопасность в приложении Spring Boot, вам нужно четкое понимание того, что вы делаете. Автор написал исчерпывающее руководство по Spring Security , которое объясняет все основные аспекты безопасности самым простым способом.
Как узнать, какие автоконфигурации Spring Boot применяются при запуске и какие условия оцениваются?	Spring Boot Actuator может предоставить эту информацию через конечные точки HTTP или JMX. Кроме того, вы можете запустить приложение Spring Boot с флагом «--debug». Обратите внимание, что информация об оцениваемых условиях немного «сырая» и ее трудно переварить. Для этого прочтите это руководство, чтобы убедиться, что вы понимаете, как работают автоконфигурации Spring Boot.
В чем различия между встроенным контейнером и WAR?	Встроенный контейнер представляет собой сервер, который поставляется с конечным приложением, тогда как WAR является архивом, который может быть развернут на внешнем сервере. Контейнеры сервлетов хороши для управления несколькими приложениями на одном хосте, но они не очень полезны для управления только одним приложением. С облачным окружение используется одно приложение на виртуальную машину является предпочтительным и более распространенным способом. Современные фреимворки хотят быть более совместимыми с облаками, поэтому переходят на встраиваемые контейнеры.
Какие встроенные контейнеры поддерживает Spring?	Spring Boot поддерживает Tomcat, Jetty, и Undertow.По умолчанию используется TomCat. Для того чтобы изменить контейенер, просто добавьте нужную зависимость в pom.xml.
Что делает @EnableAutoConfiguration?	Она позволяет использовать автоконфигурацию. Автоконфигурация в Spring Boot пытается создать и настроить бины основываясь на зависимостях в classpath, для того чтобы позволить разработчику быстро начать работать с различными технологиями и убрать шаблонный код.
Чем различаются JRE, JVM и JDK?	JVM, Java Virtual Machine (Виртуальная машина Java) — основная часть среды времени исполнения Java (JRE). Виртуальная машина Java исполняет байт-код Java, предварительно созданный из исходного текста Java-программы компилятором Java. JVM может также использоваться для выполнения программ, написанных на других языках программирования. JRE, Java Runtime Environment (Среда времени выполнения Java) - минимально-необходимая реализация виртуальной машины для исполнения Java-приложений. Состоит из JVM и стандартного набора библиотек классов Java. JDK, Java Development Kit (Комплект разработки на Java) - JRE и набор инструментов разработчика приложений на языке Java, включающий в себя компилятор Java, стандартные библиотеки классов Java, примеры, документацию, различные утилиты. Коротко: JDK - среда для разработки программ на Java, включающая в себя JRE - среду для обеспечения запуска Java программ, которая в свою очередь содержит JVM - интерпретатор кода Java программ.
Какие существуют модификаторы доступа?	private (приватный): члены класса доступны только внутри класса. Для обозначения используется служебное слово private. default, package-private, package level (доступ на уровне пакета): видимость класса/членов класса только внутри пакета. Является модификатором доступа по умолчанию - специальное обозначение не требуется. protected (защищённый): члены класса доступны внутри пакета и в наследниках. Для обозначения используется служебное слово protected. public (публичный): класс/члены класса доступны всем. Для обозначения используется служебное слово public. Последовательность модификаторов по возрастанию уровня закрытости: public, protected, default, private. Во время наследования возможно изменения модификаторов доступа в сторону большей видимости (для поддержания соответствия принципу подстановки Барбары Лисков).
О чем говорит ключевое слово final?	Модификатор final может применяться к переменным, параметрам методов, полям и методам класса или самим классам.Класс не может иметь наследников; 2) Метод не может быть переопределен в классах наследниках; 3) Поле не может изменить свое значение после инициализации; 4) Параметры методов не могут изменять своё значение внутри метода; 5) Локальные переменные не могут быть изменены после присвоения им значения.
Какими значениями инициализируются переменные по умолчанию?	 Числа инициализируются 0 или 0.0; 2) char — \u0000; 3) boolean — false; 4) Объекты (в том числе String) — null.
Что вы знаете о функции main()?	Метод main() — точка входа в программу. В приложении может быть несколько таких методов. Если метод отсутствует, то компиляция возможна, но при запуске будет получена ошибка `Error: Main method not found`
Какие логические операции и операторы вы знаете?	&: Логическое AND (И); &&: Сокращённое AND; |: Логическое OR (ИЛИ); ||: Сокращённое OR; ^: Логическое XOR (исключающее OR (ИЛИ)); !: Логическое унарное NOT (НЕ); &=: AND с присваиванием; |=: OR с присваиванием; ^=: XOR с присваиванием; ==: Равно; !=: Не равно; ?:: Тернарный (троичный) условный оператор.
Что такое тернарный оператор выбора?	Тернарный условный оператор ?: - оператор, которым можно заменить некоторые конструкции операторов if-then-else. Выражение записывается в следующей форме: условие ? выражение1 : выражение2 Если условие выполняется, то вычисляется выражение1 и его результат становится результатом выполнения всего оператора. Если же условие равно false, то вычисляется выражение2 и его значение становится результатом работы оператора. Оба операнда выражение1 и выражение2 должны возвращать значение одинакового (или совместимого) типа.
Какие побитовые операции вы знаете?	~: Побитовый унарный оператор NOT; &: Побитовый AND; &=: Побитовый AND с присваиванием; |: Побитовый OR; |=: Побитовый OR с присваиванием; ^: Побитовый исключающее XOR; ^=: Побитовый исключающее XOR с присваиванием; >>: Сдвиг вправо (деление на 2 в степени сдвига); >>=: Сдвиг вправо с присваиванием; >>>: Сдвиг вправо без учёта знака; >>>=: Сдвиг вправо без учёта знака с присваиванием; <<: Сдвиг влево (умножение на 2 в степени сдвига); <<=: Сдвиг влево с присваиванием.
Где и для чего используется модификатор abstract?	Класс, помеченный модификатором abstract, называется абстрактным классом. Такие классы могут выступать только предками для других классов. Создавать экземпляры самого абстрактного класса не разрешается. При этом наследниками абстрактного класса могут быть как другие абстрактные классы, так и классы, допускающие создание объектов. Метод, помеченный ключевым словом abstract - абстрактный метод, т.е. метод, который не имеет реализации. Если в классе присутствует хотя бы один абстрактный метод, то весь класс должен быть объявлен абстрактным. Использование абстрактных классов и методов позволяет описать некий шаблон объекта, который должен быть реализован в других классах. В них же самих описывается лишь некое общее для всех потомков поведение.
Дайте определение понятию «интерфейс». Какие модификаторы по умолчанию имеют поля и методы интерфейсов?	Ключевое слово interface используется для создания полностью абстрактных классов. Основное предназначение интерфейса - определять каким образом мы можем использовать класс, который его реализует. Создатель интерфейса определяет имена методов, списки аргументов и типы возвращаемых значений, но не реализует их поведение. Все методы неявно объявляются как public. Начиная с Java 8 в интерфейсах разрешается размещать реализацию методов по умолчанию default и статических static методов. Интерфейс также может содержать и поля. В этом случае они автоматически являются публичными public, статическими static и неизменяемыми final.
Чем абстрактный класс отличается от интерфейса? В каких случаях следует использовать абстрактный класс, а в каких интерфейс?	 В Java класс может одновременно реализовать несколько интерфейсов, но наследоваться только от одного класса.Абстрактные классы используются только тогда, когда присутствует тип отношений «is a» (является). Интерфейсы могут реализоваться классами, которые не связаны друг с другом.Абстрактный класс - средство, позволяющее избежать написания повторяющегося кода, инструмент для частичной реализации поведения. Интерфейс - это средство выражения семантики класса, контракт, описывающий возможности. Все методы интерфейса неявно объявляются как public abstract или (начиная с Java 8) default - методами с реализацией по-умолчанию, а поля - public static final.Интерфейсы позволяют создавать структуры типов без иерархии. 5)Наследуясь от абстрактного, класс «растворяет» собственную индивидуальность. Реализуя интерфейс, он расширяет собственную функциональность.  Абстрактные классы содержат частичную реализацию, которая дополняется или расширяется в подклассах. При этом все подклассы схожи между собой в части реализации, унаследованной от абстрактного класса, и отличаются лишь в части собственной реализации абстрактных методов родителя. Поэтому абстрактные классы применяются в случае построения иерархии однотипных, очень похожих друг на друга классов. В этом случае наследование от абстрактного класса, реализующего поведение объекта по умолчанию может быть полезно, так как позволяет избежать написания повторяющегося кода. Во всех остальных случаях лучше использовать интерфейсы.
Почему в некоторых интерфейсах вообще не определяют методов?	Это так называемые маркерные интерфейсы. Они просто указывают что класс относится к определенному типу. Примером может послужить интерфейс Clonable, который указывает на то, что класс поддерживает механизм клонирования.
Почему нельзя объявить метод интерфейса с модификатором final?	В случае интерфейсов указание модификатора final бессмысленно, т.к. все методы интерфейсов неявно объявляются как абстрактные, т.е. их невозможно выполнить, не реализовав где-то еще, а этого нельзя будет сделать, если у метода идентификатор final.
Может ли объект получить доступ к члену класса, объявленному как private? Если да, то каким образом?	 Внутри класса доступ к приватной переменной открыт без ограничений; 2) Вложенный класс имеет полный доступ ко всем (в том числе и приватным) членам содержащего его класса; 3) Доступ к приватным переменным извне может быть организован через отличные от приватных методов, которые предоставлены разработчиком класса. Например: getX() и setX().Через механизм рефлексии (Reflection API): class Victim {   private int field = 42;  }  //...  Victim victim = new Victim();  Field field = Victim.class.getDeclaredField("field"); field.setAccessible(true);  int fieldValue = (int) field.get(victim);
Каков порядок вызова конструкторов и блоков инициализации с учётом иерархии классов?	Сначала вызываются все статические блоки в очередности от первого статического блока корневого предка и выше по цепочке иерархии до статических блоков самого класса. Затем вызываются нестатические блоки инициализации корневого предка, конструктор корневого предка и так далее вплоть до нестатических блоков и конструктора самого класса. Parent static block(s) → Child static block(s) → Grandchild static block(s) → Parent non-static block(s) → Parent constructor → → Child non-static block(s) → Child constructor → → Grandchild non-static block(s) → Grandchild constructor
Зачем нужны и какие бывают блоки инициализации?	Блоки инициализации представляют собой код, заключенный в фигурные скобки и размещаемый внутри класса вне объявления методов или конструкторов.Существуют статические и нестатические блоки инициализации.Блок инициализации выполняется перед инициализацией класса загрузчиком классов или созданием объекта класса с помощью конструктора.Несколько блоков инициализации выполняются в порядке следования в коде класса.Блок инициализации способен генерировать исключения, если их объявления перечислены в throws всех конструкторов класса.Блок инициализации возможно создать и в анонимном классе.
К каким конструкциям Java применим модификатор static?	полям; методам; вложенным классам; членам секции import.
Ключевое слово static	Static — модификатор, применяемый к полю, блоку, методу или внутреннему классу. Данный модификатор указывает на привязку субъекта к текущему классу. При обозначении переменной уровня класса мы указываем на то, что это значение относится к классу. Если этого не делать, то значение переменной будет привязываться к объекту, созданному по этому классу. Есть два блока инициализации — обычный и статический. Блок предназначен для инициализации внутренних переменных. Если блок обычный, то им инициализируют внутренние переменные объекта, если же статический, соответственно, им задают статические переменные (то есть переменные класса). Статические методы отличаются от обычных тем, что они также привязаны к классу, а не к объекту. Важным свойством статического метода является то, что он может обратиться только к статическим переменным/методам. Статическим классом может быть только внутренний класс. Опять же, этот класс привязан к внешнему классу, и если внешний наследуется другим классом, то этот не будет наследован. При этом данный класс можно наследовать, как и он может наследоваться от любого другого класса и имплементировать интерфейс. По сути статический вложенный класс ничем не отличается от любого другого внутреннего класса за исключением того, что его объект не содержит ссылку на создавший его объект внешнего класса.
Для чего в Java используются статические блоки инициализации?	Статические блоки инициализация используются для выполнения кода, который должен выполняться один раз при инициализации класса загрузчиком классов, в момент, предшествующий созданию объектов этого класса при помощи конструктора. Такой блок (в отличие от нестатических, принадлежащих конкретном объекту класса) принадлежит только самому классу (объекту метакласса Class).
Что произойдёт, если в блоке инициализации возникнет исключительная ситуация?	Для нестатических блоков инициализации, если выбрасывание исключения прописано явным образом требуется, чтобы объявления этих исключений были перечислены в throws всех конструкторов класса. Иначе будет ошибка компиляции. Для статического блока выбрасывание исключения в явном виде, приводит к ошибке компиляции. В остальных случаях, взаимодействие с исключениями будет проходить так же, как и в любом другом месте. Класс не будет инициализирован, если ошибка происходит в статическом блоке и объект класса не будет создан, если ошибка возникает в нестатическом блоке.
Какое исключение выбрасывается при возникновении ошибки в блоке инициализации класса?	Если возникшее исключение - наследник RuntimeException: 1) для статических блоков инициализации будет выброшено java.lang.ExceptionInInitializerError; 2) для нестатических будет проброшено исключение-источник.  Если возникшее исключение - наследник Error, то в обоих случаях будет выброшено java.lang.Error. Исключение: java.lang.ThreadDeath - смерть потока. В этом случае никакое исключение выброшено не будет.
Может ли статический метод быть переопределён или перегружен?	Перегружен - да. Всё работает точно так же, как и с обычными методами - 2 статических метода могут иметь одинаковое имя, если количество их параметров или типов различается. Переопределён - нет. Выбор вызываемого статического метода происходит при раннем связывании (на этапе компиляции, а не выполнения) и выполняться всегда будет родительский метод, хотя синтаксически переопределение статического метода - это вполне корректная языковая конструкция. В целом, к статическим полям и методам рекомендуется обращаться через имя класса, а не объект.
Могут ли нестатические методы перегрузить статические?	Да. В итоге получится два разных метода. Статический будет принадлежать классу и будет доступен через его имя, а нестатический будет принадлежать конкретному объекту и доступен через вызов метода этого объекта.
Можно ли сузить уровень доступа/тип возвращаемого значения при переопределении метода?	- При переопределении метода нельзя сузить модификатор доступа к методу (например с public в MainClass до private в Class extends MainClass). - Изменить тип возвращаемого значения при переопределении метода нельзя, будет ошибка attempting to use incompatible return type. - Можно сузить возвращаемое значение, если они совместимы.
Возможно ли при переопределении метода изменить: модификатор доступа, возвращаемый тип, тип аргумента или их количество, имена аргументов или их порядок; убирать, добавлять, изменять порядок следования элементов секции throws?	При переопределении метода сужать модификатор доступа не разрешается, т.к. это приведёт к нарушению принципа подстановки Барбары Лисков. Расширение уровня доступа возможно. Можно изменять все, что не мешает компилятору понять какой метод родительского класса имеется в виду: - Изменять тип возвращаемого значения при переопределении метода разрешено только в сторону сужения типа (вместо родительского класса - наследника). - При изменении типа, количества, порядка следования аргументов вместо переопределения будет происходить overloading (перегрузка) метода. - Секцию throws метода можно не указывать, но стоит помнить, что она остаётся действительной, если уже определена у метода родительского класса. Так же, возможно добавлять новые исключения, являющиеся наследниками от уже объявленных или исключения RuntimeException. Порядок следования таких элементов при переопределении значения не имеет.
Как получить доступ к переопределенным методам родительского класса?	С помощью ключевого слова super мы можем обратиться к любому члену родительского класса - методу или полю, если они не определены с модификатором private. super.method();
Можно ли объявить метод абстрактным и статическим одновременно?	Нет. В таком случае компилятор выдаст ошибку: "Illegal combination of modifiers: 'abstract' and 'static'". Модификатор abstract говорит, что метод будет реализован в другом классе, а static наоборот указывает, что этот метод будет доступен по имени класса.
В чем разница между членом экземпляра класса и статическим членом класса?	Модификатор static говорит о том, что данный метод или поле принадлежат самому классу и доступ к ним возможен даже без создания экземпляра класса. Поля, помеченные static инициализируются при инициализации класса. На методы, объявленные как static, накладывается ряд ограничений: - Они могут вызывать только другие статические методы. - Они должны осуществлять доступ только к статическим переменным. - Они не могут ссылаться на члены типа this или super.  В отличии от статических, поля экземпляра класса принадлежат конкретному объекту и могут иметь разные значения для каждого. Вызов метода экземпляра возможен только после предварительного создания объекта класса.
Где разрешена инициализация статических/нестатических полей?	- Статические поля можно инициализировать при объявлении, в статическом или нестатическом блоке инициализации. - Нестатические поля можно инициализировать при объявлении, в нестатическом блоке инициализации или в конструкторе
Какие типы классов бывают в java?	Top level class (Обычный класс): -- Abstract class (Абстрактный класс); -- Final class (Финализированный класс). Interfaces (Интерфейс). Enum (Перечисление). Nested class (Вложенный класс): -- Static nested class (Статический вложенный класс); -- Member inner class (Простой внутренний класс); -- Local inner class (Локальный класс); -- Anonymous inner class (Анонимный класс).
Расскажите про вложенные классы. В каких случаях они применяются?	Класс называется вложенным (Nested class), если он определен внутри другого класса. Вложенный класс должен создаваться только для того, чтобы обслуживать обрамляющий его класс. Если вложенный класс оказывается полезен в каком-либо ином контексте, он должен стать классом верхнего уровня. Вложенные классы имеют доступ ко всем (в том числе приватным) полям и методам внешнего класса, но не наоборот. Из-за этого разрешения использование вложенных классов приводит к некоторому нарушению инкапсуляции.  Существуют четыре категории вложенных классов: -- Static nested class (Статический вложенный класс); -- Member inner class (Простой внутренний класс); -- Local inner class (Локальный класс); -- Anonymous inner class (Анонимный класс).  Такие категории классов, за исключением первого, также называют внутренними (Inner class). Внутренние классы ассоциируются не с внешним классом, а с экземпляром внешнего. Каждая из категорий имеет рекомендации по своему применению. Если вложенный класс должен быть виден за пределами одного метода или он слишком длинный для того, чтобы его можно было удобно разместить в границах одного метода и если каждому экземпляру такого класса необходима ссылка на включающий его экземпляр, то используется нестатический внутренний класс. В случае, если ссылка на обрамляющий класс не требуется - лучше сделать такой класс статическим. Если класс необходим только внутри какого-то метода и требуется создавать экземпляры этого класса только в этом методе, то используется локальный класс. А, если к тому же применение класса сводится к использованию лишь в одном месте и уже существует тип, характеризующий этот класс, то рекомендуется делать его анонимным классом.
Что такое «статический класс»?	Это вложенный класс, объявленный с использованием ключевого слова static. К классам верхнего уровня модификатор static неприменим.
Какие существуют особенности использования вложенных классов: статических и внутренних? В чем заключается разница между ними?	- Вложенные классы могут обращаться ко всем членам обрамляющего класса, в том числе и приватным. - Для создания объекта статического вложенного класса объект внешнего класса не требуется. - Из объекта статического вложенного класса нельзя обращаться к не статическим членам обрамляющего класса напрямую, а только через ссылку на экземпляр внешнего класса. - Обычные вложенные классы не могут содержать статических методов, блоков инициализации и классов. Статические вложенные классы - могут. - В объекте обычного вложенного класса хранится ссылка на объект внешнего класса. Внутри статической такой ссылки нет. Доступ к экземпляру обрамляющего класса осуществляется через указание .this после его имени. Например: Outer.this.
Что такое «локальный класс»? Каковы его особенности?	Local inner class (Локальный класс) - это вложенный класс, который может быть декларирован в любом блоке, в котором разрешается декларировать переменные. Как и простые внутренние классы (Member inner class) локальные классы имеют имена и могут использоваться многократно. Как и анонимные классы, они имеют окружающий их экземпляр только тогда, когда применяются в нестатическом контексте.  Локальные классы имеют следующие особенности: - Видны только в пределах блока, в котором объявлены; - Не могут быть объявлены как private/public/protected или static; - Не могут иметь внутри себя статических объявлений методов и классов, но могут иметь финальные статические поля, проинициализированные константой; - Имеют доступ к полям и методам обрамляющего класса; - Могут обращаться к локальным переменным и параметрам метода, если они объявлены с модификатором final.
Что такое «анонимные классы»? Где они применяются?	Это вложенный локальный класс без имени, который разрешено декларировать в любом месте обрамляющего класса, разрешающем размещение выражений. Создание экземпляра анонимного класса происходит одновременно с его объявлением. В зависимости от местоположения анонимный класс ведет себя как статический либо как нестатический вложенный класс - в нестатическом контексте появляется окружающий его экземпляр.  Анонимные классы имеют несколько ограничений: - Их использование разрешено только в одном месте программы - месте его создания; - Применение возможно только в том случае, если после порождения экземпляра нет необходимости на него ссылаться; - Реализует лишь методы своего интерфейса или суперкласса, т.е. не может объявлять каких-либо новых методов, так как для доступа к ним нет поименованного типа.  Анонимные классы обычно применяются для: - создания объекта функции (function object), например, реализация интерфейса Comparator; - создания объекта процесса (process object), такого как экземпляры классов Thread, Runnable и подобных; - в статическом методе генерации; - инициализации открытого статического поля final, которое соответствует сложному перечислению типов, когда для каждого экземпляра в перечислении требуется отдельный подкласс.
Каким образом из вложенного класса получить доступ к полю внешнего класса?	Статический вложенный класс имеет прямой доступ только к статическим полям обрамляющего класса. Простой внутренний класс, может обратиться к любому полю внешнего класса напрямую. В случае, если у вложенного класса уже существует поле с таким же литералом, то обращаться к такому полю следует через ссылку на его экземпляр. Например: Outer.this.field.
Для чего используется оператор assert?	Assert (Утверждение) это специальная конструкция, позволяющая проверять предположения о значениях произвольных данных в произвольном месте программы. Утверждение может автоматически сигнализировать об обнаружении некорректных данных, что обычно приводит к аварийному завершению программы с указанием места обнаружения некорректных данных. Утверждения существенно упрощают локализацию ошибок в коде. Даже проверка результатов выполнения очевидного кода может оказаться полезной при последующем рефакторинге, после которого код может стать не настолько очевидным и в него может закрасться ошибка. Обычно утверждения оставляют включенными во время разработки и тестирования программ, но отключают в релиз-версиях программ. Т.к. утверждения могут быть удалены на этапе компиляции либо во время исполнения программы, они не должны менять поведение программы. Если в результате удаления утверждения поведение программы может измениться, то это явный признак неправильного использования assert. Таким образом, внутри assert нельзя вызывать методы, изменяющие состояние программы, либо внешнего окружения программы. В Java проверка утверждений реализована с помощью оператора assert, который имеет форму: assert [Выражение типа boolean]; или assert [Выражение типа boolean] : [Выражение любого типа, кроме void]; Во время выполнения программы в том случае, если поверка утверждений включена, вычисляется значение булевского выражения, и если его результат false, то генерируется исключение java.lang.AssertionError. В случае использования второй формы оператора assert выражение после двоеточия задаёт детальное сообщение о произошедшей ошибке (вычисленное выражение будет преобразовано в строку и передано конструктору AssertionError).
Что такое Heap и Stack память в Java? Какая разница между ними?	Heap (куча) используется Java Runtime для выделения памяти под объекты и классы. Создание нового объекта также происходит в куче. Это же является областью работы сборщика мусора. Любой объект, созданный в куче, имеет глобальный доступ и на него могут ссылаться из любой части приложения. Stack (стек) это область хранения данных также находящееся в общей оперативной памяти (RAM). Всякий раз, когда вызывается метод, в памяти стека создается новый блок, который содержит примитивы и ссылки на другие объекты в методе. Как только метод заканчивает работу, блок также перестает использоваться, тем самым предоставляя доступ для следующего метода. Размер стековой памяти намного меньше объема памяти в куче. Стек в Java работает по схеме LIFO (Последний-зашел-Первый-вышел) Различия между Heap и Stack памятью:  - Куча используется всеми частями приложения, в то время как стек используется только одним потоком исполнения программы. - Всякий раз, когда создается объект, он всегда хранится в куче, а в памяти стека содержится лишь ссылка на него. Память стека содержит только локальные переменные примитивных типов и ссылки на объекты в куче. - Объекты в куче доступны с любой точки программы, в то время как стековая память не может быть доступна для других потоков. - Стековая память существует лишь какое-то время работы программы, а память в куче живет с самого начала до конца работы программы. - Если память стека полностью занята, то Java Runtime бросает исключение java.lang.StackOverflowError. Если заполнена память кучи, то бросается исключение java.lang.OutOfMemoryError: Java Heap Space. - Размер памяти стека намного меньше памяти в куче. - Из-за простоты распределения памяти, стековая память работает намного быстрее кучи.  Для определения начального и максимального размера памяти в куче используются -Xms и -Xmx опции JVM. Для стека определить размер памяти можно с помощью опции -Xss.
Верно ли утверждение, что примитивные типы данных всегда хранятся в стеке, а экземпляры ссылочных типов данных в куче?	Не совсем. Примитивное поле экземпляра класса хранится не в стеке, а в куче. Любой объект (всё, что явно или неявно создаётся при помощи оператора new) хранится в куче.
Каким образом передаются переменные в методы, по значению или по ссылке?	В Java параметры всегда передаются только по значению, что определяется как «скопировать значение и передать копию». С примитивами это будет копия содержимого. Со ссылками - тоже копия содержимого, т.е. копия ссылки. При этом внутренние члены ссылочных типов через такую копию изменить возможно, а вот саму ссылку, указывающую на экземпляр - нет.
Для чего нужен сборщик мусора?	Сборщик мусора (Garbage Collector) должен делать всего две вещи: - Находить мусор - неиспользуемые объекты. (Объект считается неиспользуемым, если ни одна из сущностей в коде, выполняемом в данный момент, не содержит ссылок на него, либо цепочка ссылок, которая могла бы связать объект с некоторой сущностью приложения, обрывается); - Освобождать память от мусора.  Существует два подхода к обнаружению мусора: - Reference counting; - Tracing Reference counting (подсчёт ссылок). Суть этого подхода состоит в том, что каждый объект имеет счетчик. Счетчик хранит информацию о том, сколько ссылок указывает на объект. Когда ссылка уничтожается, счетчик уменьшается. Если значение счетчика равно нулю, - объект можно считать мусором. Главным минусом такого подхода является сложность обеспечения точности счетчика. Также при таком подходе сложно выявлять циклические зависимости (когда два объекта указывают друг на друга, но ни один живой объект на них не ссылается), что приводит к утечкам памяти. Главная идея подхода Tracing (трассировка) состоит в утверждении, что живыми могут считаться только те объекты, до которых мы можем добраться из корневых точек (GC Root) и те объекты, которые доступны с живого объекта. Всё остальное - мусор.  Существует 4 типа корневых точки: - Локальные переменные и параметры методов; - Потоки; - Статические переменные; - Ссылки из JNI. Самое простое java приложение будет иметь корневые точки: - Локальные переменные внутри main() метода и параметры main() метода; - Поток который выполняет main(); - Статические переменные класса, внутри которого находится main() метод. Таким образом, если мы представим все объекты и ссылки между ними как дерево, то нам нужно будет пройти с корневых узлов (точек) по всем рёбрам. При этом узлы, до которых мы сможем добраться - не мусор, все остальные - мусор. При таком подходе циклические зависимости легко выявляются. HotSpot VM использует именно такой подход.  Для очистки памяти от мусора существуют два основных метода: - Copying collectors - Mark-and-sweep  При copying collectors подходе память делится на две части «from-space» и «to-space», при этом сам принцип работы такой: - Объекты создаются в «from-space»; - Когда «from-space» заполняется, приложение приостанавливается; - Запускается сборщик мусора. Находятся живые объекты в «from-space» и копируются в «to-space»; - Когда все объекты скопированы «from-space» полностью очищается; - «to-space» и «from-space» меняются местами.  Главный плюс такого подхода в том, что объекты плотно забивают память. Минусы подхода: 1 Приложение должно быть остановлено на время, необходимое для полного прохождения цикла сборки мусора; 2 В худшем случае (когда все объекты живые) «form-space» и «to-space» будут обязаны быть одинакового размера.  Алгоритм работы mark-and-sweep можно описать так: - Объекты создаются в памяти; - В момент, когда нужно запустить сборщик мусора приложение приостанавливается; - Сборщик проходится по дереву объектов, помечая живые объекты; - Сборщик проходится по всей памяти, находя все не отмеченные куски памяти и сохраняя их в «free list»; - Когда новые объекты начинают создаваться они создаются в памяти доступной во «free list».  Минусы этого способа: - Приложение не работает пока происходит сборка мусора; - Время остановки напрямую зависит от размеров памяти и количества объектов; - Если не использовать «compacting» память будет использоваться не эффективно. Сборщики мусора HotSpot VM используют комбинированный подход Generational Garbage Collection, который позволяет использовать разные алгоритмы для разных этапов сборки мусора. Этот подход опирается на том, что: - большинство создаваемых объектов быстро становятся мусором; - существует мало связей между объектами, которые были созданы в прошлом и только что созданными объектами.
Как работает сборщик мусора?	Механизм сборки мусора - это процесс освобождения места в куче, для возможности добавления новых объектов. Объекты создаются посредством оператора new, тем самым присваивая объекту ссылку. Для окончания работы с объектом достаточно просто перестать на него ссылаться, например, присвоив переменной ссылку на другой объект или значение null; прекратить выполнение метода, чтобы его локальные переменные завершили свое существование естественным образом. Объекты, ссылки на которые отсутствуют, принято называть мусором (garbage), который будет удален. Виртуальная машина Java, применяя механизм сборки мусора, гарантирует, что любой объект, обладающий ссылками, остается в памяти — все объекты, которые недостижимы из исполняемого кода, ввиду отсутствия ссылок на них, удаляются с высвобождением отведенной для них памяти. Точнее говоря, объект не попадает в сферу действия процесса сборки мусора, если он достижим посредством цепочки ссылок, начиная с корневой (GC Root) ссылки, т.е. ссылки, непосредственно существующей в выполняемом коде. Память освобождается сборщиком мусора по его собственному «усмотрению». Программа может успешно завершить работу, не исчерпав ресурсов свободной памяти или даже не приблизившись к этой черте и поэтому ей так и не потребуются «услуги» сборщика мусора. Мусор собирается системой автоматически, без вмешательства пользователя или программиста, но это не значит, что этот процесс не требует внимания вовсе. Необходимость создания и удаления большого количества объектов существенным образом сказывается на производительности приложений и, если быстродействие программы является важным фактором, следует тщательно обдумывать решения, связанные с созданием объектов, — это, в свою очередь, уменьшит и объем мусора, подлежащего утилизации.
Какие разновидности сборщиков мусора реализованы в виртуальной машине HotSpot?	Java HotSpot VM предоставляет разработчикам на выбор четыре различных сборщика мусора: - Serial (последовательный) — самый простой вариант для приложений с небольшим объемом данных и не требовательных к задержкам. На данный момент используется сравнительно редко, но на слабых компьютерах может быть выбран виртуальной машиной в качестве сборщика по умолчанию. Использование Serial GC включается опцией -XX:+UseSerialGC. - Parallel (параллельный) — наследует подходы к сборке от последовательного сборщика, но добавляет параллелизм в некоторые операции, а также возможности по автоматической подстройке под требуемые параметры производительности. Параллельный сборщик включается опцией -XX:+UseParallelGC. - Concurrent Mark Sweep (CMS) — нацелен на снижение максимальных задержек путем выполнения части работ по сборке мусора параллельно с основными потоками приложения. Подходит для работы с относительно большими объемами данных в памяти. Использование CMS GC включается опцией -XX:+UseConcMarkSweepGC. - Garbage-First (G1) — создан для замены CMS, особенно в серверных приложениях, работающих на многопроцессорных серверах и оперирующих большими объемами данных. G1 включается опцией Java -XX:+UseG1GC.
Опишите алгоритм работы какого-нибудь сборщика мусора, реализованного в виртуальной машине HotSpot.	Serial Garbage Collector (Последовательный сборщик мусора) был одним из первых сборщиков мусора в HotSpot VM. Во время работы этого сборщика приложения приостанавливается и продолжает работать только после прекращения сборки мусора.  Память приложения делится на три пространства: - Young generation. Объекты создаются именно в этом участке памяти. - Old generation. В этот участок памяти перемещаются объекты, которые переживают «minor garbage collection». - Permanent generation. Тут хранятся метаданные об объектах, Class data sharing (CDS), пул строк (String pool). Permanent область делится на две: только для чтения и для чтения-записи. Очевидно, что в этом случае область только для чтения не чистится сборщиком мусора никогда.  Область памяти Young generation состоит из трёх областей: Eden и двух меньших по размеру Survivor spaces - To space и From space. Большинство объектов создаются в области Eden, за исключением очень больших объектов, которые не могут быть размещены в ней и поэтому сразу размещаются в Old generation. В Survivor spaces перемещаются объекты, которые пережили по крайней мере одну сборку мусора, но ещё не достигли порога «старости» (tenuring threshold), чтобы быть перемещенными в Old generation. Когда Young generation заполняется, то в этой области запускается процесс лёгкой сборки (minor collection), в отличие от процесса сборки, проводимого над всей кучей (full collection). Он происходит следующим образом: в начале работы одно из Survivor spaces - To space, является пустым, а другое - From space, содержит объекты, пережившие предыдущие сборки. Сборщик мусора ищет живые объекты в Eden и копирует их в To space, а затем копирует туда же и живые «молодые» (то есть не пережившие еще заданное число сборок мусора) объекты из From space. Старые объекты из From space перемещаются в Old generation. После лёгкой сборки From space и To space меняются ролями, область Eden становится пустой, а число объектов в Old generation увеличивается.  Если в процессе копирования живых объектов To space переполняется, то оставшиеся живые объекты из Eden и From space, которым не хватило места в To space, будут перемещены в Old generation, независимо от того, сколько сборок мусора они пережили. Поскольку при использовании этого алгоритма сборщик мусора просто копирует все живые объекты из одной области памяти в другую, то такой сборщик мусора называется copying (копирующий). Очевидно, что для работы копирующего сборщика мусора у приложения всегда должна быть свободная область памяти, в которую будут копироваться живые объекты, и такой алгоритм может применяться для областей памяти сравнительно небольших по отношению к общему размеру памяти приложения. Young generation как раз удовлетворяет этому условию (по умолчанию на машинах клиентского типа эта область занимает около 10% кучи (значение может варьироваться в зависимости от платформы)). Однако, для сборки мусора в Old generation, занимающем большую часть всей памяти, используется другой алгоритм. В Old generation сборка мусора происходит с использованием алгоритма mark-sweep-compact, который состоит из трёх фаз. В фазе Mark (пометка) сборщик мусора помечает все живые объекты, затем, в фазе Sweep (очистка) все не помеченные объекты удаляются, а в фазе Сompact (уплотнение) все живые объекты перемещаются в начало Old generation, в результате чего свободная память после очистки представляет собой непрерывную область. Фаза уплотнения выполняется для того, чтобы избежать фрагментации и упростить процесс выделения памяти в Old generation. Когда свободная память представляет собой непрерывную область, то для выделения памяти под создаваемый объект можно использовать очень быстрый (около десятка машинных инструкций) алгоритм bump-the-pointer: адрес начала свободной памяти хранится в специальном указателе, и когда поступает запрос на создание нового объекта, код проверяет, что для нового объекта достаточно места, и, если это так, то просто увеличивает указатель на размер объекта. Последовательный сборщик мусора отлично подходит для большинства приложений, использующих до 200 мегабайт кучи, работающих на машинах клиентского типа и не предъявляющих жёстких требований к величине пауз, затрачиваемых на сборку мусора. В то же время модель «stop-the-world» может вызвать длительные паузы в работе приложения при использовании больших объёмов памяти. Кроме того, последовательный алгоритм работы не позволяет оптимально использовать вычислительные ресурсы компьютера, и последовательный сборщик мусора может стать узким местом при работе приложения на многопроцессорных машинах.
Что такое finalize()? Зачем он нужен?	Через вызов метода finalize() (который наследуется от Java.lang.Object) JVM реализуется функциональность аналогичная функциональности деструкторов в С++, используемых для очистки памяти перед возвращением управления операционной системе. Данный метод вызывается при уничтожении объекта сборщиком мусора (garbage collector) и переопределяя finalize() можно запрограммировать действия необходимые для корректного удаления экземпляра класса - например, закрытие сетевых соединений, соединений с базой данных, снятие блокировок на файлы и т.д. После выполнения этого метода объект должен быть повторно собран сборщиком мусора (и это считается серьезной проблемой метода finalize() т.к. он мешает сборщику мусора освобождать память). Вызов этого метода не гарантируется, т.к. приложение может быть завершено до того, как будет запущена сборка мусора. Объект не обязательно будет доступен для сборки сразу же - метод finalize() может сохранить куда-нибудь ссылку на объект. Подобная ситуация называется «возрождением» объекта и считается антипаттерном. Главная проблема такого трюка - в том, что «возродить» объект можно только 1 раз.
Что произойдет со сборщиком мусора, если выполнение метода finalize() требует ощутимо много времени, или в процессе выполнения будет выброшено исключение?	Непосредственно вызов finalize() происходит в отдельном потоке Finalizer (java.lang.ref.Finalizer.FinalizerThread), который создаётся при запуске виртуальной машины (в статической секции при загрузке класса Finalizer). Методы finalize() вызываются последовательно в том порядке, в котором были добавлены в список сборщиком мусора. Соответственно, если какой-то finalize() зависнет, он подвесит поток Finalizer, но не сборщик мусора. Это в частности означает, что объекты, не имеющие метода finalize(), будут исправно удаляться, а вот имеющие будут добавляться в очередь, пока поток Finalizer не освободится, не завершится приложение или не кончится память. То же самое применимо и выброшенным в процессе finalize() исключениям: метод runFinalizer() у потока Finalizer игнорирует все исключения выброшенные в момент выполнения finalize(). Таким образом возникновение исключительной ситуации никак не скажется на работоспособности сборщика мусора.
Чем отличаются final, finally и finalize()?	Модификатор final: - Класс не может иметь наследников; - Метод не может быть переопределен в классах наследниках; - Поле не может изменить свое значение после инициализации; - Локальные переменные не могут быть изменены после присвоения им значения; - Параметры методов не могут изменять своё значение внутри метода.  Оператор finally гарантирует, что определенный в нём участок кода будет выполнен независимо от того, какие исключения были возбуждены и перехвачены в блоке try-catch. Метод finalize() вызывается перед тем как сборщик мусора будет проводить удаление объекта.
Расскажите про приведение типов. Что такое понижение и повышение типа?	Java является строго типизированным языком программирования, а это означает, то что каждое выражение и каждая переменная имеет строго определенный тип уже на момент компиляции. Однако определен механизм приведения типов (casting) - способ преобразования значения переменной одного типа в значение другого типа.  В Java существуют несколько разновидностей приведения: - Тождественное (identity). Преобразование выражения любого типа к точно такому же типу всегда допустимо и происходит автоматически. - Расширение (повышение, upcasting) примитивного типа (widening primitive). Означает, что осуществляется переход от менее емкого типа к более ёмкому. Например, от типа byte (длина 1 байт) к типу int (длина 4 байта). Такие преобразование безопасны в том смысле, что новый тип всегда гарантировано вмещает в себя все данные, которые хранились в старом типе и таким образом не происходит потери данных. Этот тип приведения всегда допустим и происходит автоматически. - Сужение (понижение, downcasting) примитивного типа (narrowing primitive). Означает, что переход осуществляется от более емкого типа к менее емкому. При таком преобразовании есть риск потерять данные. Например, если число типа int было больше 127, то при приведении его к byte значения битов старше восьмого будут потеряны. В Java такое преобразование должно совершаться явным образом, при этом все старшие биты, не умещающиеся в новом типе, просто отбрасываются - никакого округления или других действий для получения более корректного результата не производится. - Расширение объектного типа (widening reference). Означает неявное восходящее приведение типов или переход от более конкретного типа к менее конкретному, т.е. переход от потомка к предку. Разрешено всегда и происходит автоматически. - Сужение объектного типа (narrowing reference). Означает нисходящее приведение, то есть приведение от предка к потомку (подтипу). Возможно только если исходная переменная является подтипом приводимого типа. При несоответствии типов в момент выполнения выбрасывается исключение ClassCastException. Требует явного указания типа. - Преобразование к строке (to String). Любой тип может быть приведен к строке, т.е. к экземпляру класса String. - Запрещенные преобразования (forbidden). Не все приведения между произвольными типами допустимы. Например, к запрещенным преобразованиям относятся приведения от любого ссылочного типа к примитивному и наоборот (кроме преобразования к строке). Кроме того, невозможно привести друг к другу классы, находящиеся на разных ветвях дерева наследования и т.п.  При приведении ссылочных типов с самим объектом ничего не происходит, - меняется лишь тип ссылки, через которую происходит обращение к объекту. Для проверки возможности приведения нужно воспользоваться оператором instanceof: Parent parent = new Child();  if (parent instanceof Child) {   Child child = (Child) parent;  }
Когда в приложении может быть выброшено исключение ClassCastException?	ClassCastException (потомок RuntimeException) - исключение, которое будет выброшено при ошибке приведения типа.
Что такое литералы?	Литералы это явно заданные значения в коде программы — константы определенного типа, которые находятся в коде в момент запуска.Литералы бывают разных типов, которые определяются их назначением и способом написания.
Что такое autoboxing («автоупаковка») в Java и каковы правила упаковки примитивных типов в классы-обертки?	Автоупаковка - это механизм неявной инициализации объектов классов-оберток (Byte, Short, Integer, Long, Float, Double, Character, Boolean) значениями соответствующих им исходных примитивных типов (byte, short, int...), без явного использования конструктора класса. - Автоупаковка происходит при прямом присваивании примитива классу-обертке (с помощью оператора =), либо при передаче примитива в параметры метода (типа класса-обертки). - Автоупаковке в классы-обертки могут быть подвергнуты как переменные примитивных типов, так и константы времени компиляции (литералы и final-примитивы). При этом литералы должны быть синтаксически корректными для инициализации переменной исходного примитивного типа. - Автоупаковка переменных примитивных типов требует точного соответствия типа исходного примитива типу класса-обертки. Например, попытка упаковать переменную типа byte в Short, без предварительного явного приведения byte в short вызовет ошибку компиляции. - Автоупаковка констант примитивных типов допускает более широкие границы соответствия. В этом случае компилятор способен предварительно осуществлять  -- неявное расширение/сужение типа примитивов: неявное расширение/сужение исходного типа примитива до типа примитива, соответствующего классу-обертке (для преобразования int в Byte, сначала компилятор самостоятельно неявно сужает int к byte) -- автоупаковку примитива в соответствующий класс-обертку. Однако, в этом случае существуют два дополнительных ограничения: a) присвоение примитива обертке может производится только оператором = (нельзя передать такой примитив в параметры метода без явного приведения типов) b) тип левого операнда не должен быть старше чем Character, тип правого не должен старше, чем int: допустимо расширение/сужение byte в/из short, byte в/из char, short в/из char и только сужение byte из int, short из int, char из int. Все остальные варианты требуют явного приведения типов).  Дополнительной особенностью целочисленных классов-оберток, созданных автоупаковкой констант в диапазоне -128 ... +127 является то, что они кэшируются JVM. Поэтому такие обертки с одинаковыми значениями будут являться ссылками на один объект.
Что такое класс Object? Какие в нем есть методы?	Object это базовый класс для всех остальных объектов в Java. Любой класс наследуется от Object и, соответственно, наследуют его методы: public boolean equals(Object obj) - служит для сравнения объектов по значению; int hashCode() - возвращает hash код для объекта; String toString() - возвращает строковое представление объекта; Class getClass() - возвращает класс объекта во время выполнения; protected Object clone() - создает и возвращает копию объекта; void notify() - возобновляет поток, ожидающий монитор; void notifyAll() - возобновляет все потоки, ожидающие монитор; void wait() - остановка вызвавшего метод потока до момента пока другой поток не вызовет метод notify() или notifyAll() для этого объекта; void wait(long timeout) - остановка вызвавшего метод потока на определённое время или пока другой поток не вызовет метод notify() или notifyAll() для этого объекта; void wait(long timeout, int nanos) - остановка вызвавшего метод потока на определённое время или пока другой поток не вызовет метод notify() или notifyAll() для этого объекта; protected void finalize() - может вызываться сборщиком мусора в момент удаления объекта при сборке мусора.
Дайте определение понятию «конструктор».	Конструктор это специальный метод, у которого отсутствует возвращаемый тип и который имеет то же имя, что и класс, в котором он используется. Конструктор вызывается при создании нового объекта класса и определяет действия необходимые для его инициализации.
Что такое «конструктор по умолчанию»?	Если у какого-либо класса не определить конструктор, то компилятор сгенерирует конструктор без аргументов - так называемый «конструктор по умолчанию». public class ClassName() {} Если у класса уже определен какой-либо конструктор, то конструктор по умолчанию создан не будет и, если он необходим, его нужно описывать явно.
Чем отличаются конструктор по-умолчанию, конструктор копирования и конструктор с параметрами?	У конструктора по умолчанию отсутствуют какие-либо аргументы. Конструктор копирования принимает в качестве аргумента уже существующий объект класса для последующего создания его клона. Конструктор с параметрами имеет в своей сигнатуре аргументы (обычно необходимые для инициализации полей класса).
Где и как вы можете использовать приватный конструктор?	Приватный (помеченный ключевым словом private, скрытый) конструктор может использоваться публичным статическим методом генерации объектов данного класса. Также доступ к нему разрешён вложенным классам и может использоваться для их нужд.
Расскажите про классы-загрузчики и про динамическую загрузку классов.	Основа работы с классами в Java — классы-загрузчики, обычные Java-объекты, предоставляющие интерфейс для поиска и создания объекта класса по его имени во время работы приложения. В начале работы программы создается 3 основных загрузчика классов: - базовый загрузчик (bootstrap/primordial). Загружает основные системные и внутренние классы JDK (Core API - пакеты java.* (rt.jar и i18n.jar) . Важно заметить, что базовый - загрузчик является «Изначальным» или «Корневым» и частью JVM, вследствие чего его нельзя создать внутри кода программы. - загрузчик расширений (extention). Загружает различные пакеты расширений, которые располагаются в директории <JAVA_HOME>/lib/ext или другой директории, описанной в системном параметре java.ext.dirs. Это позволяет обновлять и добавлять новые расширения без необходимости модифицировать настройки используемых приложений. Загрузчик расширений реализован классом sun.misc.Launcher$ExtClassLoader. - системный загрузчик (system/application). Загружает классы, пути к которым указаны в переменной окружения CLASSPATH или пути, которые указаны в командной строке запуска JVM после ключей -classpath или -cp. Системный загрузчик реализован классом sun.misc.Launcher$AppClassLoader.  Загрузчики классов являются иерархическими: каждый из них (кроме базового) имеет родительский загрузчик и в большинстве случаев, перед тем как попробовать загрузить класс самостоятельно, он посылает вначале запрос родительскому загрузчику загрузить указанный класс. Такое делегирование позволяет загружать классы тем загрузчиком, который находится ближе всего к базовому в иерархии делегирования. Как следствие поиск классов будет происходить в источниках в порядке их доверия: сначала в библиотеке Core API, потом в папке расширений, потом в локальных файлах CLASSPATH. Процесс загрузки класса состоит из трех частей: - Loading - на этой фазе происходит поиск и физическая загрузка файла класса в определенном источнике (в зависимости от загрузчика). Этот процесс определяет базовое представление класса в памяти. На этом этапе такие понятия как «методы», «поля» и т.д. пока не известны. - Linking - процесс, который может быть разбит на 3 части: -- Bytecode verification - проверка байт-кода на соответствие требованиям, определенным в спецификации JVM. -- Class preparation - создание и инициализация необходимых структур, используемых для представления полей, методов, реализованных интерфейсов и т.п., определенных в загружаемом классе. -- Resolving - загрузка набора классов, на которые ссылается загружаемый класс. - Initialization - вызов статических блоков инициализации и присваивание полям класса значений по умолчанию.  Динамическая загрузка классов в Java имеет ряд особенностей: - отложенная (lazy) загрузка и связывание классов. Загрузка классов производится только при необходимости, что позволяет экономить ресурсы и распределять нагрузку. - проверка корректности загружаемого кода (type safeness). Все действия связанные с контролем использования типов производятся только во время загрузки класса, позволяя избежать дополнительной нагрузки во время выполнения кода. - программируемая загрузка. Пользовательский загрузчик полностью контролирует процесс получения запрошенного класса — самому ли искать байт-код и создавать класс или делегировать создание другому загрузчику. Дополнительно существует возможность выставлять различные атрибуты безопасности для загружаемых классов, позволяя таким образом работать с кодом из ненадежных источников. - множественные пространства имен. Каждый загрузчик имеет своё пространство имён для создаваемых классов. Соответственно, классы, загруженные двумя различными загрузчиками на основе общего байт-кода, в системе будут различаться.  Существует несколько способов инициировать загрузку требуемого класса: - явный: вызов ClassLoader.loadClass() или Class.forName() (по умолчанию используется загрузчик, создавший текущий класс, но есть возможность и явного указания загрузчика); - неявный: когда для дальнейшей работы приложения требуется ранее не использованный класс, JVM инициирует его загрузку.
Что такое Reflection?	Рефлексия (Reflection) - это механизм получения данных о программе во время её выполнения (runtime). В Java Reflection осуществляется с помощью Java Reflection API, состоящего из классов пакетов java.lang и java.lang.reflect.  Возможности Java Reflection API: - Определение класса объекта; - Получение информации о модификаторах класса, полях, методах, конструкторах и суперклассах; - Определение интерфейсов, реализуемых классом; - Создание экземпляра класса; - Получение и установка значений полей объекта; - Вызов методов объекта; - Создание нового массива.
Зачем нужен equals(). Чем он отличается от операции ==?	Метод equals() - определяет отношение эквивалентности объектов. При сравнении объектов с помощью == сравнение происходит лишь между ссылками. При сравнении по переопределённому разработчиком equals() - по внутреннему состоянию объекто
Если вы хотите переопределить equals(), какие условия должны выполняться?	Метод equals() обозначает отношение эквивалентности объектов. Эквивалентным называется отношение, которое является симметричным, транзитивным и рефлексивным. Рефлексивность: для любого ненулевого x, x.equals(x) вернет true; Транзитивность: для любого ненулевого x, y и z, если x.equals(y) и y.equals(z) вернет true, тогда и x.equals(z) вернет true; Симметричность: для любого ненулевого x и y, x.equals(y) должно вернуть true, тогда и только тогда, когда y.equals(x) вернет true. Также для любого ненулевого x, x.equals(null) должно вернуть false.
Какими свойствами обладает порождаемое equals() отношение эквивалентности?	- Рефлексивность: для любой ссылки на значение x, x.equals(x) вернет true; - Симметричность: для любых ссылок на значения x и y, x.equals(y) должно вернуть true, тогда и только тогда, когда y.equals(x) возвращает true. - Транзитивность: для любых ссылок на значения x, y и z, если x.equals(y) и y.equals(z) возвращают true, тогда и x.equals(z) вернёт true; - Непротиворечивость: для любых ссылок на значения х и у, если несколько раз вызвать х.equals(y), постоянно будет возвращаться значение true либо постоянно будет возвращаться значение false при условии, что никакая информация, используемая при сравнении объектов, не поменялась.  Для любой ненулевой ссылки на значение х выражение х.equals(null) должно возвращать false.
Правила переопределения метода Object.equals().	 Использование оператора == для проверки, является ли аргумент ссылкой на указанный объект. Если является, возвращается true. Если сравниваемый объект == null, должно вернуться false. 2)Использование оператор instanceof и вызова метода getClass() для проверки, имеет ли аргумент правильный тип. Если не имеет, возвращается false.Приведение аргумента к правильному типу. Поскольку эта операция следует за проверкой instanceof она гарантированно будет выполнена. 4)Обход всех значимых полей класса и проверка того, что значение поля в текущем объекте и значение того же поля в проверяемом на эквивалентность аргументе соответствуют друг другу. Если проверки для всех полей прошли успешно, возвращается результат true, в противном случае - false.  По окончанию переопределения метода equals() следует проверить: является ли порождаемое отношение эквивалентности рефлексивным, симметричным, транзитивным и непротиворечивым? Если ответ отрицательный, метод подлежит соответствующей правке.
Какая связь между hashCode() и equals()?	Равные объекты должны возвращать одинаковые хэш коды. При переопределении equals() нужно обязательно переопределять и метод hashCode().
Что будет, если переопределить equals() не переопределяя hashCode()? Какие могут возникнуть проблемы?	Классы и методы, которые используют правила этого контракта могут работать некорректно. Так для HashMap это может привести к тому, что пара «ключ-значение», которая была в неё помещена при использовании нового экземпляра ключа не будет в ней найдена.
Каким образом реализованы методы hashCode() и equals() в классе Object?	Реализация метода Object.equals() сводится к проверке на равенство двух ссылок: public boolean equals(Object obj)  {   return (this == obj);  }  Реализация метода Object.hashCode() описана как native, т.е. определенной не с помощью Java кода и обычно возвращает адрес объекта в памяти: public native int hashCode();
Для чего нужен метод hashCode()?	Метод hashCode() необходим для вычисления хэш кода переданного в качестве входного параметра объекта. В Java это целое число, в более широком смысле - битовая строка фиксированной длины, полученная из массива произвольной длины. Этот метод реализован таким образом, что для одного и того же входного объекта, хэш код всегда будет одинаковым. Следует понимать, что в Java множество возможных хэш кодов ограничено типом int, а множество объектов ничем не ограничено. Из-за этого, вполне возможна ситуация, что хэш коды разных объектов могут совпасть: - если хэш коды разные, то и объекты гарантированно разные; - если хэш коды равны, то объекты могут не обязательно равны.
Каковы правила переопределения метода Object.hashCode()?	Общий совет: выбирать поля, которые с большой долью вероятности будут различаться. Для этого необходимо использовать уникальные, лучше всего примитивные поля, например, такие как id, uuid. При этом нужно следовать правилу, если поля задействованы при вычислении hashCode(), то они должны быть задействованы и при выполнении equals().
Могут ли у разных объектов быть одинаковые hashCode()?	Да, могут. Метод hashCode() не гарантирует уникальность возвращаемого значения. Ситуация, когда у разных объектов одинаковые хэш коды называется коллизией. Вероятность возникновения коллизии зависит от используемого алгоритма генерации хэш кода.
Если у класса Point{int x, y;} реализовать метод equals(Object that) {(return this.x == that.x && this.y == that.y)}, но сделать хэш код в виде int hashCode() {return x;}, то будут ли корректно такие точки помещаться и извлекаться из HashSet?	HashSet использует HashMap для хранения элементов. При добавлении элемента в HashMap вычисляется хэш код, по которому определяется позиция в массиве, куда будет вставлен новый элемент. У всех экземпляров класса Point хэш код будет одинаковым для всех объектов с одинаковым x, что приведёт к вырождению хэш таблицы в список. При возникновении коллизии в HashMap осуществляется проверка на наличие элемента в списке: e.hash == hash && ((k = e.key) == key || key.equals(k)). Если элемент найден, то его значение перезаписывается. В нашем случае для разных объектов метод equals() будет возвращать false. Соответственно новый элемент будет успешно добавлен в HashSet. Извлечение элемента также будет осуществляться успешно. Но производительность такого кода будет невысокой и преимущества хэш таблиц использоваться не будут.
Могут ли у разных объектов (ref0 != ref1) быть ref0.equals(ref1) == true?	Да, могут. Для этого в классе этих объектов должен быть переопределен метод equals(). Если используется метод Object.equals(), то для двух ссылок x и y метод вернет true тогда и только тогда, когда обе ссылки указывают на один и тот же объект (т.е. x == y возвращает true).
Могут ли у разных ссылок на один объект (ref0 == ref1) быть ref0.equals(ref1) == false?	В общем случае - могут, если метод equals() реализован некорректно и не выполняет свойство рефлексивности: для любых ненулевых ссылок x метод x.equals(x) должен возвращать true.
Можно ли так реализовать метод equals(Object that) {return this.hashCode() == that.hashCode()}?	Строго говоря нельзя, поскольку метод hashCode() не гарантирует уникальность значения для каждого объекта. Однако для сравнения экземпляров класса Object такой код допустим, т.к. метод hashCode() в классе Object возвращает уникальные значения для разных объектов (его вычисление основано на использовании адреса объекта в памяти).
В equals() требуется проверять, что аргумент equals(Object that) такого же типа что и сам объект. В чем разница между this.getClass() == that.getClass() и that instanceof MyClass?	Оператор instanceof сравнивает объект и указанный тип. Его можно использовать для проверки является ли данный объект экземпляром некоторого класса, либо экземпляром его дочернего класса, либо экземпляром класса, который реализует указанный интерфейс. this.getClass() == that.getClass() проверяет два класса на идентичность, поэтому для корректной реализации контракта метода equals() необходимо использовать точное сравнение с помощью метода getClass().
Можно ли реализовать метод equals() класса MyClass вот так: class MyClass {public boolean equals(MyClass that) {return this == that;}}?	Реализовать можно, но данный метод не переопределяет метод equals() класса Object, а перегружает его
Есть класс Point{int x, y;}. Почему хэш код в виде 31 * x + y предпочтительнее чем x + y?	Множитель создает зависимость значения хэш кода от очередности обработки полей, что в итоге порождает лучшую хэш функцию.
Расскажите про клонирование объектов.	Использование оператора присваивания не создает нового объекта, а лишь копирует ссылку на объект. Таким образом, две ссылки указывают на одну и ту же область памяти, на один и тот же объект. Для создания нового объекта с таким же состоянием используется клонирование объекта. Класс Object содержит protected метод clone(), осуществляющий побитовое копирование объекта производного класса. Однако сначала необходимо переопределить метод clone() как public для обеспечения возможности его вызова. В переопределенном методе следует вызвать базовую версию метода super.clone(), которая и выполняет собственно клонирование. Чтобы окончательно сделать объект клонируемым, класс должен реализовать интерфейс Cloneable. Интерфейс Cloneable не содержит методов относится к маркерным интерфейсам, а его реализация гарантирует, что метод clone() класса Object возвратит точную копию вызвавшего его объекта с воспроизведением значений всех его полей. В противном случае метод генерирует исключение CloneNotSupportedException. Следует отметить, что при использовании этого механизма объект создается без вызова конструктора. Это решение эффективно только в случае, если поля клонируемого объекта представляют собой значения базовых типов и их обёрток или неизменяемых (immutable) объектных типов. Если же поле клонируемого типа является изменяемым ссылочным типом, то для корректного клонирования требуется другой подход. Причина заключается в том, что при создании копии поля оригинал и копия представляют собой ссылку на один и тот же объект. В этой ситуации следует также клонировать и сам объект поля класса. Такое клонирование возможно только в случае, если тип атрибута класса также реализует интерфейс Cloneable и переопределяет метод clone(). Так как, если это будет иначе вызов метода невозможен из-за его недоступности. Отсюда следует, что если класс имеет суперкласс, то для реализации механизма клонирования текущего класса-потомка необходимо наличие корректной реализации такого механизма в суперклассе. При этом следует отказаться от использования объявлений final для полей объектных типов по причине невозможности изменения их значений при реализации клонирования.  Помимо встроенного механизма клонирования в Java для клонирования объекта можно использовать: - Специализированный конструктор копирования - в классе описывается конструктор, который принимает объект этого же класса и инициализирует поля создаваемого объекта значениями полей переданного. - Фабричный метод - (Factory method), который представляет собой статический метод, возвращающий экземпляр своего класса. - Механизм сериализации - сохранение и последующее восстановление объекта в/из потока байтов.
В чем отличие между поверхностным и глубоким клонированием?	Поверхностное копирование копирует настолько малую часть информации об объекте, насколько это возможно. По умолчанию, клонирование в Java является поверхностным, т.е. класс Object не знает о структуре класса, которого он копирует. Клонирование такого типа осуществляется JVM по следующим правилам: - Если класс имеет только члены примитивных типов, то будет создана совершенно новая копия объекта и возвращена ссылка на этот объект. - Если класс помимо членов примитивных типов содержит члены ссылочных типов, то тогда копируются ссылки на объекты этих классов. Следовательно, оба объекта будут иметь одинаковые ссылки. Глубокое копирование дублирует абсолютно всю информацию объекта: - Нет необходимости копировать отдельно примитивные данные; - Все члены ссылочного типа в оригинальном классе должны поддерживать клонирование. Для каждого такого члена при переопределении метода clone() должен вызываться super.clone(); - Если какой-либо член класса не поддерживает клонирование, то в методе клонирования необходимо создать новый экземпляр этого класса и скопировать каждый его член со всеми атрибутами в новый объект класса, по одному.
Какой способ клонирования предпочтительней?	Наиболее безопасным и, следовательно, предпочтительным способом клонирования является использование специализированного конструктора копирования: - Отсутствие ошибок наследования (не нужно беспокоиться, что у наследников появятся новые поля, которые не будут склонированы через метод clone()); - Поля для клонирования указываются явно; - Возможность клонировать даже final поля.
Почему метод clone() объявлен в классе Object, а не в интерфейсе Cloneable?	Метод clone() объявлен в классе Object с указанием модификатора native, чтобы обеспечить доступ к стандартному механизму поверхностного копирования объектов. Одновременно он объявлен и как protected, чтобы нельзя было вызвать этот метод у не переопределивших его объектов. Непосредственно интерфейс Cloneable является маркерным (не содержит объявлений методов) и нужен только для обозначения самого факта, что данный объект готов к тому, чтобы быть клонированным. Вызов переопределённого метода clone() у не Cloneable объекта вызовет выбрасывание CloneNotSupportedException.
Может ли метод main() выбросить исключение во вне и если да, то где будет происходить обработка данного исключения?	Может и оно будет передано в виртуальную машину Java (JVM).
Что такое generics?	Generics - это технический термин, обозначающий набор свойств языка позволяющих определять и использовать обобщенные типы и методы. Обобщенные типы или методы отличаются от обычных тем, что имеют типизированные параметры. Примером использования обобщенных типов может служить Java Collection Framework. Так, класс LinkedList<E> - типичный обобщенный тип. Он содержит параметр E, который представляет тип элементов, которые будут храниться в коллекции. Создание объектов обобщенных типов происходит посредством замены параметризированных типов реальными типами данных. Вместо того, чтобы просто использовать LinkedList, ничего не говоря о типе элемента в списке, предлагается использовать точное указание типа LinkedList<String>, LinkedList<Integer> и т.п.
Что такое «интернационализация», «локализация»?	Интернационализация (internationalization) - способ создания приложений, при котором их можно легко адаптировать для разных аудиторий, говорящих на разных языках.  Локализация (localization) - адаптация интерфейса приложения под несколько языков. Добавление нового языка может внести определенные сложности в локализацию интерфейса.
Что такое Аннотации в Java?	Аннотации - это своего рода метатеги, которые добавляются к коду и применяются к объявлению пакетов, классов, конструкторов, методов, полей, параметров и локальных переменных. Аннотации всегда обладают некоторой информацией и связывают эти "дополнительные данные" и все перечисленные конструкции языка. Фактически аннотации представляют собой их дополнительные модификаторы, применение которых не влечет за собой изменений ранее созданного кода.
Какие функции выполняет Аннотации?	выполняет следующие функции: дает необходимую информацию для компилятора; дает информацию различным инструментам для генерации другого кода, конфигураций и т. д.; может использоваться во время работы кода; Самая часто встречаемая аннотация, которую встречал любой программист, даже начинающий это @Override.
Какие встроенные аннотации в Java вы знаете?	В языке Java SE определено несколько встроенных аннотаций, большинство из их являются специализированными. Четыре типа @Retention, @Documented, @Target и @Inherited - из пакета java.lang.annotation. Из оставшиеся выделяются - @Override, @Deprecated, @SafeVarargs и @SuppressWarnings - из пакета java.lang. Широкое использование аннотаций в различных технологиях и фреймворках обуславливается возможностью сокращения кода и снижения его связанности.
Что делают аннотации @Retention, @Documented, @Target и @Inherited?	Эти аннотации, имеют следующее значение: @Retention - эта аннотация предназначена для применения только в качестве аннотации к другим аннотациям, позволяет указать жизненный цикл аннотации: будет она присутствовать только в исходном коде, в скомпилированном файле, или она будет также видна и в процессе выполнения. Выбор нужного типа зависит от того, как вы хотите использовать аннотацию. @Documented - это маркер-интерфейс, который сообщает инструменту, что аннотация должна быть документирована. @Target - эта аннотация задает тип объявления, к которым может быть применима аннотация. Принимает один аргумент, который должен быть константой из перечисления ElementType, это может быть поле, метод, тип и т.д. Например, чтобы указать, что аннотация применима только к полям и локальным переменным: @Targer({ ElementType.FIELD, ElementTyle.LOCAL_VARIABLE } ) @Inherited - это аннотация-маркер, которая может применяться в другом объявление аннотации, она касается только тех аннотаций, что будут использованы в объявлениях классов. Эта аннотация позволяет аннотации супер класса быть унаследованной в подклассе.
Что делают аннотации @Override, @Deprecated, @SafeVarargs и @SuppressWarnings?	Эти аннотации предназначены для: @Override - аннотация-маркер, которая может применяться только к методам. Метод, аннотированный как @Override, должен переопределять метод супер класса. @Deprecated - указывает, что объявление устарело и должно быть заменено более новой формой. @SafeVarargs - аннотация-маркер, применяется к методам и конструкторам. Она указывает, что никакие небезопасные действия, связанные с параметром переменного количества аргументов, недопустимы. Применяется только к методам и конструкторам с переменным количеством аргументов, которые объявлены как static или final. @SuppressWarnings - эта аннотация указывает, что одно или более предупреждений, которые могут быть выданы компилятором следует подавить.
Какой жизненный цикл аннотации можно указать с помощью @Retention?	Существует 3 возможные варианты чтобы указать где аннотация будет жить. Они инкапсулированы в перечисление java.lang.annotation.RetentionPolicy. Это SOURSE, CLASS, RUNTIME. SOURCE - содержаться только в исходном файле и отбрасываются при компиляции. CLASS - сохраняются в файле, однако они недоступны JVM во время выполнения. RUNTIME - сохраняются в файле во время компиляции и остаются доступными JVM во время выполнения.
К каким элементам можно применять аннотацию, как это указать?	Для того чтобы ограничить использование аннотации её нужно проаннотировать. Для этого существует аннотация @Target. @Target(ElementType.PACKAGE) - только для пакетов; @Target(ElementType.TYPE) - только для классов; @Target(ElementType.CONSTRUCTOR) - только для конструкторов; @Target(ElementType.METHOD) - только для методов; @Target(ElementType.FIELD) - только для атрибутов(переменных) класса; @Target(ElementType.PARAMATER) - только для параметров метода; @Target(ElementType.LOCAL_VARIABLE) - только для локальных переменных. В случае если вы хотите, что бы ваша аннотация использовалась больше чем для одного типа параметров, то можно указать @Target следующим образом:  @Target({ ElementType. PARAMETER, ElementType. LOCAL_VARIABLE  тут мы говорим, аннотацию можно использовать только для параметров метода и для локальных переменных.
Как создать свою Аннотацию?	Написать свою аннотацию не так сложно, как могло бы казаться. В следующем коде приведено объявление аннотации.  public @interface About{ String info() default } как вы видите на месте где обычно пишут class или interface у нас написано @interface. Структура практически та же, что и у интерфейсов, только пишется @interface. @interface - указывает на то, что это аннотация default - говорит про то, что метод по умолчанию будет возвращать определённое значение. готова теперь ею можно пользоваться, также аннотацию можно сконфигурировать.
Атрибуты каких типов допустимы в аннотациях?	Атрибуты могут иметь только следующие типы: String Class или «any parameterized invocation of Class» enum annotation массив элементов любого из вышеперечисленных типов Последний пункт надо понимать как то, что допустимы только одномерные массивы.
Что такое JMX?	Управленческие расширения Java (Java Management Extensions, JMX) - API при помощи которого можно контролировать работу приложений и управлять различными параметрами удаленно в реальном времени. Причем управлять можно фактически чем угодно - лишь бы это было написано на Java. Это может быть микро-устройство типа считывателя отпечатка или система, включающая тысячи машин, каждая из которых предоставляет определенные сервисы. Данные ресурсы представляются MBean-объектами (управляемый Java Bean). JMX вошла в поставку Java начиная с версии 5.
Какие выгоды предлагает JMX?	Вот как эти выгоды описывает Sun Простота реализации. Архитектура JMX основана на понятии "сервера управляемых объектов" который выступает как управляющий агент и может быть запущен на многих устройствах/компьютерах, которые поддерживают JAVA. Масштабируемость. Службы агентов JXM являются независимыми и могут быть встроены наподобие plug-in'ов в агента JMX. Компонентно-основанаая система позволяет создавать масштабируемые решения от крохотных устройств до очень крупных систем. Возможность расширять концепцию в будущем. JMX позволяет создавать гибкие решения. Например, JMX позволяет создавать удобные решения, которые могут находить различные сервисы. Концентрация на управлении. JMX предоставляет сервися, разработанные для работы в распределенных средах и его API спроектировано для решений, которые управляют приложениями, сетями, сервисами и т.д.
Что еще умеет JMX кроме дистанционного управления?	JMX делает гораздо больше, чем просто предоставляет рабочую оболочку для дистанционного управления. Она обеспечивает дополнительные услуги (services), способные занять ключевое место в процессе разработки. Приведу лишь краткое описание: Event notification: Интерфейсы оповещают исполнителей и слушателей о событиях типа изменения атрибута, что позволяет MBean-компонентам общаться с другими MBean-компонентами или удалённым "командным пунктом" и докладывать об изменениях своего состояния Monitor service: Monitor MBeans может посылать уведомления о событиях зарегистрированным слушателям. Слушателем может выступать другой MBean или управляющее приложение. В качестве основных атрибутов, для которых используется данное свойство, являются counter, gauge или string. Timer service: Timer MBean будет посылать уведомления зарегистрированным слушателям, с учётом определённого числа или временного промежутка. M-let service: М-let service может создавать и регистрировать экземпляры MBean-серверов. Список MBean-компонентов и имён из классов определяются в m-let-файле с помощью MLET -меток. URL указывает на месторасположения m-let-файла.
Что такое MBean?	MBeans - это Java-объекты, которые реализуют определенный интерфейс. Интерфейс включает: некие величины, которые могут быть доступны; операции, которые могут быть вызваны; извещения, которые могут быть посланы; конструкторы.
Какие типы MBeans существуют?	Существует 4 типа MBeans: Standard MBeans. Самые простые бины. Их управляющий интерфейс определяется набором методов Dynamic MBeans. Они реализуют специализированный интерфейс, который делают доступным во время исполнения. Open MBeans. Это Dynamic MBeans, которые используют только основные типы данных для универсального управления. Model MBeans. Это Dynamic MBeans, которые полностью конфигурируемы и могут показать свое описание во время исполнения (нечто вроде Reflection)
Что такое MBean Server?	MBean Server - это реестр объектов, которые используются для управления. Любой объект зарегистрированный на сервере становится доступным для приложений. Надо отметить, что сервер публикует только интерфейсы и не дает прямых ссылок на объекты. Любые ресурсы, которыми вы хотите управлять должны быть зарегистрированы на сервере как MBean. Сервер предоставляет стандартный интерфейс для доступа к MBean. Интересно, что регистрировать MBean может любой другой MBean, сам агент или удаленное приложение через распределенные сервисы. Когда вы регистрируете MBean вы должны дать ему уникальное имя, которое будет использовано для обращения к даному объекту.
Какие механизмы обеспечивают безопасность в технологии Java?	В технологии Java безопасность обеспечивают следующие три механизма: структурные функциональные возможности языка (например, проверка границ массивов, запрет на преобразования непроверенных типов, отсутствие указателей и т.д.). средства контроля доступа, определяющие действия, которые разрешается или запрещается выполнять в коде (например, может ли код получать доступ к файлам, передавать данные по сети и т.д.). механизм цифровой подписи, предоставляющий авторам возможность применять стандартные алгоритмы для аутентификации своих программ, а пользователям - точно определять, кто создал код и изменился ли он с момента его подписания.
Назовите несколько видов проверок которые выполняет верификатор байт-кода Java?	Ниже приведены некоторые виды проверок, выполняемых верификатором.  инициализация переменных перед их использованием.  согласование типов ссылок при вызове метода.  соблюдение правил доступа к закрытым данным и методам.  доступ к локальным переменным в стеке во время выполнения.  отсутствие переполнения стека.  При невыполнении какой-нибудь из этих проверок класс считается поврежденным и загружаться не будет.
Что вы знаете о "диспетчере защиты" в Java?	В качестве диспетчера защиты служит класс, определяющий, разрешено ли коду выполнять ту или иную операцию. Ниже перечислены операции, подпадающие под контроль диспетчера защиты. Существует немало других проверок, выполняемых диспетчером защиты в библиотеке Java.  создание нового загрузчика классов. выход из виртуальной машины. получение доступа к члену другого класса с помощью рефлексии. получение доступа к файлу. установление соединения через сокет. запуск задания на печать. получение доступа к системному буферу обмена. получение доступа к очереди событий в AWT. обращение к окну верхнего уровня.
Что такое JAAS?	JAAS (Java Authentication and Authorization Service - служба аутентификации и авторизации Java ) - служба JAAS, по существу, представляет собой встраиваемый прикладной интерфейс API, отделяющий прикладные программы на Java от конкретной технологии, применяемой для реализации средств аутентификации. Помимо прочего, эта служба поддерживает механизмы регистрации в UNIX и NT, механизм аутентификации Kerberos и механизмы аутентификации по сертификатам. После аутентификации за пользователем может быть закреплен определенный набор полномочий. Входит в состав платформы Java начиная с версии Java SE 1.4.
Что такое Рефакторинг?	Рефакторинг - процесс изменения внутренней структуры программы, не затрагивающий её внешнего поведения и имеющий целью облегчить понимание её работы. В основе рефакторинга лежит последовательность небольших эквивалентных (то есть сохраняющих поведение) преобразований..
Имеет ли смысл объявлять метод private final?	Нет, такой метод и так не виден для наследников, а значит не может быть ими переопределен.
Какие примитивы есть в Java?	«Пустой» тип - void. Логический (булевый) тип. bolean - 1 бит  Целы числа byte - 8 бит short - 16 бит int - 32 бита long - 64 бита  Числа с плавающей запятой.  float - 32 бита double - 64 бита  Символы - для хранения литералов.  char - 16 бит
В чём разница между intrinsic и native методами?	Методы, помеченные модификатором native, реализованны на нативном языке платофрмы (например, C++). Например, Object.hashCode. Intrinsic-методы, у которых нет модификатора native, но которые во время исполнения заменяются нативной реализацией. Например, String.equals. Т.е. скорость работы этого метода будет отличаться в ситуациях, когда вы вызываете его через API или скопируете реализацию в собственный метод. Начиная с 9-ой версии в HotSpot JVM существует аннотация @HotSpotIntrinsicCandidate для метода(или конструктора), которая указыает, что аннотируемый метод может (но гарантий в этом нет) стать intrinsic-методом в будущем.
Что значит ключевое слово var?	Ключево слово var, введённо в Java 10, избавляет от указания типа локальной переменной (local-variable type inference). Пример. Выражение int i = 0 эквивалентно var i = 0;. При объяевления коллекций читаемость кода повышается var list = new ArrayList<Objet>(); Но, с другой стороны, при объявлении generics нельзя будет использовать сокращённый вариант без указания типа - <...>. В случаях, когда тип переменной не очевиден компилятору, будет выдана ошибка error: cannot infer type for local variable ....
Что такое Metaspace?	В Metaspa ceвиртуальная машина хранит метаданные загруженных классов. Также здесь находятся всё статическое содержимое приложения, переменные примитивных типов и ссылки на статические объекты. Более того Metaspace хранит данные о байткоде и JIT информацию.  В результате появления Metaspace, процесс очистки памяти получил некоторые преимущества. Теперь сборщик мусора автоматически удаляет из памяти ненужные классы, когда емкость, выделенная для хранения метаданных, достигает максимального значения. Вместе с этим, уменьшилась вероятность получения ошибки OutOfMemoryError. Несмотря на все плюсы, нам все равно необходимо контролировать и, при необходимости, настраивать Metaspace чтобы избежать утечек памяти.
Какие алгоритмы сортировки массивов используются в Java?	Версия | Array.sort(primitives) | Array.sort(objects) Java ...-6 | Quicksort | MergerSort Java 7-... | DualPivotQuicksort | TimSort
Чем объект отличается от примитивных типов данных?	Первое отличие: количество занимаемой памяти: примитивы занимают очень мало, ведь они содержат лишь собственное значение, в то время как объекты могут содержать очень и очень много различных значений: как примитивов, так и ссылок на другие объекты. Второе отличие: Java —это объектно-ориентированный язык, поэтому в ней все работает через взаимодействие между объектами, и примитивы тут не сильно вписываются (собственно, поэтому Java это не 100% объектно-ориентированный язык). Третье, вытекающее со второго: так как Java ориентирована на взаимодействие между объектами, у этих объектов есть много различных механизмов для управления. Например, конструкторы, методы, исключения (которые работают в первую очередь с объектами), и т.д. Собственно, чтобы примитивы могли как-то ввязаться (работать) в этой объектно ориентированной среде и были придуманы обертки (wrappers) для примитивных типов (Integer, Character, Double, Boolean...)
Что такое bytecode?	Как я и говорил выше, компилятор преобразовывает Java-код в промежуточный — bytecode (файлы с расширением .java в файлы с расширением .class). Байткод во многом похож на машинный код, только он использует набор инструкций не реального процессора, а виртуального. При этом он может включать в себя участки, ориентированные на использование JIT-компилятора, оптимизирующего выполнение команд под реальный процессор, на котором запущена программа. JIT-компиляция, называемая ещё компиляцией на летуэто технология, которая увеличивает производительность программы, использующей байткод, через компиляции байткода в машинный или в другой формат во время работы программы. Как вы могли догадаться, JVM и использует JIT-компилятор, когда запускает байткод.
Что такое класс POJO?	POJO — Plain Old Java Object — старый добрый Java-объект: простой объект, класса, который не унаследован от какого-то специфического класса и не реализует никаких служебных интерфейсов сверх тех, которые нужны для бизнес-модели. Другими словами POJO класс это просто класс без особых требований. Единственное требование — отсутствие различных наворотов, завязанных на определенном фреймворке. Как правило такие классы не наследуют от других классов (кроме классов POJO из того же пакета), не реализуют интерфейсов — иногда делается исключение для маркерных интерфейсов из стандартной библиотеки типа Serializable или Cloneable — не используют аннотаций и не зависят от сторонних библиотек. Но отмечу, что у POJO могут быть и методы с бизнес-логикой, и произвольного вида конструкторы. Если разрешить аннотации, не вносящие изменения в семантику класса (без которых назначение объекта и логика его работы не изменятся), к POJO также можно отнести Entity сущности JPA и объекты DTO, десериализуемые из XML или JSON, правила для которых заданы в аннотациях. Также для POJO классов желательно переопределить equals и hashCode, ведь это может помочь им лучше выполнять свою роль.
Зачем нужны разные типы ссылок в Java?	Сильные, они же обычные, нужны для указания на объекты, которые должны обязательно оставаться в памяти всё то время, что эти ссылки на него существуют. Если не складывается, получите OutOfMemoryError. Мягкие ссылки полезны для кэшей, чувствительных к доступному объёму оперативной памяти. Объекты по ним могут зачиститься, но только в случае необходимости. Например, если нужно насоздавать ещё объектов с сильными ссылками, а уже негде, лучше освободить кэш и замедлить работу, чем уронить процесс напрочь. Слабые ссылки полезны для сопоставления объектов чему-нибудь без удерживания их от зачистки когда они больше не нужны (а-ля Map<Ключ, WeakRef<Значение>>). На возможность зачистки они не влияют вообще никак, слабые ссылки будут очищены при очередном запуске сборщика. Фантомные ссылки возникают, когда объект уже признан мусором, финализирован и находится в процессе зачистки, о чём можно узнать с помощью класса Cleaner и выполнить в это время какие-то собственные действия. Плюс общее правило: политика зачистки для некоего объекта и очистки ссылок на него определяется самыми жёсткими из всех ссылок, что на него указывают.
Что такое generic? Как они реализованы в Java?	Generics это параметризованные типы. С их помощью можно объявлять классы, интерфейсы и методы, где тип данных указан в виде параметра. Обобщения добавили в язык безопасность типов. Пример реализации: class MyClass<T>{  T obj;  public MyClass(T obj) {  this.obj = obj;  }  } class MyClass<T> В угловых скобках используется T — имя параметра типа. Это имя используется в качестве заполнителя, куда будет подставлено имя реального типа, переданного классу MyClass при создании реальных типов. То есть параметр типа T применяется в классе всякий раз, когда требуется параметр типа. Угловые скобки указывают, что параметр может быть обобщен. Сам класс при этом называется обобщенным классом или параметризованным типом. Далее тип T используется для объявления объекта по имени obj: T obj; Вместо T подставится реальный тип, который будет указан при создании объекта класса MyClass. Объект obj будет объектом типа, переданного в параметре типа T. Если в параметре T передать тип String, то экземпляр obj будет иметь тип String. Рассмотрим конструктор MyClass(): public MyClass(T obj){ this.obj = obj; } Параметр obj имеет тип T. Это значит, что реальный тип параметра obj определяется типом, переданным параметром типа T при создании объекта класса MyClass. Параметр типа T также может быть использован для указания типа возвращаемого значения метода. В именах переменных типа принято использовать заглавные буквы. Обычно для коллекций используется буква E, буквами K и V — типы ключей и значение (Key/Value), а буквой T (и при необходимости буквы S и U) — любой тип. Обобщения работают только с объектами. Поэтому нельзя использовать в качестве параметра элементарные типы вроде int или char. *Так же считаю нужным упомянуть generic методы. Это методы вида: модификаторы <T, ...> возвращаемыйТип имяМетода(T t, ...)
Что такое стирание типа?	Важно понимать, что информация об общем типе доступна только компилятору, а не JVM. Другими словами , стирание типа означает, что информация об общем типе недоступна для JVM во время выполнения, а доступна только во время компиляции . Причина выбора основной реализации проста - сохранение обратной совместимости со старыми версиями Java. Когда универсальный код компилируется в байт-код, создается впечатление, что универсального типа никогда не существовало. Это означает, что компиляция будет: Замена универсальных типов объектами Замените ограниченные типы (подробнее об этом в следующем вопросе) первым связанным классом Вставьте эквивалент приведений при извлечении универсальных объектов.
Если универсальный тип опущен при создании экземпляра объекта, будет ли код по-прежнему компилироваться?	Поскольку до Java 5 дженериков не существовало, их можно вообще не использовать. Например, универсальные шаблоны были модернизированы для большинства стандартных классов Java, таких как коллекции. Если мы посмотрим на наш список из первого вопроса, то увидим, что у нас уже есть пример исключения универсального типа: List list = new ArrayList(); Несмотря на возможность компиляции, все же вероятно, что компилятор выдаст предупреждение. Это потому, что мы теряем дополнительную проверку во время компиляции, которую мы получаем от использования дженериков. Следует помнить, что, хотя обратная совместимость и стирание типов позволяют опускать общие типы, это плохая практика.
Чем универсальный метод отличается от универсального типа?	В универсальном методе параметр типа вводится в метод, находящийся в рамках этого метода. Давайте попробуем это на примере:  public static T returnType(T argument) { return argument; }  Мы использовали статический метод, но при желании могли бы использовать и нестатический. Используя вывод типа (описанный в следующем вопросе), мы можем вызывать его, как любой обычный метод, без необходимости указывать какие-либо аргументы типа, когда мы это делаем.
Что такое wildcard?	Wildcard это дженерик вида <?>, что означает, что тип может быть чем угодно. Используется, например, в коллекциях, где для всех коллекций базовым типом является Сollection<?>.
Что такое подстановочные знаки «Неограниченный» и «Неограниченный» в Generics?	Ограниченные подстановочные знаки это те, которые накладывают ограничения на тип. Есть два вида подстановочных знаков <? расширяет T>, что накладывает верхнюю границу, гарантируя, что тип должен быть подклассом T и <? super T> где его наложение нижней границы, гарантируя, что Type должен быть суперклассом T. Этот универсальный тип должен быть создан с помощью Type внутри bound, иначе это приведет к ошибке компиляции. С другой стороны, <?> Представляют и неограниченный тип, потому что <?> Можно заменить любым типом.
В чем разница между списком <? расширяет T> и List <? супер T> ?	Обе декларации List являются примером ограниченных символов подстановки, List <? extends T> будет принимать любой список с типом extending T, а List <? super T> примет любой Список с типом super class из T. Например, List <? extends Number> может принимать список <Integer> или список <Float>.
Как написать универсальный метод, который принимает универсальный аргумент и возвращает универсальный тип?	необработанного типа вам нужно использовать универсальный тип, такой как T, E или K, V, которые являются хорошо известными заполнителями для Type, Element и Key, Value. Посмотрите на Java Collection Framework для примеров обобщенных методов. В простейшей форме универсальный метод будет выглядеть так: public V put(K key, V value) { return cache.put(key, value); }
Можете ли вы передать List <String> методу, который принимает List <Object>	Этот общий вопрос об интервью на Java может показаться странным для любого, кто не очень знаком с Generics, так как на первый взгляд кажется, что String является объектом, поэтому List <String> можно использовать там, где требуется List <Object>, но это не так. Это приведет к ошибке компиляции. Это имеет смысл, если вы идете на один шаг дальше, потому что List <Object> может хранить любую вещь, включая String, Integer и т. Д., Но List <String> может хранить только String. List<Object> objectList; List<String> stringList; objectList = stringList;
Можем ли мы использовать Generics с Array?	Вероятно, это был самый простой вопрос об обобщении в Java, если вы знаете тот факт, что Array не поддерживает Generics, и именно поэтому Джошуа Блоч предложил предпочесть List над Array, потому что List может обеспечить безопасность типов времени компиляции над Array.
Как вы можете подавить непроверенное предупреждение в Java?	Компилятор javac для Java 5 генерирует непроверенные предупреждения, если вы используете объединение необработанных типов и обобщенных типов, например List<String> rawList = new ArrayList() Note: Hello.java uses unchecked or unsafe operations.; который может быть подавлен с помощью аннотации @SuppressWarnings («unchecked»). Это были некоторые из часто задаваемых вопросов об интервью дженериков и ответов на Java . Ни один из этих общих вопросов интервью не является жестким или сложным, на самом деле они основаны на фундаментальных знаниях дженериков. Любой Java-программист, который имеет приличное знание Generics, должен быть знаком с этими универсальными вопросами в Java. Если у вас есть какой-либо другой хороший общий вопрос, который был задан в каком-либо интервью, или вы ищете ответ на любой вопрос об интервью Generics на Java, пожалуйста, оставьте сообщение в разделе комментариев.
Что такое дженерики в Java? Каковы преимущества использования Generics?	Те, кто пришел до Java 5, знают, как неудобно было сохранять объект в Collection и затем приводить его обратно к правильному типу Type перед его использованием. Дженерики мешают от тех. он обеспечивает безопасность типов времени компиляции и гарантирует, что вы вставляете только правильный тип в коллекцию, и исключает ClassCastException во время выполнения.
В чем отличие ArrayList и ArrayList<?>	Запись вида ArrayList называется raw type (обычный тип). Она эквивалентна записи вида ArrayList<T> и используется для обратной совместимости, т.к. до Java 1.5 не было дженерик коллекций. По возможности такой формы записи следует избегать. ArrayList<?> является супертипом для ArrayList.
Типы генериков.	Существует 2 типа дженериков: Параметризированый тип. Представляет из себя возможность указать неопределенный тип, или несколько(в классе или методе), дать ему имя котрое в дальнейшем можно использоваться в рамках класса, или метода, как эквивалентное оригинальному типу. Может быть использован с ключевым словом extends, ограничен этим классом и его наследниками. Так же можно использовать & или/и | указать несколько классов и/или интерфейсов. Поддерживает рекурсивное расширение типов public static class NumberContainer<T extends Number & Comparable> {  Wildcard. Используется в сигнатуре методов. Для параметризации класса - не возможно. Может быть использован в сочитании ключевыми словами extends и/или super. Делятся на три типа: Upper Bounded Wildcards - <? extends Number> Unbounded Wildcards - <?> Lower Bounded Wildcards - <? super Integer> Для выбора типа используют принцип PECS (Producer Extends Consumer Super) extends - когда надо только получать данные из объекта. Метод передает данные в аргумент. super - когда надо надо только вставлять данные в объект. Метод читает данные из аргумента не использовать wildcard когда надо и получать и вставлять данные в структуру Использование generic wildcards для повышения удобства Java API Рекурсивные дженерики